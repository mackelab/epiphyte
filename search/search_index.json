{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Epiphyte","text":"<p>Welcome to the Epiphyte documentation! </p> <p>Epiphyte is a toolkit for using a relational database to organize and analyze large neural datasets, particularly experiments which use dynamic, continuous stimuli like movies.</p> <p>The focus: unit-wise and population analysis of single neurons paired with dynamic, continous, or otherwise complex stimuli. </p> <p>The core: a DataJoint database built for organizing spiking &amp; field potential data and stimulus information such as feature annotations. </p> <p>The shell: a series of Python modules for building analysis pipelines using database, including modules for generating simulated data and setting up an example database. </p>"},{"location":"#getting-started","title":"Getting Started","text":""},{"location":"#installation","title":"Installation","text":"<p>The Install page provides detailed instructions for setting up Epiphyte for your particular use case. </p>"},{"location":"#tutorials","title":"Tutorials","text":"<p>We provide a series of tutorials for setting up, configuring, and using the Epiphyte core database. No prior knowledge of relational databases is needed. </p> <p>The set-up and configuration scales to any DataJoint implementation, and can be used beyond the example database included in this project. </p> <ol> <li>Launch the database locally or Launch the database on a virtual machine</li> <li>(Optional) Add MinIO to an existing virtual machine</li> <li>Install Epiphyte</li> <li>Configure and connect to the database</li> <li>Design and implement the database</li> <li>Compile the codebase</li> <li>(Optional) Run regular backups</li> </ol>"},{"location":"#api-reference","title":"API Reference","text":"<ul> <li>Browse API Reference for module-level documentation</li> </ul>"},{"location":"acknowledgements/","title":"Acknowledgements","text":"<p>Epiphyte is a tailored implementation of the DataJoint for Python data management framework and was developed at the Macke Lab at the University of T\u00fcbingen and the Mormann Lab and the University Hospital Bonn.</p> <p>We thank Fabian Sinz, Edgar Walker, and Christoph-Benjamin Blessing for their DataJoint support, their input on the database setup, general structure, and troubleshooting. Additionally, many thanks to Aleksandar Levic for his work on the data pre-processing pipeline, to Matthijs Pals and Tharanika Thevururasa for establishing the DataJoint infrastructure on Tuebingen's compute cluster, to Sebastian Bischoff for helping troubleshoot the solutions for large-data storage with MinIO, and to Muthu Jeyanthi Prakash for testing the implementation and providing feedback on the GitHub tutorials. </p>"},{"location":"acknowledgements/#funding","title":"Funding","text":"<p>This research was funded by German Ministry of Education and Research (BMBF), grant number 031L01978 and the German Research Foundation (DFG) through Germany\u2019s Excellence Strategy (EXC-Number 2064/1, Project number 390727645).</p>"},{"location":"contribute/","title":"Contributing","text":""},{"location":"contribute/#contributing","title":"Contributing","text":"<p>We welcome any feedback and improvements! </p> <p>Contributions can be made by submitting an issue or making a pull request on the GitHub repo.</p> <p>For any changes or additions, please follow PEP8 conventions and add docstrings for public APIs. </p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#general","title":"General","text":"<ul> <li>What is Epiphyte? A toolkit for database-backed neural data workflows. Epiphyte is built for working with continuous, dynamic stimuli and associated annotations or meta-data.</li> <li>Where to configure DB access? See <code>epiphyte/database/access_info.py</code>.</li> </ul>"},{"location":"faq/#docker","title":"Docker","text":"<ul> <li><code>docker-compose up -d</code> doesn't work. This line attempts to configure a datajoint database using an existing docker-image. To diagnose the issue, try running <code>sudo docker-compose ps</code>. If this returns nothing, the issue is likely with docker-compose. Make sure the install is correct and that the config files are in the expected place. Otherwise, check out the advice here.</li> </ul>"},{"location":"faq/#mysql-issues","title":"MySQL Issues","text":"<ul> <li> <p><code>mysql -h 127.0.0.1 -u root -P 3306</code> doesn't work. Depending on the error, a couple things could be wrong. Most commonly, the issue is that MySQL is not running in the background.</p> <ul> <li> <p><code>mysql not found</code>: Possibly due to an issue with the path.</p> <ol> <li>Try: <code>export PATH=${PATH}:/usr/local/mysql/bin</code> </li> <li>re-run the original line. if the error is gone, add the above line to your <code>./bash-profile</code>. </li> <li>if the path is not the issue, make sure that MySQL is properly installed. </li> </ol> </li> <li> <p><code>ERROR 2003 (HY000): Can\u2019t connect to MySQL server on '127.0.0.1' (111)</code> Likely cause: the MySQL server isn\u2019t running (or is listening on a different port).</p> <ol> <li>Check if MySQL is running:     <pre><code>ps -Af | grep mysqld\n</code></pre>     If you only see your shell/grep line like     <pre><code>al       18214 18159  0 13:01 pts/4    00:00:00 grep mysqld\n</code></pre>     then MySQL is not running.</li> <li>Start MySQL.<ul> <li>Linux: <pre><code>sudo systemctl start mysql.service\n# or (on some distros)\nsudo service mysqld start\n</code></pre> If you get <code>Failed to start mysqld.service: Unit mysqld.service not found.</code>, see the dedicated section below.</li> <li>macOS (Homebrew): <pre><code>brew services start mysql@5.7\n</code></pre></li> </ul> </li> <li>Verify it\u2019s running:     <pre><code>ps -Af | grep mysqld\n</code></pre>     Expected output includes a <code>mysqld</code> line, e.g.     <pre><code>mysql    18365     1 30 13:04 ?        00:00:01 /usr/libexec/mysqld --basedir=/usr\n</code></pre></li> <li>Find the listening port (default 3306):     <pre><code>sudo netstat -lnp | grep mysql\n</code></pre></li> <li>Try logging in using that port:     <pre><code>mysql -h 127.0.0.1 -u root -P &lt;port&gt;\n</code></pre> Reference: Troubleshooting steps and causes are discussed here.</li> </ol> </li> <li> <p><code>ERROR 1045 (28000): Access denied for user 'user'@'172.18.0.1' (using password: NO)</code> Cause: authentication failed\u2014no password was provided or server isn\u2019t fully configured yet.</p> <ul> <li>Fix</li> <li>Force a password prompt:     <pre><code>mysql -h 127.0.0.1 -u root -p\n</code></pre></li> <li>When prompted, enter your password.     If you haven\u2019t changed it and are using the default from your environment, use <code>simple</code>.</li> <li>Once authenticated, you should enter the MySQL monitor.</li> </ul> <p>Security note: Change the default password once your database is stable (see the DataJoint/MySQL hardening guide).</p> </li> <li> <p><code>ERROR 1698 (28000): Access denied for user 'root'@'localhost'</code> Cause: root uses socket or another auth plugin; your CLI user isn\u2019t permitted.</p> <ul> <li>Fix (Linux)</li> <li>Log in with sudo:     <pre><code>sudo mysql -u root\n</code></pre></li> <li>Create a local user mapped to your system account and grant privileges:     <pre><code>USE mysql;\nCREATE USER 'YOUR_SYSTEM_USER'@'localhost' IDENTIFIED BY '';\nGRANT ALL PRIVILEGES ON *.* TO 'YOUR_SYSTEM_USER'@'localhost';\nUPDATE user SET plugin='auth_socket' WHERE User='YOUR_SYSTEM_USER';\nFLUSH PRIVILEGES;\n</code></pre></li> <li>Restart MySQL:     <pre><code>sudo service mysql restart\n</code></pre></li> </ul> </li> <li> <p><code>Failed to start mysqld.service: Unit mysqld.service not found.</code> Cause: MySQL not installed (or a mismatched service name) on your distro.</p> <ul> <li>Fix (Ubuntu)</li> <li>Update package lists:     <pre><code>sudo apt-get update\n</code></pre></li> <li>Install MySQL server:     <pre><code>sudo apt-get install mysql-server\n</code></pre></li> <li>Start MySQL:     <pre><code>sudo systemctl start mysql.service\n</code></pre></li> <li>Verify:     <pre><code>ps -Af | grep mysqld\n</code></pre>     You should see a line like:     <pre><code>mysql       7186       1  2 12:34 ?        00:00:00 /usr/sbin/mysqld\n</code></pre></li> </ul> </li> <li> <p>Homebrew postinstall warning: <code>Warning: The post-install step did not complete successfully.</code> after <code>brew postinstall mysql@5.7</code> Cause: multiple/conflicting MySQL installs.</p> <ul> <li>Fix</li> <li>See potential resolutions on this StackOverflow thread: https://stackoverflow.com/questions/50874931/the-post-install-step-did-not-complete-successfully-mysql-mac-os-sierra</li> </ul> </li> <li> <p>SSL handshake when using DataJoint/Python: <code>\"Can't connect to MySQL server on '127.0.0.1' ([SSL: SSLV3_ALERT_HANDSHAKE_FAILURE]\"</code> Cause: DataJoint (as of Jan 2024) hasn\u2019t supported Python &gt; 3.9 in some setups; newer Python may trigger SSL handshake errors with <code>datajoint.conn()</code>.</p> <ul> <li>Fix</li> <li>Use Python 3.7\u20133.9, or create a fresh virtual environment pinned to \u2264 3.9 for DataJoint.</li> <li>Then retry your connection.</li> </ul> </li> </ul> <p>After applying the relevant fix, you should be able to connect both from Terminal and from a Jupyter notebook. If an error persists, re-check that MySQL is running and that you are using the correct host/port/credentials.</p> </li> </ul>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#installation","title":"Installation","text":"<p>Epiphyte can be configured and deployed for three main use cases: </p> <p></p>"},{"location":"install/#option-a-install-a-local-instance-of-epiphyte","title":"Option A: Install a local instance of Epiphyte.","text":"<p>Use cases: </p> <ul> <li>You want to test out the database infrastructure.</li> <li>You will be the only user and do not work with large data files. </li> </ul> <p>Install locally,</p> <p>and continue to Configure and connect to the database.</p>"},{"location":"install/#option-b-install-a-remote-instance-of-epiphyte-without-minio","title":"Option B: Install a remote instance of Epiphyte, without MinIO.","text":"<p>Use cases:</p> <ul> <li>Multiple people, accessing from separate locations, will use the database. </li> <li>You do not need to support large data files. </li> </ul> <p>Install on a server-hosted virtual machine,</p> <p>and continue to Install and set up Epiphyte.</p>"},{"location":"install/#option-c-install-a-remote-instance-of-epiphyte-with-minio","title":"Option C: Install a remote instance of Epiphyte, with MinIO.","text":"<p>Use cases:</p> <ul> <li>Multiple people, accessing from separate locations, will use the database. </li> <li>You use large data files (e.g., LFP, movie data, multi-hour calcium imaging).</li> </ul> <p>Start at Launch the MySQL database on a virtual machine and continue through the remaining tutorials.</p>"},{"location":"reference/data/","title":"Data utilities","text":""},{"location":"reference/data/#epiphyte.data","title":"epiphyte.data","text":""},{"location":"reference/data/#epiphyte.data.mock_data_inits","title":"mock_data_inits","text":"<p>Seed spike shapes for randomized mock data generation. These are used in <code>epiphyte.data.mock_data_utils</code> to generate mock spike timeseries data.</p> <p>Notes:</p> <ul> <li><code>spike_shape_u</code> is the mean spike shape (in microvolts) for a spike with 64 samples.</li> <li><code>spike_shape_sd</code> is the standard deviation of the spike shape (in microvolts) for a spike with 64 samples.</li> </ul>"},{"location":"reference/data/#epiphyte.data.mock_data_utils","title":"mock_data_utils","text":"<p>Mock neural-data generator and file writer.</p> <p>This module contains GenerateData, which synthesizes spike trains, LFP-like signals, channel metadata, event streams, DAQ logs, and watchlogs, and for saves them to the on-disk layout expected by Epiphyte. Constants such as output roots (e.g., PATH_TO_DATA, PATH_TO_LABELS), annotation metadata (e.g., annotators), and spike-shape parameters are read from epiphyte.database.config and .mock_data_inits.</p> Example <pre><code>from epiphyte.data.mock_data_utils import GenerateData\n\ngen = GenerateData(patient_id=1, session_nr=1, stimulus_len=83.33)\ngen.summarize()\ngen.save_session_info()\ngen.save_spike_trains()\ngen.save_lfp_data()\ngen.save_channel_names()\ngen.save_events()\ngen.save_daq_log()\ngen.save_watchlog_with_artifacts()\n</code></pre> <p>Running the module as a script executes run_data_generation(), which creates a small demo dataset for a few patients/sessions.</p> <p>Outputs &amp; directory layout:</p> <pre><code>Created under:\n    {PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/\n\n- session_info.npy\n    Dict with keys: patient_id, session_nr, date, time\n- ChannelNames.txt\n    One \".ncs\" channel name per line\n- spiking_data/CSC{channel}_{MU|SU}{idx}.npy\n    Dict with \"spike_times\" (ms, Unix epoch) and \"spike_amps\" (waveform arrays)\n- lfp_data/CSC1_lfp.npy\n    Dict with \"ts\" (ms, Unix epoch) and \"samples\" (1 kHz sine)\n- event_file/Events.npy\n    Rows of (timestamp, code); codes tile over [1, 2, 4, 8, 16, 32, 64, 128]\n- daq_files/timedDAQ-log-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log\n    Tabular DAQ log\n- watchlogs/ffplay-watchlog-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log\n    PTS/CPU-time log with pauses/skips\n\nAnnotation stubs are written to:\n    {PATH_TO_LABELS}/\nas simple *.npy arrays with on/off segments.\n</code></pre> Conventions <ul> <li>Time bases:<ul> <li>Spike times / LFP timestamps: milliseconds since Unix epoch</li> <li>stim_on_time / stim_off_time: microseconds since Unix epoch</li> <li>Watchlog PTS increments: ~0.04 s per frame</li> </ul> </li> <li>Sampling: LFP synthesized at 1 kHz</li> <li>Randomness: Data are randomized per run (no fixed seed by default)</li> </ul> Public API <ul> <li>GenerateData: main generator with save_* methods for each artifact</li> <li>run_data_generation(): convenience entry point to populate a demo dataset</li> </ul> Notes <ul> <li>Relies on configuration constants from epiphyte.database.config and   waveform shape parameters from .mock_data_inits.</li> <li>Use GenerateData.summarize() to quickly inspect randomized session settings.</li> <li>For reproducible outputs, set seeds in both random and numpy.random   before instantiation.</li> </ul>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData","title":"GenerateData","text":"<p>Generate mock neural data and related metadata.</p> <p>Attributes:</p> Name Type Description <code>patient_id</code> <code>int</code> <p>Integer identifier for the mock patient.</p> <code>session_nr</code> <code>int</code> <p>Session number for this recording.</p> <code>stimulus_len</code> <code>float</code> <p>Stimulus length in minutes.</p> <code>nr_channels</code> <code>int</code> <p>Number of channels simulated.</p> <code>nr_units</code> <code>int</code> <p>Number of units across all channels.</p> <code>nr_channels_per_region</code> <code>int</code> <p>Channels per brain region label.</p> <code>unit_types</code> <code>enum</code> <p>Allowed unit type codes (e.g., <code>\"MU\"</code>, <code>\"SU\"</code>).</p> <code>brain_regions</code> <code>List[str]</code> <p>Region codes used to synthesize channel names.</p> <code>rec_length</code> <code>int</code> <p>Recording length in milliseconds.</p> <code>rectime_on</code> <code>int</code> <p>Start time (unix epoch ms) for recording.</p> <code>rectime_off</code> <code>int</code> <p>End time (unix epoch ms) for recording.</p> <code>spike_times</code> <code>List[ndarray]</code> <p>Generated spike time arrays per unit.</p> <code>spike_amps</code> <code>List[ndarray]</code> <p>Generated spike amplitude arrays per unit.</p> <code>channel_dict</code> <code>dict</code> <p>Mapping of channel index to list of unit types.</p> <code>sampling_rate</code> <code>int</code> <p>LFP sampling rate (Hz) used in mock signal.</p> <code>len_context_files</code> <code>int</code> <p>Number of entries for events/DAQ logs.</p> <code>datetime</code> <code>str</code> <p>ISO-like timestamp used in filenames.</p> <code>signal_tile</code> <code>ndarray</code> <p>Bit-pattern tile used to synthesize event codes.</p> <code>stim_on_time</code> <code>int</code> <p>Estimated stimulus onset (microseconds).</p> <code>stim_off_time</code> <code>int</code> <p>Estimated stimulus offset (microseconds).</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>class GenerateData:\n    \"\"\"Generate mock neural data and related metadata.\n\n    Attributes:\n        patient_id (int): Integer identifier for the mock patient.\n        session_nr (int): Session number for this recording.\n        stimulus_len (float): Stimulus length in minutes.\n        nr_channels (int): Number of channels simulated.\n        nr_units (int): Number of units across all channels.\n        nr_channels_per_region (int): Channels per brain region label.\n        unit_types (enum): Allowed unit type codes (e.g., ``\"MU\"``, ``\"SU\"``).\n        brain_regions (List[str]): Region codes used to synthesize channel names.\n        rec_length (int): Recording length in milliseconds.\n        rectime_on (int): Start time (unix epoch ms) for recording.\n        rectime_off (int): End time (unix epoch ms) for recording.\n        spike_times (List[np.ndarray]): Generated spike time arrays per unit.\n        spike_amps (List[np.ndarray]): Generated spike amplitude arrays per unit.\n        channel_dict (dict): Mapping of channel index to list of unit types.\n        sampling_rate (int): LFP sampling rate (Hz) used in mock signal.\n        len_context_files (int): Number of entries for events/DAQ logs.\n        datetime (str): ISO-like timestamp used in filenames.\n        signal_tile (np.ndarray): Bit-pattern tile used to synthesize event codes.\n        stim_on_time (int): Estimated stimulus onset (microseconds).\n        stim_off_time (int): Estimated stimulus offset (microseconds).\n    \"\"\"\n\n    def __init__(self, patient_id: int, session_nr: int,\n                 stimulus_len: float = 83.33) -&gt; None:\n\n        self.patient_id = patient_id\n        self.session_nr = session_nr\n        self.stimulus_len = stimulus_len\n\n        self.nr_channels = 80\n        self.nr_units = random.randint(20, 100)\n        self.nr_channels_per_region = 8\n        self.unit_types = [\"MU\", \"SU\"]\n        self.brain_regions = [\"LA\", \"LAH\", \"LEC\", \"LMH\", \"LPHC\", \n                              \"RA\", \"RAH\", \"REC\", \"RMH\", \"RPCH\"]\n\n        self.rec_length = 5400000\n        self.rectime_on = random.randint(1347982266000, 1695051066000)\n        self.rectime_off = self.rectime_on + self.rec_length + random.randint(300000, 900000)\n\n        self.spike_times, self.spike_amps = self.generate_spike_trains()\n        self.channel_dict = self.generate_channelwise_unit_distribution()\n\n        self.sampling_rate = 1000\n        ## stimulus data\n\n        self.len_context_files = random.randint(4000, 5400) # generate length of events.nev &amp; DAQ file. \n        self.datetime = datetime.utcfromtimestamp(int(self.rectime_on)/1000).strftime('%Y-%m-%d_%H-%M-%S')\n\n        self.signal_tile = self.generate_pings()\n        self.stim_on_time = self.generate_stimulus_onsets()[0]\n        self.stim_off_time = self.generate_stimulus_onsets()[1]\n\n    def summarize(self) -&gt; None:\n        \"\"\"Print key randomized parameters for quick inspection.\"\"\"\n\n        print(f\"# of 'neurons': {self.nr_units}\")\n        print(f\"Date of recording session: {self.datetime}\")\n\n\n    def format_save_dir(self, subdir: str | None = None) -&gt; Path:\n        \"\"\"Build and ensure the output directory exists.\n\n        Args:\n            subdir: Optional subdirectory under the session path.\n\n        Returns:\n            Path: Absolute path to the created directory:\n                ``{PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/[subdir]``.\n        \"\"\"\n\n        save_dir = Path(f\"{PATH_TO_DATA}/patient_data/{self.patient_id}/session_{self.session_nr}/\")\n\n        if subdir:\n            save_dir = save_dir / subdir\n\n        save_dir.mkdir(parents=True, exist_ok=True)\n\n        return save_dir\n\n    def generate_spike_trains(self) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:\n        \"\"\"Generate mock spike trains and amplitudes for all units.\n\n        Returns:\n            Tuple[List[np.ndarray], List[np.ndarray]]: ``(spike_times, spike_amps)``\n\n            - ``spike_times``: list of length ``nr_units``; each element is a\n            sorted ``float`` array of spike times in Unix epoch **ms**.\n            - ``spike_amps``: list of length ``nr_units``; each element is a\n            ``(n_spikes, 64)`` array of waveform-like amplitudes.\n\n        Notes:\n            The number of spikes per unit is randomized per unit.\n        \"\"\"\n\n        spike_times = [\n            np.sort([uniform(self.rectime_on, self.rectime_off) for _ in range(int(uniform(50, 5000)))])\n            for _ in range(self.nr_units)\n        ]\n\n        spike_amps = []\n        for s_t in spike_times:\n\n            new_amps = np.random.normal(loc=spike_shape_u, scale=spike_shape_sd, size=(len(s_t), 64))\n            spike_amps.append(new_amps)\n\n        return spike_times, spike_amps\n\n    def generate_channelwise_unit_distribution(self) -&gt; dict[int, List[str]]:\n        \"\"\"Distribute units across channels and assign unit types.\n\n        Returns:\n            dict[int, List[str]]: Mapping from channel index (1-based) to a list\n            of unit-type codes (e.g., ``[\"MU\", \"SU\", ...]``).\n        \"\"\"\n\n        channel_units = [\n            int(random.uniform(1, self.nr_channels+1)) for _ in range(self.nr_units)\n        ]\n\n        channel_dict = {\n            csc: [random.choice(self.unit_types) for _ in range(repeats)]\n            for (csc, repeats) in Counter(channel_units).items()\n        }\n\n        return channel_dict\n\n    def generate_lfp_channel(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Generate a simple sine-wave LFP-like channel.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]: ``(timestamps_ms, samples)`` where\n            ``timestamps_ms`` are Unix epoch **ms** and ``samples`` is a float\n            array representing an 8 Hz sine wave at 1 kHz.\n        \"\"\"\n        ts = np.arange(self.rectime_on, self.rectime_off,1)\n        frequency = 8  # in Hz\n        amplitude = 100  # arbitrary unit\n        samples = amplitude * np.sin(2 * np.pi * frequency * ts)\n        return ts, samples\n\n    def generate_channel_list(self) -&gt; List[str]:\n        \"\"\"Create channel names like ``LA1``, ``LA2``, ..., ``RPCH8``.\n\n        Returns:\n            List[str]: List of channel name strings.\n        \"\"\"\n\n        channel_list = [\n            f\"{region}{i+1}\" \n            for region in self.brain_regions\n            for i in range(self.nr_channels_per_region)\n                       ]\n\n        return channel_list\n\n    def save_spike_trains(self) -&gt; None:\n        \"\"\"Save generated spike trains and amplitudes as ``.npy`` files.\n\n        Writes:\n            ``spiking_data/CSC{channel}_{TYPE}{idx}.npy`` under the session\n            directory. Each file contains a dict with keys:\n\n            - ``\"spike_times\"``: Unix epoch **ms** (1D array)\n            - ``\"spike_amps\"``: waveform amplitudes, shape ``(n_spikes, 64)``\n        \"\"\"\n        save_dir = self.format_save_dir(subdir=\"spiking_data\")\n\n        i = 0\n        for csc, unit_types in self.channel_dict.items():\n            su_ct = 1\n            mu_ct = 1\n\n            for t in unit_types:\n                if t == \"SU\":\n                    unit_counter = su_ct\n                    su_ct += 1\n                elif t == \"MU\":\n                    unit_counter = mu_ct\n                    mu_ct += 1\n\n                save_dict = {\n                    \"spike_times\": self.spike_times[i], \n                    \"spike_amps\": self.spike_amps[i]\n                }\n\n                filename = f\"CSC{csc}_{t}{unit_counter}.npy\"\n                np.save(save_dir / filename, save_dict)\n                i += 1\n\n    def save_lfp_data(self) -&gt; None:\n        \"\"\"Generate and save the LFP channel as ``CSC1_lfp.npy``.\n\n        Writes:\n            ``lfp_data/CSC1_lfp.npy`` containing a dict with:\n\n            - ``\"ts\"``: timestamps (Unix epoch **ms**)\n            - ``\"samples\"``: LFP-like samples at 1 kHz\n\n        Notes: \n            Only one LFP channel is generated due to the size of each channel. \n            A single channel suffices for demonstration purposes.\n            If you include field potential data, consider using a large-storage backend.\n        \"\"\"\n        save_dir = self.format_save_dir(subdir=\"lfp_data\")\n\n        ts, samples = self.generate_lfp_channel()\n\n        filename = f\"CSC1_lfp.npy\"\n        np.save(save_dir / filename, {\"ts\": ts, \"samples\": samples})\n\n    def save_channel_names(self) -&gt; None:\n        \"\"\"Save ``ChannelNames.txt`` listing channel names one per line.\n\n        Writes:\n            ``ChannelNames.txt`` in the session root. Each line ends with\n            ``.ncs`` (e.g., ``LA1.ncs``).\n        \"\"\"        \n        save_dir = self.format_save_dir()\n\n        channel_names = self.generate_channel_list()\n\n        file = save_dir / \"ChannelNames.txt\"\n        f1 = open(file, \"w+\")\n        for csc_name in channel_names:\n            f1.write(f\"{csc_name}.ncs\\n\")\n        f1.close()\n\n    def save_session_info(self) -&gt; None:\n        \"\"\"Save a ``session_info.npy`` dictionary.\n\n        Writes:\n            ``session_info.npy`` containing a dict with\n            ``patient_id``, ``session_nr``, ``date``, and ``time`` (UTC).\n        \"\"\"\n        save_dir = self.format_save_dir()\n\n        date, time = self.datetime.split(\"_\")\n        session_info = {\n            \"patient_id\": self.patient_id,\n            \"session_nr\": self.session_nr,\n            \"date\": date, \n            \"time\": time\n        }\n        np.save(save_dir / \"session_info.npy\", session_info)\n\n    ## stimulus data generation\n\n    def generate_pings(self) -&gt; np.ndarray:\n        \"\"\"Create a repeating event-code tile.\n\n        Returns:\n            np.ndarray: 1D integer array of length ``len_context_files`` with\n            elements tiled from ``[1, 2, 4, 8, 16, 32, 64, 128]``.\n        \"\"\"\n        # recreate pings\n        if self.len_context_files % 8 == 0:\n            reps = int(self.len_context_files / 8)\n        else:\n            reps = int(self.len_context_files / 8) + 1\n\n        signal_tile = np.tile([1,2,4,8,16,32,64,128], reps)\n        signal_tile = signal_tile[:self.len_context_files]\n\n        return signal_tile\n\n    def generate_events(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n        \"\"\"Generate mock event timestamps and (timestamp, code) matrix.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray]:\n                - ``events``: 1D float array of Unix epoch **ms** timestamps.\n                - ``events_mat``: 2D array with rows ``(timestamp_ms, code)``.\n        \"\"\"\n\n        # recreate event timestamps\n        events = np.linspace(self.rectime_on, self.rectime_off, num=self.len_context_files)\n        events_mat = np.array(list(zip(events, self.signal_tile)))\n\n        return events, events_mat\n\n    def save_events(self) -&gt; None:\n        \"\"\"Save generated events to ``event_file/Events.npy``.\"\"\"\n\n        events, events_mat = self.generate_events()\n\n        save_dir = self.format_save_dir(subdir=\"event_file\")\n\n        ev_name = save_dir / \"Events.npy\"\n\n        np.save(ev_name, events_mat)\n\n    def generate_stimulus_onsets(self) -&gt; Tuple[int, int]:\n        \"\"\"Generate approximate onset and offset timestamps for the stimulus.\n\n        Returns:\n            Tuple[int, int]: ``(stim_on_time, stim_off_time)`` in Unix epoch **\u00b5s**.\n        \"\"\"\n\n        # generate projected end time for the DAQ log, in unix time microseconds\n        # movie_len_unix = (stimulus_len * 60 * 1000 * 1000)       \n        stim_on_time = (self.rectime_on + random.randint(120000, 180000)) * 1000\n        stim_off_time = (stim_on_time + (self.stimulus_len * 60 * 1000)) * 1000\n\n        return stim_on_time, stim_off_time\n\n    def seed_and_interval(self) -&gt; Tuple[int, int]:\n        \"\"\"Compute DAQ interval and initial seed time for log synthesis.\n\n        Returns:\n            Tuple[int, int]: ``(interval_us, seed_time_us)`` in **microseconds**.\n        \"\"\"\n\n        add_interval = int((self.stim_off_time) / self.len_context_files)\n        seed = int(self.stim_on_time + add_interval * 1.25)\n        return add_interval, seed\n\n    def generate_daq_log(self) -&gt; List[Tuple[int, int, int, int]]:\n        \"\"\"Generate DAQ log entries.\n\n        Each entry is a tuple ``(code, idx, pre_us, post_us)``.\n\n        Returns:\n            List[Tuple[int, int, int, int]]: DAQ log with one row per event.\n        \"\"\"\n        add_interval, seed = self.seed_and_interval()\n\n        pre = []\n        post = []\n\n        for i in range(self.len_context_files):\n            interval_diff = (np.random.normal(1000, 200) / 2)\n\n            pre.append(int(seed - interval_diff))\n            post.append(int(seed + interval_diff))\n            seed += add_interval \n\n        return list(zip(self.signal_tile, np.arange(self.len_context_files), pre, post))\n\n    def save_daq_log(self) -&gt; None:\n        \"\"\"Save the generated DAQ log as a text file in ``daq_files``.\"\"\"\n\n        log_lines = self.generate_daq_log()\n\n        save_dir = self.format_save_dir(subdir=\"daq_files\")\n        log_loc = save_dir / f\"timedDAQ-log-{self.datetime}.log\"\n\n        with open(log_loc, 'a') as file:\n            file.write(\"Initial signature: 255\t255\\n255\\t255\\t\\ndata\\tStamp\\tpre\\tpost\\n\")\n            for datum in log_lines:\n                file.write(\"{}\\t{}\\t{}\\t{}\\n\".format(datum[0], datum[1], datum[2], datum[3]))\n            file.close()\n\n    def generate_perfect_watchlog(self) -&gt; Tuple[int, List[float], List[int]]:\n        \"\"\"Generate watchlog without pauses or skips.\n\n        Returns:\n            Tuple[int, List[float], List[int]]:\n                - ``nr_movie_frames``: Number of frames (\u2248 stimulus_len / 0.04s).\n                - ``perfect_pts``: PTS values (seconds), 0.04 s increments.\n                - ``cpu_time``: Corresponding Unix epoch **\u00b5s** timestamps.\n        \"\"\"\n\n        _, seed = self.seed_and_interval()\n\n        nr_movie_frames = int(self.stimulus_len * 60 / 0.04)\n        perfect_pts = [round((x * 0.04), 2) for x in range(1, nr_movie_frames+1)] \n\n        cpu_time = []\n        for i in range(nr_movie_frames):\n            seed += 41000\n            cpu_time.append(seed)\n\n        return nr_movie_frames, perfect_pts, cpu_time\n\n    def save_perfect_watchlog(self) -&gt; None:\n        \"\"\"Write a perfect (no pauses/skips) watchlog to ``watchlogs``.\"\"\"\n        nr_movie_frames, perfect_pts, cpu_time = self.generate_perfect_watchlog()\n\n        save_dir = self.format_save_dir(subdir=\"watchlogs\")\n\n        wl_name = f\"ffplay-watchlog-{self.datetime}.log\"\n\n        with open(save_dir / wl_name, 'a') as file:\n            file.write(\"movie_stimulus.avi\\n\")\n            for i in range(nr_movie_frames):\n                file.write(\"pts\\t{}\\ttime\\t{}\\n\".format(perfect_pts[i], cpu_time[i]))\n            file.close()\n\n    def make_pauses_and_skips(self) -&gt; Tuple[int, List[float], List[int], List[int]]:\n        \"\"\"Generate a watchlog with pauses and skips.\n\n        Returns:\n            Tuple[int, List[float], List[int], List[int]]:\n                - ``nr_movie_frames``: Number of frames.\n                - ``pts``: PTS values (seconds) after inserting skips.\n                - ``cpu_time``: Unix epoch **\u00b5s** timestamps per frame.\n                - ``indices_pause``: Frame indices at which a pause occurred.\n\n        Notes:\n            Pause lengths and skip magnitudes are randomized. PTS values are\n            clamped to the movie duration and non-negative.\n        \"\"\"\n        nr_movie_frames, perfect_pts, cpu_time = self.generate_perfect_watchlog()\n        _, seed = self.seed_and_interval()\n        pause_pool = 1 * 1000 * 1000 * 60 # 5 minutes in unix/epoch time -- use for max pause time        movie_len_unix = (self.stimulus_len * 60 * 1000 * 1000) - pause_pool\n\n        movie_len_unix = (self.stimulus_len * 60 * 1000 * 1000) - pause_pool\n        end_time = seed + movie_len_unix \n        add_interval = int((end_time - seed) / nr_movie_frames)\n\n        cpu_time = []\n        for i in range(nr_movie_frames):\n            seed += add_interval\n            cpu_time.append(int(seed))   \n\n        nr_pauses = int(uniform(1,3))\n        min_pause = 0.1 * 1000 * 1000 * 60\n\n        indices_pause = random.sample(range(len(cpu_time) - 5000), nr_pauses)\n\n        cpu_time = np.array(cpu_time)\n\n        for i, index in enumerate(indices_pause): \n            if (len(indices_pause) - i) &gt; 0: \n                pause_len = random.randint(int(min_pause), pause_pool)\n                cpu_time = np.concatenate((cpu_time[:index],cpu_time[index:] + pause_len)) \n                pause_pool -= pause_len\n            else:\n                pause_len = pause_pool\n                cpu_time = np.concatenate((cpu_time[:index],cpu_time[index:] + pause_len))\n\n            # randomly select indices from perfect watchlog \n            nr_skips = int(uniform(1,4))\n\n            indices_skip = random.sample(range(len(perfect_pts) - 5000), nr_skips)\n\n            skip_pts = np.array(copy.copy(perfect_pts))\n\n            max_skip = 500\n\n            for i, index in enumerate(indices_skip): \n                # note: careful about values here -- can exceed mocked movie length. \n                # currently set so that the max possible skip is the penultimate frame\n                if len(indices_skip) &gt; 1:\n                    skip_len = int(uniform((max_skip * -1), max_skip))\n                    skip_pts = np.concatenate((skip_pts[:index],skip_pts[index:] + skip_len)) \n                    max_skip -= skip_len\n\n                if len(indices_skip) == 1:\n                    skip_len = max_skip\n                    skip_pts = np.concatenate((skip_pts[:index],skip_pts[index:] + skip_len)) \n\n            # test for rounding issue\n            skip_pts = [round(frame, 2) for frame in skip_pts]\n\n            # prevents generated frame from exceeding the mock movie length\n            skip_pts_revised = []\n            for i, frame in enumerate(skip_pts):\n                if frame &gt; (nr_movie_frames * 0.04):\n                    skip_pts_revised.append(nr_movie_frames * 0.04)\n                if frame &lt;= (nr_movie_frames * 0.04):\n                    skip_pts_revised.append(frame)\n                if frame &lt; 0: \n                    skip_pts_revised.append(0.0)\n\n\n        return nr_movie_frames, skip_pts_revised, cpu_time, indices_pause\n\n    def save_watchlog_with_artifacts(self) -&gt; None:\n        \"\"\"Save a watchlog including pauses and skips to ``watchlogs`` dir.\"\"\"\n        nr_movie_frames, skip_pts_revised, cpu_time, indices_pause = self.make_pauses_and_skips()\n\n        # save\n        save_dir = self.format_save_dir(subdir=\"watchlogs\")\n        wl_name = f\"ffplay-watchlog-{self.datetime}.log\"\n\n        with open(save_dir / wl_name, 'a') as file:\n            file.write(\"movie_stimulus.avi\\n\")\n            for i in range(nr_movie_frames):\n                if i not in indices_pause:\n                    file.write(\"pts\\t{}\\ttime\\t{}\\n\".format(skip_pts_revised[i], cpu_time[i]))\n                if i in indices_pause: \n                    file.write(\"Pausing\\nContinuing\\tafter\\tpause\\n\")\n\n        file.close()\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.summarize","title":"summarize","text":"<pre><code>summarize()\n</code></pre> <p>Print key randomized parameters for quick inspection.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def summarize(self) -&gt; None:\n    \"\"\"Print key randomized parameters for quick inspection.\"\"\"\n\n    print(f\"# of 'neurons': {self.nr_units}\")\n    print(f\"Date of recording session: {self.datetime}\")\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.format_save_dir","title":"format_save_dir","text":"<pre><code>format_save_dir(subdir=None)\n</code></pre> <p>Build and ensure the output directory exists.</p> <p>Parameters:</p> Name Type Description Default <code>subdir</code> <code>str | None</code> <p>Optional subdirectory under the session path.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Absolute path to the created directory: <code>{PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/[subdir]</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def format_save_dir(self, subdir: str | None = None) -&gt; Path:\n    \"\"\"Build and ensure the output directory exists.\n\n    Args:\n        subdir: Optional subdirectory under the session path.\n\n    Returns:\n        Path: Absolute path to the created directory:\n            ``{PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/[subdir]``.\n    \"\"\"\n\n    save_dir = Path(f\"{PATH_TO_DATA}/patient_data/{self.patient_id}/session_{self.session_nr}/\")\n\n    if subdir:\n        save_dir = save_dir / subdir\n\n    save_dir.mkdir(parents=True, exist_ok=True)\n\n    return save_dir\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_spike_trains","title":"generate_spike_trains","text":"<pre><code>generate_spike_trains()\n</code></pre> <p>Generate mock spike trains and amplitudes for all units.</p> <p>Returns:</p> Type Description <code>List[ndarray]</code> <p>Tuple[List[np.ndarray], List[np.ndarray]]: <code>(spike_times, spike_amps)</code></p> <code>List[ndarray]</code> <ul> <li><code>spike_times</code>: list of length <code>nr_units</code>; each element is a</li> </ul> <code>Tuple[List[ndarray], List[ndarray]]</code> <p>sorted <code>float</code> array of spike times in Unix epoch ms.</p> <code>Tuple[List[ndarray], List[ndarray]]</code> <ul> <li><code>spike_amps</code>: list of length <code>nr_units</code>; each element is a</li> </ul> <code>Tuple[List[ndarray], List[ndarray]]</code> <p><code>(n_spikes, 64)</code> array of waveform-like amplitudes.</p> Notes <p>The number of spikes per unit is randomized per unit.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_spike_trains(self) -&gt; Tuple[List[np.ndarray], List[np.ndarray]]:\n    \"\"\"Generate mock spike trains and amplitudes for all units.\n\n    Returns:\n        Tuple[List[np.ndarray], List[np.ndarray]]: ``(spike_times, spike_amps)``\n\n        - ``spike_times``: list of length ``nr_units``; each element is a\n        sorted ``float`` array of spike times in Unix epoch **ms**.\n        - ``spike_amps``: list of length ``nr_units``; each element is a\n        ``(n_spikes, 64)`` array of waveform-like amplitudes.\n\n    Notes:\n        The number of spikes per unit is randomized per unit.\n    \"\"\"\n\n    spike_times = [\n        np.sort([uniform(self.rectime_on, self.rectime_off) for _ in range(int(uniform(50, 5000)))])\n        for _ in range(self.nr_units)\n    ]\n\n    spike_amps = []\n    for s_t in spike_times:\n\n        new_amps = np.random.normal(loc=spike_shape_u, scale=spike_shape_sd, size=(len(s_t), 64))\n        spike_amps.append(new_amps)\n\n    return spike_times, spike_amps\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_channelwise_unit_distribution","title":"generate_channelwise_unit_distribution","text":"<pre><code>generate_channelwise_unit_distribution()\n</code></pre> <p>Distribute units across channels and assign unit types.</p> <p>Returns:</p> Type Description <code>dict[int, List[str]]</code> <p>dict[int, List[str]]: Mapping from channel index (1-based) to a list</p> <code>dict[int, List[str]]</code> <p>of unit-type codes (e.g., <code>[\"MU\", \"SU\", ...]</code>).</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_channelwise_unit_distribution(self) -&gt; dict[int, List[str]]:\n    \"\"\"Distribute units across channels and assign unit types.\n\n    Returns:\n        dict[int, List[str]]: Mapping from channel index (1-based) to a list\n        of unit-type codes (e.g., ``[\"MU\", \"SU\", ...]``).\n    \"\"\"\n\n    channel_units = [\n        int(random.uniform(1, self.nr_channels+1)) for _ in range(self.nr_units)\n    ]\n\n    channel_dict = {\n        csc: [random.choice(self.unit_types) for _ in range(repeats)]\n        for (csc, repeats) in Counter(channel_units).items()\n    }\n\n    return channel_dict\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_lfp_channel","title":"generate_lfp_channel","text":"<pre><code>generate_lfp_channel()\n</code></pre> <p>Generate a simple sine-wave LFP-like channel.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>Tuple[np.ndarray, np.ndarray]: <code>(timestamps_ms, samples)</code> where</p> <code>ndarray</code> <p><code>timestamps_ms</code> are Unix epoch ms and <code>samples</code> is a float</p> <code>Tuple[ndarray, ndarray]</code> <p>array representing an 8 Hz sine wave at 1 kHz.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_lfp_channel(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generate a simple sine-wave LFP-like channel.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: ``(timestamps_ms, samples)`` where\n        ``timestamps_ms`` are Unix epoch **ms** and ``samples`` is a float\n        array representing an 8 Hz sine wave at 1 kHz.\n    \"\"\"\n    ts = np.arange(self.rectime_on, self.rectime_off,1)\n    frequency = 8  # in Hz\n    amplitude = 100  # arbitrary unit\n    samples = amplitude * np.sin(2 * np.pi * frequency * ts)\n    return ts, samples\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_channel_list","title":"generate_channel_list","text":"<pre><code>generate_channel_list()\n</code></pre> <p>Create channel names like <code>LA1</code>, <code>LA2</code>, ..., <code>RPCH8</code>.</p> <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of channel name strings.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_channel_list(self) -&gt; List[str]:\n    \"\"\"Create channel names like ``LA1``, ``LA2``, ..., ``RPCH8``.\n\n    Returns:\n        List[str]: List of channel name strings.\n    \"\"\"\n\n    channel_list = [\n        f\"{region}{i+1}\" \n        for region in self.brain_regions\n        for i in range(self.nr_channels_per_region)\n                   ]\n\n    return channel_list\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_spike_trains","title":"save_spike_trains","text":"<pre><code>save_spike_trains()\n</code></pre> <p>Save generated spike trains and amplitudes as <code>.npy</code> files.</p> Writes <p><code>spiking_data/CSC{channel}_{TYPE}{idx}.npy</code> under the session directory. Each file contains a dict with keys:</p> <ul> <li><code>\"spike_times\"</code>: Unix epoch ms (1D array)</li> <li><code>\"spike_amps\"</code>: waveform amplitudes, shape <code>(n_spikes, 64)</code></li> </ul> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_spike_trains(self) -&gt; None:\n    \"\"\"Save generated spike trains and amplitudes as ``.npy`` files.\n\n    Writes:\n        ``spiking_data/CSC{channel}_{TYPE}{idx}.npy`` under the session\n        directory. Each file contains a dict with keys:\n\n        - ``\"spike_times\"``: Unix epoch **ms** (1D array)\n        - ``\"spike_amps\"``: waveform amplitudes, shape ``(n_spikes, 64)``\n    \"\"\"\n    save_dir = self.format_save_dir(subdir=\"spiking_data\")\n\n    i = 0\n    for csc, unit_types in self.channel_dict.items():\n        su_ct = 1\n        mu_ct = 1\n\n        for t in unit_types:\n            if t == \"SU\":\n                unit_counter = su_ct\n                su_ct += 1\n            elif t == \"MU\":\n                unit_counter = mu_ct\n                mu_ct += 1\n\n            save_dict = {\n                \"spike_times\": self.spike_times[i], \n                \"spike_amps\": self.spike_amps[i]\n            }\n\n            filename = f\"CSC{csc}_{t}{unit_counter}.npy\"\n            np.save(save_dir / filename, save_dict)\n            i += 1\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_lfp_data","title":"save_lfp_data","text":"<pre><code>save_lfp_data()\n</code></pre> <p>Generate and save the LFP channel as <code>CSC1_lfp.npy</code>.</p> Writes <p><code>lfp_data/CSC1_lfp.npy</code> containing a dict with:</p> <ul> <li><code>\"ts\"</code>: timestamps (Unix epoch ms)</li> <li><code>\"samples\"</code>: LFP-like samples at 1 kHz</li> </ul> Notes <p>Only one LFP channel is generated due to the size of each channel.  A single channel suffices for demonstration purposes. If you include field potential data, consider using a large-storage backend.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_lfp_data(self) -&gt; None:\n    \"\"\"Generate and save the LFP channel as ``CSC1_lfp.npy``.\n\n    Writes:\n        ``lfp_data/CSC1_lfp.npy`` containing a dict with:\n\n        - ``\"ts\"``: timestamps (Unix epoch **ms**)\n        - ``\"samples\"``: LFP-like samples at 1 kHz\n\n    Notes: \n        Only one LFP channel is generated due to the size of each channel. \n        A single channel suffices for demonstration purposes.\n        If you include field potential data, consider using a large-storage backend.\n    \"\"\"\n    save_dir = self.format_save_dir(subdir=\"lfp_data\")\n\n    ts, samples = self.generate_lfp_channel()\n\n    filename = f\"CSC1_lfp.npy\"\n    np.save(save_dir / filename, {\"ts\": ts, \"samples\": samples})\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_channel_names","title":"save_channel_names","text":"<pre><code>save_channel_names()\n</code></pre> <p>Save <code>ChannelNames.txt</code> listing channel names one per line.</p> Writes <p><code>ChannelNames.txt</code> in the session root. Each line ends with <code>.ncs</code> (e.g., <code>LA1.ncs</code>).</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_channel_names(self) -&gt; None:\n    \"\"\"Save ``ChannelNames.txt`` listing channel names one per line.\n\n    Writes:\n        ``ChannelNames.txt`` in the session root. Each line ends with\n        ``.ncs`` (e.g., ``LA1.ncs``).\n    \"\"\"        \n    save_dir = self.format_save_dir()\n\n    channel_names = self.generate_channel_list()\n\n    file = save_dir / \"ChannelNames.txt\"\n    f1 = open(file, \"w+\")\n    for csc_name in channel_names:\n        f1.write(f\"{csc_name}.ncs\\n\")\n    f1.close()\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_session_info","title":"save_session_info","text":"<pre><code>save_session_info()\n</code></pre> <p>Save a <code>session_info.npy</code> dictionary.</p> Writes <p><code>session_info.npy</code> containing a dict with <code>patient_id</code>, <code>session_nr</code>, <code>date</code>, and <code>time</code> (UTC).</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_session_info(self) -&gt; None:\n    \"\"\"Save a ``session_info.npy`` dictionary.\n\n    Writes:\n        ``session_info.npy`` containing a dict with\n        ``patient_id``, ``session_nr``, ``date``, and ``time`` (UTC).\n    \"\"\"\n    save_dir = self.format_save_dir()\n\n    date, time = self.datetime.split(\"_\")\n    session_info = {\n        \"patient_id\": self.patient_id,\n        \"session_nr\": self.session_nr,\n        \"date\": date, \n        \"time\": time\n    }\n    np.save(save_dir / \"session_info.npy\", session_info)\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_pings","title":"generate_pings","text":"<pre><code>generate_pings()\n</code></pre> <p>Create a repeating event-code tile.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: 1D integer array of length <code>len_context_files</code> with</p> <code>ndarray</code> <p>elements tiled from <code>[1, 2, 4, 8, 16, 32, 64, 128]</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_pings(self) -&gt; np.ndarray:\n    \"\"\"Create a repeating event-code tile.\n\n    Returns:\n        np.ndarray: 1D integer array of length ``len_context_files`` with\n        elements tiled from ``[1, 2, 4, 8, 16, 32, 64, 128]``.\n    \"\"\"\n    # recreate pings\n    if self.len_context_files % 8 == 0:\n        reps = int(self.len_context_files / 8)\n    else:\n        reps = int(self.len_context_files / 8) + 1\n\n    signal_tile = np.tile([1,2,4,8,16,32,64,128], reps)\n    signal_tile = signal_tile[:self.len_context_files]\n\n    return signal_tile\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_events","title":"generate_events","text":"<pre><code>generate_events()\n</code></pre> <p>Generate mock event timestamps and (timestamp, code) matrix.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: - <code>events</code>: 1D float array of Unix epoch ms timestamps. - <code>events_mat</code>: 2D array with rows <code>(timestamp_ms, code)</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_events(self) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Generate mock event timestamps and (timestamp, code) matrix.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]:\n            - ``events``: 1D float array of Unix epoch **ms** timestamps.\n            - ``events_mat``: 2D array with rows ``(timestamp_ms, code)``.\n    \"\"\"\n\n    # recreate event timestamps\n    events = np.linspace(self.rectime_on, self.rectime_off, num=self.len_context_files)\n    events_mat = np.array(list(zip(events, self.signal_tile)))\n\n    return events, events_mat\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_events","title":"save_events","text":"<pre><code>save_events()\n</code></pre> <p>Save generated events to <code>event_file/Events.npy</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_events(self) -&gt; None:\n    \"\"\"Save generated events to ``event_file/Events.npy``.\"\"\"\n\n    events, events_mat = self.generate_events()\n\n    save_dir = self.format_save_dir(subdir=\"event_file\")\n\n    ev_name = save_dir / \"Events.npy\"\n\n    np.save(ev_name, events_mat)\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_stimulus_onsets","title":"generate_stimulus_onsets","text":"<pre><code>generate_stimulus_onsets()\n</code></pre> <p>Generate approximate onset and offset timestamps for the stimulus.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: <code>(stim_on_time, stim_off_time)</code> in Unix epoch \u00b5s.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_stimulus_onsets(self) -&gt; Tuple[int, int]:\n    \"\"\"Generate approximate onset and offset timestamps for the stimulus.\n\n    Returns:\n        Tuple[int, int]: ``(stim_on_time, stim_off_time)`` in Unix epoch **\u00b5s**.\n    \"\"\"\n\n    # generate projected end time for the DAQ log, in unix time microseconds\n    # movie_len_unix = (stimulus_len * 60 * 1000 * 1000)       \n    stim_on_time = (self.rectime_on + random.randint(120000, 180000)) * 1000\n    stim_off_time = (stim_on_time + (self.stimulus_len * 60 * 1000)) * 1000\n\n    return stim_on_time, stim_off_time\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.seed_and_interval","title":"seed_and_interval","text":"<pre><code>seed_and_interval()\n</code></pre> <p>Compute DAQ interval and initial seed time for log synthesis.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: <code>(interval_us, seed_time_us)</code> in microseconds.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def seed_and_interval(self) -&gt; Tuple[int, int]:\n    \"\"\"Compute DAQ interval and initial seed time for log synthesis.\n\n    Returns:\n        Tuple[int, int]: ``(interval_us, seed_time_us)`` in **microseconds**.\n    \"\"\"\n\n    add_interval = int((self.stim_off_time) / self.len_context_files)\n    seed = int(self.stim_on_time + add_interval * 1.25)\n    return add_interval, seed\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_daq_log","title":"generate_daq_log","text":"<pre><code>generate_daq_log()\n</code></pre> <p>Generate DAQ log entries.</p> <p>Each entry is a tuple <code>(code, idx, pre_us, post_us)</code>.</p> <p>Returns:</p> Type Description <code>List[Tuple[int, int, int, int]]</code> <p>List[Tuple[int, int, int, int]]: DAQ log with one row per event.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_daq_log(self) -&gt; List[Tuple[int, int, int, int]]:\n    \"\"\"Generate DAQ log entries.\n\n    Each entry is a tuple ``(code, idx, pre_us, post_us)``.\n\n    Returns:\n        List[Tuple[int, int, int, int]]: DAQ log with one row per event.\n    \"\"\"\n    add_interval, seed = self.seed_and_interval()\n\n    pre = []\n    post = []\n\n    for i in range(self.len_context_files):\n        interval_diff = (np.random.normal(1000, 200) / 2)\n\n        pre.append(int(seed - interval_diff))\n        post.append(int(seed + interval_diff))\n        seed += add_interval \n\n    return list(zip(self.signal_tile, np.arange(self.len_context_files), pre, post))\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_daq_log","title":"save_daq_log","text":"<pre><code>save_daq_log()\n</code></pre> <p>Save the generated DAQ log as a text file in <code>daq_files</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_daq_log(self) -&gt; None:\n    \"\"\"Save the generated DAQ log as a text file in ``daq_files``.\"\"\"\n\n    log_lines = self.generate_daq_log()\n\n    save_dir = self.format_save_dir(subdir=\"daq_files\")\n    log_loc = save_dir / f\"timedDAQ-log-{self.datetime}.log\"\n\n    with open(log_loc, 'a') as file:\n        file.write(\"Initial signature: 255\t255\\n255\\t255\\t\\ndata\\tStamp\\tpre\\tpost\\n\")\n        for datum in log_lines:\n            file.write(\"{}\\t{}\\t{}\\t{}\\n\".format(datum[0], datum[1], datum[2], datum[3]))\n        file.close()\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.generate_perfect_watchlog","title":"generate_perfect_watchlog","text":"<pre><code>generate_perfect_watchlog()\n</code></pre> <p>Generate watchlog without pauses or skips.</p> <p>Returns:</p> Type Description <code>Tuple[int, List[float], List[int]]</code> <p>Tuple[int, List[float], List[int]]: - <code>nr_movie_frames</code>: Number of frames (\u2248 stimulus_len / 0.04s). - <code>perfect_pts</code>: PTS values (seconds), 0.04 s increments. - <code>cpu_time</code>: Corresponding Unix epoch \u00b5s timestamps.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def generate_perfect_watchlog(self) -&gt; Tuple[int, List[float], List[int]]:\n    \"\"\"Generate watchlog without pauses or skips.\n\n    Returns:\n        Tuple[int, List[float], List[int]]:\n            - ``nr_movie_frames``: Number of frames (\u2248 stimulus_len / 0.04s).\n            - ``perfect_pts``: PTS values (seconds), 0.04 s increments.\n            - ``cpu_time``: Corresponding Unix epoch **\u00b5s** timestamps.\n    \"\"\"\n\n    _, seed = self.seed_and_interval()\n\n    nr_movie_frames = int(self.stimulus_len * 60 / 0.04)\n    perfect_pts = [round((x * 0.04), 2) for x in range(1, nr_movie_frames+1)] \n\n    cpu_time = []\n    for i in range(nr_movie_frames):\n        seed += 41000\n        cpu_time.append(seed)\n\n    return nr_movie_frames, perfect_pts, cpu_time\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_perfect_watchlog","title":"save_perfect_watchlog","text":"<pre><code>save_perfect_watchlog()\n</code></pre> <p>Write a perfect (no pauses/skips) watchlog to <code>watchlogs</code>.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_perfect_watchlog(self) -&gt; None:\n    \"\"\"Write a perfect (no pauses/skips) watchlog to ``watchlogs``.\"\"\"\n    nr_movie_frames, perfect_pts, cpu_time = self.generate_perfect_watchlog()\n\n    save_dir = self.format_save_dir(subdir=\"watchlogs\")\n\n    wl_name = f\"ffplay-watchlog-{self.datetime}.log\"\n\n    with open(save_dir / wl_name, 'a') as file:\n        file.write(\"movie_stimulus.avi\\n\")\n        for i in range(nr_movie_frames):\n            file.write(\"pts\\t{}\\ttime\\t{}\\n\".format(perfect_pts[i], cpu_time[i]))\n        file.close()\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.make_pauses_and_skips","title":"make_pauses_and_skips","text":"<pre><code>make_pauses_and_skips()\n</code></pre> <p>Generate a watchlog with pauses and skips.</p> <p>Returns:</p> Type Description <code>Tuple[int, List[float], List[int], List[int]]</code> <p>Tuple[int, List[float], List[int], List[int]]: - <code>nr_movie_frames</code>: Number of frames. - <code>pts</code>: PTS values (seconds) after inserting skips. - <code>cpu_time</code>: Unix epoch \u00b5s timestamps per frame. - <code>indices_pause</code>: Frame indices at which a pause occurred.</p> Notes <p>Pause lengths and skip magnitudes are randomized. PTS values are clamped to the movie duration and non-negative.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def make_pauses_and_skips(self) -&gt; Tuple[int, List[float], List[int], List[int]]:\n    \"\"\"Generate a watchlog with pauses and skips.\n\n    Returns:\n        Tuple[int, List[float], List[int], List[int]]:\n            - ``nr_movie_frames``: Number of frames.\n            - ``pts``: PTS values (seconds) after inserting skips.\n            - ``cpu_time``: Unix epoch **\u00b5s** timestamps per frame.\n            - ``indices_pause``: Frame indices at which a pause occurred.\n\n    Notes:\n        Pause lengths and skip magnitudes are randomized. PTS values are\n        clamped to the movie duration and non-negative.\n    \"\"\"\n    nr_movie_frames, perfect_pts, cpu_time = self.generate_perfect_watchlog()\n    _, seed = self.seed_and_interval()\n    pause_pool = 1 * 1000 * 1000 * 60 # 5 minutes in unix/epoch time -- use for max pause time        movie_len_unix = (self.stimulus_len * 60 * 1000 * 1000) - pause_pool\n\n    movie_len_unix = (self.stimulus_len * 60 * 1000 * 1000) - pause_pool\n    end_time = seed + movie_len_unix \n    add_interval = int((end_time - seed) / nr_movie_frames)\n\n    cpu_time = []\n    for i in range(nr_movie_frames):\n        seed += add_interval\n        cpu_time.append(int(seed))   \n\n    nr_pauses = int(uniform(1,3))\n    min_pause = 0.1 * 1000 * 1000 * 60\n\n    indices_pause = random.sample(range(len(cpu_time) - 5000), nr_pauses)\n\n    cpu_time = np.array(cpu_time)\n\n    for i, index in enumerate(indices_pause): \n        if (len(indices_pause) - i) &gt; 0: \n            pause_len = random.randint(int(min_pause), pause_pool)\n            cpu_time = np.concatenate((cpu_time[:index],cpu_time[index:] + pause_len)) \n            pause_pool -= pause_len\n        else:\n            pause_len = pause_pool\n            cpu_time = np.concatenate((cpu_time[:index],cpu_time[index:] + pause_len))\n\n        # randomly select indices from perfect watchlog \n        nr_skips = int(uniform(1,4))\n\n        indices_skip = random.sample(range(len(perfect_pts) - 5000), nr_skips)\n\n        skip_pts = np.array(copy.copy(perfect_pts))\n\n        max_skip = 500\n\n        for i, index in enumerate(indices_skip): \n            # note: careful about values here -- can exceed mocked movie length. \n            # currently set so that the max possible skip is the penultimate frame\n            if len(indices_skip) &gt; 1:\n                skip_len = int(uniform((max_skip * -1), max_skip))\n                skip_pts = np.concatenate((skip_pts[:index],skip_pts[index:] + skip_len)) \n                max_skip -= skip_len\n\n            if len(indices_skip) == 1:\n                skip_len = max_skip\n                skip_pts = np.concatenate((skip_pts[:index],skip_pts[index:] + skip_len)) \n\n        # test for rounding issue\n        skip_pts = [round(frame, 2) for frame in skip_pts]\n\n        # prevents generated frame from exceeding the mock movie length\n        skip_pts_revised = []\n        for i, frame in enumerate(skip_pts):\n            if frame &gt; (nr_movie_frames * 0.04):\n                skip_pts_revised.append(nr_movie_frames * 0.04)\n            if frame &lt;= (nr_movie_frames * 0.04):\n                skip_pts_revised.append(frame)\n            if frame &lt; 0: \n                skip_pts_revised.append(0.0)\n\n\n    return nr_movie_frames, skip_pts_revised, cpu_time, indices_pause\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.GenerateData.save_watchlog_with_artifacts","title":"save_watchlog_with_artifacts","text":"<pre><code>save_watchlog_with_artifacts()\n</code></pre> <p>Save a watchlog including pauses and skips to <code>watchlogs</code> dir.</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def save_watchlog_with_artifacts(self) -&gt; None:\n    \"\"\"Save a watchlog including pauses and skips to ``watchlogs`` dir.\"\"\"\n    nr_movie_frames, skip_pts_revised, cpu_time, indices_pause = self.make_pauses_and_skips()\n\n    # save\n    save_dir = self.format_save_dir(subdir=\"watchlogs\")\n    wl_name = f\"ffplay-watchlog-{self.datetime}.log\"\n\n    with open(save_dir / wl_name, 'a') as file:\n        file.write(\"movie_stimulus.avi\\n\")\n        for i in range(nr_movie_frames):\n            if i not in indices_pause:\n                file.write(\"pts\\t{}\\ttime\\t{}\\n\".format(skip_pts_revised[i], cpu_time[i]))\n            if i in indices_pause: \n                file.write(\"Pausing\\nContinuing\\tafter\\tpause\\n\")\n\n    file.close()\n</code></pre>"},{"location":"reference/data/#epiphyte.data.mock_data_utils.run_data_generation","title":"run_data_generation","text":"<pre><code>run_data_generation()\n</code></pre> <p>Populate a small mock dataset and minimal annotation arrays.</p> <p>Iterates through hard-coded <code>patients</code> and <code>sessions</code> and, for each (patient, session) pair, uses :class:<code>GenerateData</code> to synthesize and write: session info, spike trains, an LFP-like channel, channel-name list, events, a DAQ log, and a watchlog with artifacts. After data generation, it also writes a few toy annotation arrays into <code>PATH_TO_LABELS</code>.</p> Steps <ol> <li>For each patient/session:</li> <li>Print a short summary (:meth:<code>GenerateData.summarize</code>).</li> <li>Save <code>session_info.npy</code>.</li> <li>Save spike trains (<code>spiking_data/*.npy</code>).</li> <li>Save LFP data (<code>lfp_data/CSC1_lfp.npy</code>).</li> <li>Save channel names (<code>ChannelNames.txt</code>).</li> <li>Save events (<code>event_file/Events.npy</code>).</li> <li>Save DAQ log (<code>daq_files/timedDAQ-log-&lt;timestamp&gt;.log</code>).</li> <li>Save watchlog with pauses/skips (<code>watchlogs/ffplay-watchlog-&lt;timestamp&gt;.log</code>).</li> <li>Create three example <code>*.npy</code> annotation files under <code>PATH_TO_LABELS</code>, with filenames including a random <code>annotator_id</code> and the current date.</li> </ol> Writes <ul> <li>Under <code>{PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/</code>:<ul> <li><code>session_info.npy</code></li> <li><code>ChannelNames.txt</code></li> <li><code>spiking_data/CSC{channel}_{MU|SU}{idx}.npy</code></li> <li><code>lfp_data/CSC1_lfp.npy</code></li> <li><code>event_file/Events.npy</code></li> <li><code>daq_files/timedDAQ-log-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log</code></li> <li><code>watchlogs/ffplay-watchlog-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log</code></li> </ul> </li> <li>Under <code>{PATH_TO_LABELS}/</code>:<ul> <li><code>1_character1_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy</code></li> <li><code>2_character2_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy</code></li> <li><code>3_location1_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy</code></li> </ul> </li> </ul> Notes <ul> <li>Relies on configuration/constants imported elsewhere: <code>PATH_TO_DATA</code>, <code>PATH_TO_LABELS</code>, and <code>annotators</code>.</li> <li>Data are randomized on each run; for reproducibility, set seeds in both <code>random</code> and <code>numpy.random</code> before calling.</li> <li>Time bases follow the conventions used in :class:<code>GenerateData</code> (e.g., spike/event timestamps in ms, some logs in \u00b5s).</li> </ul> <p>Returns:</p> Type Description <code>None</code> <p>None</p> Example <p>run_data_generation()</p> Source code in <code>epiphyte/data/mock_data_utils.py</code> <pre><code>def run_data_generation() -&gt; None:\n    \"\"\"Populate a small mock dataset and minimal annotation arrays.\n\n    Iterates through hard-coded ``patients`` and ``sessions`` and, for each\n    (patient, session) pair, uses :class:`GenerateData` to synthesize and write:\n    session info, spike trains, an LFP-like channel, channel-name list, events,\n    a DAQ log, and a watchlog with artifacts. After data generation, it also\n    writes a few toy annotation arrays into ``PATH_TO_LABELS``.\n\n    Steps:\n        1. For each patient/session:\n        - Print a short summary (:meth:`GenerateData.summarize`).\n        - Save ``session_info.npy``.\n        - Save spike trains (``spiking_data/*.npy``).\n        - Save LFP data (``lfp_data/CSC1_lfp.npy``).\n        - Save channel names (``ChannelNames.txt``).\n        - Save events (``event_file/Events.npy``).\n        - Save DAQ log (``daq_files/timedDAQ-log-&lt;timestamp&gt;.log``).\n        - Save watchlog with pauses/skips (``watchlogs/ffplay-watchlog-&lt;timestamp&gt;.log``).\n        2. Create three example ``*.npy`` annotation files under ``PATH_TO_LABELS``,\n        with filenames including a random ``annotator_id`` and the current date.\n\n    Writes:\n        - Under ``{PATH_TO_DATA}/patient_data/{patient_id}/session_{session_nr}/``:\n            * ``session_info.npy``\n            * ``ChannelNames.txt``\n            * ``spiking_data/CSC{channel}_{MU|SU}{idx}.npy``\n            * ``lfp_data/CSC1_lfp.npy``\n            * ``event_file/Events.npy``\n            * ``daq_files/timedDAQ-log-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log``\n            * ``watchlogs/ffplay-watchlog-&lt;YYYY-mm-dd_HH-MM-SS&gt;.log``\n        - Under ``{PATH_TO_LABELS}/``:\n            * ``1_character1_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy``\n            * ``2_character2_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy``\n            * ``3_location1_&lt;annotator_id&gt;_&lt;YYYYMMDD&gt;_character.npy``\n\n    Notes:\n        - Relies on configuration/constants imported elsewhere:\n        ``PATH_TO_DATA``, ``PATH_TO_LABELS``, and ``annotators``.\n        - Data are randomized on each run; for reproducibility, set seeds in both\n        ``random`` and ``numpy.random`` before calling.\n        - Time bases follow the conventions used in :class:`GenerateData`\n        (e.g., spike/event timestamps in ms, some logs in \u00b5s).\n\n    Returns:\n        None\n\n    Example:\n        run_data_generation()\n    \"\"\"\n\n    patients = [1,2,3]\n    sessions = [[1], [1, 2], [1]]\n\n    print(f\"Generating patient data for {len(patients)} 'patients'..\")\n    for patient_id, patient_sessions in zip(patients, sessions):\n\n        for session_nr in patient_sessions:\n\n            print(f\"patient {patient_id}, session {session_nr}\")\n\n            pat_neural_data = GenerateData(patient_id, session_nr)\n            pat_neural_data.summarize()\n            pat_neural_data.save_session_info()\n\n            pat_neural_data.save_spike_trains()\n            pat_neural_data.save_lfp_data()\n\n            pat_neural_data.save_channel_names()\n            pat_neural_data.save_events()\n            pat_neural_data.save_daq_log()\n            pat_neural_data.save_watchlog_with_artifacts()\n\n    print(\"Generating movie annotations..\")\n\n    annotator_ids = []\n    for i in range(len(annotators)):\n        annotator_ids.append(annotators[i]['annotator_id'])\n\n    path = Path(PATH_TO_LABELS)\n    path.mkdir(parents=True, exist_ok=True)\n\n    start_times_1 = [0, 5000.04, 7000.04, 12000.04]\n    stop_times_1 = [5000,7000,12000,12575]\n    values_1 = [1,0,1,0]\n    character1 = np.array([values_1, start_times_1, stop_times_1]) \n    np.save(path / f\"1_character1_{random.choice(annotator_ids)}_{datetime.now().strftime('%Y%m%d')}_character.npy\", character1)\n\n    start_times_2 = [0, 400.04, 4000.04, 10000.04, 10500.04]\n    stop_times_2 = [400,4000,10000,10500,12575]\n    values_2 = [0,1,0,1,0]\n    character2 = np.array([values_2, start_times_2, stop_times_2]) \n    np.save(path / f\"2_character2_{random.choice(annotator_ids)}_{datetime.now().strftime('%Y%m%d')}_character.npy\", character2)\n\n    start_times_3 = [0, 100.04, 500.04]\n    stop_times_3 = [100, 500, 12575]\n    values_3 = [0,1,0]\n    location1 = np.array([values_3, start_times_3, stop_times_3]) \n    np.save(path / f\"3_location1_{random.choice(annotator_ids)}_{datetime.now().strftime('%Y%m%d')}_character.npy\", location1)\n</code></pre>"},{"location":"reference/database/","title":"Database","text":""},{"location":"reference/database/#epiphyte.database","title":"epiphyte.database","text":""},{"location":"reference/database/#epiphyte.database.access_info","title":"access_info","text":"<p>Database connection and storage configuration for Epiphyte.</p> <p>This module sets up the DataJoint connection parameters and storage settings. The module is imported by the <code>db_setup.py</code> script to connect to the local or remote database.</p>"},{"location":"reference/database/#epiphyte.database.config","title":"config","text":"<p>Hard-coded variables for initializing the database.</p> <p>This modules defines the paths and variables used to initialize the mock database.</p> <p>Paths: </p> <ul> <li><code>PATH_TO_REPO</code>: Path to the root of the repository.</li> <li><code>PATH_TO_DATA</code>: Path to the folder containing the mock data.</li> <li><code>PATH_TO_LABELS</code>: Path to the folder containing the movie annotations.</li> <li><code>PATH_PATIENT_ALIGNED_LABELS</code>: Path to the folder containing the patient-aligned annotations.</li> <li><code>PATH_TO_PATIENT_DATA</code>: Path to the folder containing the refractored mock patient data.</li> <li><code>PATH_TO_SESSION_DATA</code>: Path to the folder containing the refractored mock session data.</li> </ul> <p>Variables:</p> <ul> <li><code>PTS_MOVIE_new</code>: List of time points for the movie, sampled at 25 Hz (0.04s intervals).</li> <li><code>patients</code>: List of dictionaries, each containing information about a patient (id, age, gender, year).    </li> <li><code>sessions</code>: List of dictionaries, each containing information about a session (patient_id, session_nr, session_type).</li> <li><code>annotators</code>: List of dictionaries, each containing information about an annotator (id, first_name, last_name).</li> <li><code>label_names</code>: List of label names used in the annotations.</li> </ul>"},{"location":"reference/database/#epiphyte.database.db_setup","title":"db_setup","text":"<p>DataJoint tables and population helpers for the mock database.</p> <p>This module defines DataJoint schemas and tables used to represent patients, sessions, events, annotations, spikes, and derived entities used throughout the tutorials. </p> <p>Methods for populating the tables are included as class methods. Tables are populating using the mock data generated in <code>epiphyte.data.mock_data_utils</code>.</p> Conventions <ul> <li>Tables are defined according to the order of population, with the most top-level tables first, followed by tables which pull keys from those tables.</li> <li>The method of populating a table varies by table type and content. For <code>Imported</code> tables, the population function is class method. For <code>Manual</code> tables, the population method is defined separately.</li> </ul>"},{"location":"reference/database/#epiphyte.database.db_setup.Patients","title":"Patients","text":"<p>               Bases: <code>Lookup</code></p> <p>Table containing patient demographics.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass Patients(dj.Lookup):\n    \"\"\"Table containing patient demographics.\"\"\"\n    definition = \"\"\"\n    # general patient data, imported from config file\n    patient_id: int                                    # patient ID\n    ---\n    age: smallint                                      # age of patient\n    gender: enum('f', 'm', 'x')                        # gender of patient\n    year: int                                          # year of surgery\n    \"\"\"\n\n    contents = config.patients\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.Sessions","title":"Sessions","text":"<p>               Bases: <code>Lookup</code></p> <p>Table containing recording session metadata per patient.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass Sessions(dj.Lookup):\n    \"\"\"Table containing recording session metadata per patient.\"\"\"\n    definition = \"\"\"\n    # general session data, imported from config file\n    patient_id: int                                    # patient ID\n    session_nr: int                                    # session number\n    ---\n    session_type: enum('full_movie', 'follow_up', 'partial_movie')   # type of session for corresponding recording\n    \"\"\"\n\n    contents = config.sessions\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.Annotator","title":"Annotator","text":"<p>               Bases: <code>Lookup</code></p> <p>Table containing annotators who labeled movie content and events.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass Annotator(dj.Lookup):\n    \"\"\"Table containing annotators who labeled movie content and events.\"\"\"\n    definition = \"\"\"\n    # annatotors of the video, imported from config file\n    annotator_id: varchar(5)                    # unique ID for each annotator\n    ---\n    first_name: varchar(32)                      # first name of annotator\n    last_name: varchar(32)                       # last name of annotator\n    \"\"\"\n\n    contents = config.annotators\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.LabelName","title":"LabelName","text":"<p>               Bases: <code>Lookup</code></p> <p>Table containing the name of labelled content.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass LabelName(dj.Lookup):\n    \"\"\"Table containing the name of labelled content.\"\"\"\n    definition = \"\"\"\n    # names of existing labels, imported from config file\n    label_name: varchar(32)   # label name\n    \"\"\"\n\n    contents = config.label_names\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.MovieSession","title":"MovieSession","text":"<p>               Bases: <code>Imported</code></p> <p>Table containing the session-wise movie timing and channel metadata.</p> <p>Populates from watchlogs, DAQ logs, and event files under the session directory. Stores PTS, DTS, neural recording time, and channel names.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass MovieSession(dj.Imported):\n    \"\"\"Table containing the session-wise movie timing and channel metadata.\n\n    Populates from watchlogs, DAQ logs, and event files under the session\n    directory. Stores PTS, DTS, neural recording time, and channel names.\n    \"\"\"\n    definition = \"\"\"\n    # data of individual movie watching sessions\n    -&gt; Patients                          # patient ID\n    -&gt; Sessions                          # session ID\n    ---\n    date : date                         # date of movie session\n    time : time\n    pts: longblob                       # order of movie frames for patient (pts) \n    dts: longblob                       # cpu time stamps (dts)\n    neural_recording_time: longblob     # neural recording time (rectime)\n    channel_names: longblob             # channel name, indicating electrode number and brain region\n    \"\"\"\n\n    def _make_tuples(self, key):\n        \"\"\"Populate the MovieSession table from the session files of each patient.\"\"\"\n        patient_ids = Patients.fetch(\"patient_id\")       \n\n        for _, pat in enumerate(patient_ids):\n\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")       \n\n            try:\n                checks = (MovieSession &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n                if len(checks) == len(pat_sessions):\n                    print(checks)\n                    print(len(checks), len(pat_sessions))\n                    continue\n                else:\n                    print(f\"Adding patient {pat} to database...\")\n                    pass\n            except:\n                print(f\"Adding patient {pat} to database...\")\n                pass\n\n            for _, sesh in enumerate(pat_sessions):\n\n                try:\n                    check = len((MovieSession &amp; f\"patient_id={1}\" &amp; f\"session_nr={1}\").fetch(\"pts\")[0])\n                    if check &gt; 0:\n                        print(f\"Adding patient {pat} to database...\")\n                        pass\n                    else:\n                        continue\n                except:\n                    print(f\"Adding patient {pat} to database...\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n                pts, rectime, dts = time_conversion.convert()\n\n                save_dir = main_patient_dir / \"movie_info\"\n                save_dir.mkdir(exist_ok=True)\n                np.save(save_dir / \"pts.npy\", pts)\n                np.save(save_dir / \"dts.npy\", dts)\n                np.save(save_dir / \"neural_rec_time.npy\", rectime)\n\n                path_channel_names = main_patient_dir / \"ChannelNames.txt\"\n                channel_names = helpers.get_channel_names(path_channel_names)\n\n                self.insert1({'patient_id': pat,\n                            'session_nr': sesh,\n                            'date': date,\n                            'time': time,\n                            'pts': pts,\n                            'dts': dts,\n                            'neural_recording_time': rectime,\n                            'channel_names': channel_names\n                            }, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.LFPData","title":"LFPData","text":"<p>               Bases: <code>Manual</code></p> <p>Table containing the local field potential-like signals from each channel.</p> <p>Populated manually using the <code>populate_lfp_data_table()</code> function.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass LFPData(dj.Manual):\n    \"\"\"Table containing the local field potential-like signals from each channel.\n\n    Populated manually using the `populate_lfp_data_table()` function.\n    \"\"\"\n    definition = \"\"\"\n    # local field potential data, by channel. \n    -&gt; Patients\n    -&gt; Sessions\n    csc_nr: int\n    ---\n    samples: longblob                # samples, in microvolts\n    timestamps: longblob             # timestamps corresponding to each sample, in ms\n    sample_rate: int                 # sample rate from the recording device\n    brain_region: varchar(8)         # brain region where unit was recorded\n    \"\"\"\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.ElectrodeUnit","title":"ElectrodeUnit","text":"<p>               Bases: <code>Imported</code></p> <p>Table containing information on the units detected per channel with type and within-channel number.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass ElectrodeUnit(dj.Imported):\n    \"\"\"Table containing information on the units detected per channel with type and within-channel number.\"\"\"\n    definition = \"\"\"\n    # Contains information about the implanted electrodes of each patient\n    -&gt; Patients                      # patient ID\n    -&gt; Sessions                      # session number\n    unit_id: int                     # unique ID for unit (for respective  patient)\n    ---\n    csc: int                         # number of CSC file\n    unit_type: enum('M', 'S', 'X')   # unit type: 'M' for Multi Unit, 'S' for Single Unit, 'X': undefined\n    unit_nr: int                     # number of unit, as there can be several multi units and single units in one CSC file\n    brain_region: varchar(8)         # brain region where unit was recorded\n    \"\"\"\n\n    def _make_tuples(self, key):\n        \"\"\"Populate by parsing spike filenames and channel names.\"\"\"\n        patient_ids = Patients.fetch(\"patient_id\")\n\n        # iterate over each patient in db\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n\n            # further iterate over each patient's sessions\n            for i_sesh, sesh in enumerate(pat_sessions):\n\n                path_channels = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n                channel_names = helpers.get_channel_names(path_channels / \"ChannelNames.txt\")\n\n                try:\n                    check = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"csc_nr\")\n                    if len(check) == len(channel_names):\n                        continue\n                    else:\n                        print(f\"    Adding patient {pat} session {sesh} to database...\")\n                        pass\n                except:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n\n                spike_dir = Path(config.PATH_TO_DATA, \"patient_data\", str(pat), f\"session_{sesh}\", \"spiking_data\")\n                spike_filepaths = list(spike_dir.iterdir())\n                spike_filenames = sorted([s.name for s in spike_filepaths], key=helpers.extract_sort_key)\n\n                for unit_id, filename in enumerate(spike_filenames):\n                    csc_nr, unit = filename[:-4].split(\"_\")\n                    csc_index = int(csc_nr[3:]) - 1\n                    print(f\"    ... Unit ID: {unit_id}, CSC #: {csc_nr}, Channel index: {csc_index}\")\n\n                    channel = channel_names[csc_index]\n                    print(f\"    ... Channel name: {channel}\")\n\n                    unit_type, unit_nr = helpers.get_unit_type_and_number(unit)\n                    print(f\"    ... Unit type: {unit_type},  Within-channel unit number: {unit_nr}\")\n\n                    self.insert1({'patient_id': pat,\n                                'session_nr': sesh,\n                                'unit_id': unit_id, \n                                'csc': csc_nr[3:], \n                                'unit_type': unit_type, \n                                'unit_nr': unit_nr,\n                                'brain_region': channel},\n                                    skip_duplicates=True)\n\n                    print(\" \")\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.MovieAnnotation","title":"MovieAnnotation","text":"<p>               Bases: <code>Imported</code></p> <p>Table containing the raw movie annotations (values and segments) per label and annotator.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass MovieAnnotation(dj.Imported):\n    \"\"\"Table containing the raw movie annotations (values and segments) per label and annotator.\"\"\"\n    definition = \"\"\"\n    # information about video annotations (e.g. labels of characters); \n    # this table contains start and end time points and values of the segments of the annotations;\n    # all time points are in Neural Recording Time;\n    -&gt; Annotator                    # creator of movie annotation\n    -&gt; LabelName                    # name of annotation\n    annotation_date: date           # date of annotation\n    ---\n    values: longblob                # list of values that represent label\n    start_times: longblob           # list of start times of label segments in movie play time (PTS)\n    stop_times: longblob            # list of stop times of label segments in movie play time (PTS)\n    category: varchar(32)           # category of label; e.g. 'character', 'emotion', 'location'\n    indicator_function: longblob    # full indicator function, one value for each movie frame\n    \"\"\"\n\n    def _make_tuples(self, key):\n        \"\"\"Populate by reading ``.npy`` annotation files from labels directory.\"\"\"\n        path_labels = Path(config.PATH_TO_LABELS)\n\n        for filepath in path_labels.iterdir():\n            label_id, label_name, annotator, date, category = filepath.name[:-4].split(\"_\")\n\n            try:\n                check = (MovieAnnotation &amp; f\"label_name='{label_name}'\" &amp; f\"category='{category}'\").fetch(\"values\")\n                if len(check) &gt; 0:\n                    continue\n                else: \n                    print(f\"    Adding {label_name}, category {category} to database...\")\n                    pass\n            except:\n                print(f\"    Adding {label_name}, category {category} to database...\")\n                pass\n\n            content = np.load(filepath)\n\n            values = np.array(content[0])\n            start_times = np.array(content[1])\n            stop_times = np.array(content[2])\n\n            ind_func = processing_labels.make_label_from_start_stop_times(values, start_times, stop_times, config.PTS_MOVIE_new)\n\n            print(f\"    ... # of occurrences: {int(sum(values))}\\n\")\n\n            self.insert1({'label_name': label_name,\n                            'annotator_id': annotator,\n                            'annotation_date': datetime.strptime(date, '%Y%m%d'),\n                            'category': category,\n                            'values': values,\n                            'start_times': start_times,\n                            'stop_times': stop_times,\n                            'indicator_function': np.array(ind_func)\n                            }, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.SpikeData","title":"SpikeData","text":"<p>               Bases: <code>Imported</code></p> <p>Table containing the spike times and amplitudes per unit in neural recording time.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass SpikeData(dj.Imported):\n    \"\"\"Table containing the spike times and amplitudes per unit in neural recording time.\"\"\"\n    definition = \"\"\"\n    # This table contains all spike times of all units of all patients in Neural Recording Time\n    # Each entry contains a vector of all spike times of one unit of one patient\n    -&gt; Sessions\n    -&gt; ElectrodeUnit                   # unit from which data was recorded\n    ---\n    spike_times: longblob              # in case bin_size is not 0: number of spikes; otherwise: times of spikes (original data)\n    spike_amps: longblob               # amplitudes for each spike in spike_times\n    \"\"\"\n\n    def _make_tuples(self, key):\n        \"\"\"Populate by loading unit spike files and matching to units.\"\"\"\n        patient_ids = Patients.fetch(\"patient_id\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n\n            for i_sesh, sesh in enumerate(pat_sessions):\n                spike_dir = Path(config.PATH_TO_DATA, \"patient_data\", str(pat), f\"session_{sesh}\", \"spiking_data\")\n                spike_files = list(spike_dir.iterdir())\n                unit_ids = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"unit_id\")\n\n                assert len(spike_files) == len(unit_ids), \"Number of units in ElectrodeUnits doesn't match number of spiking files.\"\n\n                try:\n                    check = (SpikeData &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"unit_id\")[0]\n                    if len(check) == len(spike_files) == len(unit_ids):\n                        continue\n                    else:\n                        print(f\"    Adding patient {pat} session {sesh} to database...\")\n                        pass\n                except:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n\n                for filepath in spike_files:\n                    filename = filepath.name\n                    csc_nr, unit = filename[:-4].split(\"_\")\n                    csc_nr = int(csc_nr[3:])\n                    unit_type, unit_nr = helpers.get_unit_type_and_number(unit)\n\n                    unit_id = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\" \n                            &amp; f\"csc={csc_nr}\" &amp; f\"unit_nr={unit_nr}\" &amp; f\"unit_type='{unit_type}'\").fetch(\"unit_id\")[0]\n\n                    spikes_file = np.load(filepath, allow_pickle=True)\n                    spikes_file = spikes_file.item()\n                    times = spikes_file[\"spike_times\"]\n                    amps = spikes_file[\"spike_amps\"]\n\n                    print(f\"    ... Unit ID: {unit_id}, CSC #: {csc_nr}\")\n                    print(f\"    ... Nm. of spikes: {len(times)}\")\n                    print(f\"    ... Max amp.: {np.max(amps)} microV\\n\")\n\n                    self.insert1({'patient_id': pat, \n                                'session_nr': sesh, \n                                'unit_id': unit_id,\n                                'spike_times': times, \n                                'spike_amps': amps}, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.PatientAlignedMovieAnnotation","title":"PatientAlignedMovieAnnotation","text":"<p>               Bases: <code>Computed</code></p> <p>Table containing annotations aligned to individual patient PTS and neural time.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass PatientAlignedMovieAnnotation(dj.Computed):\n    \"\"\"Table containing annotations aligned to individual patient PTS and neural time.\"\"\"\n    definition = \"\"\"\n    # Movie Annotations aligned to patient time / time points are in neural recording time\n    -&gt; MovieSession        # movie watching session ID\n    -&gt; MovieAnnotation     # label\n    ---\n    label_in_patient_time: longblob    # label matched to patient time (pts)\n    values: longblob       # list of values that represent label\n    start_times: longblob  # list of start times of label segments in neural recording time\n    stop_times: longblob   # list of stop times of label segments in neural recording time\n    \"\"\"\n\n    def make(self, key):\n        \"\"\"Align indicator to PTS and derive start/stop in neural time.\"\"\"\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n        entries = (MovieAnnotation).fetch('KEY')\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                print(f\"Patient {pat} session {sesh}..\")\n\n                for entry in entries:\n\n                    annotator_id = entry[\"annotator_id\"]\n                    label_name = entry[\"label_name\"]\n                    annotation_date = entry[\"annotation_date\"]\n\n                    try:\n                        check = (PatientAlignedMovieAnnotation &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\"\n                                    &amp; f\"label_name='{label_name}'\" &amp; f\"annotator_id='{annotator_id}'\").fetch(\"values\")\n                        if check.any():\n                            print(f\"    ... {label_name} already in database.\")\n                            continue\n                        else:\n                            print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                            pass\n                    except:\n                        print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                        pass\n\n                    patient_pts = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"pts\")[0]\n                    neural_rectime = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"neural_recording_time\")[0]\n\n                    default_label = (MovieAnnotation &amp; f\"annotator_id='{annotator_id}'\" &amp; f\"label_name='{label_name}'\").fetch(\"indicator_function\")[0]\n                    patient_aligned_label = match_label_to_patient_pts_time(default_label, patient_pts)\n                    values, starts, stops = create_vectors_from_time_points.get_start_stop_times_from_label(neural_rectime, \n                                                                                            patient_aligned_label)\n\n                    self.insert1({'patient_id': pat,\n                                    'session_nr': sesh,\n                                    'annotator_id': annotator_id,\n                                    'label_name': label_name,\n                                    'annotation_date': annotation_date,\n                                    'label_in_patient_time': np.array(patient_aligned_label),\n                                    'values': np.array(values),\n                                    'start_times': np.array(starts),\n                                    'stop_times': np.array(stops),\n                                    }, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.PatientAlignedMovieAnnotation.make","title":"make","text":"<pre><code>make(key)\n</code></pre> <p>Align indicator to PTS and derive start/stop in neural time.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>def make(self, key):\n    \"\"\"Align indicator to PTS and derive start/stop in neural time.\"\"\"\n    patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n    entries = (MovieAnnotation).fetch('KEY')\n\n    for i_pat, pat in enumerate(patient_ids):\n        pat_sessions = session_nrs[i_pat]\n        for i_sesh, sesh in enumerate([pat_sessions]):\n\n            print(f\"Patient {pat} session {sesh}..\")\n\n            for entry in entries:\n\n                annotator_id = entry[\"annotator_id\"]\n                label_name = entry[\"label_name\"]\n                annotation_date = entry[\"annotation_date\"]\n\n                try:\n                    check = (PatientAlignedMovieAnnotation &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\"\n                                &amp; f\"label_name='{label_name}'\" &amp; f\"annotator_id='{annotator_id}'\").fetch(\"values\")\n                    if check.any():\n                        print(f\"    ... {label_name} already in database.\")\n                        continue\n                    else:\n                        print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                        pass\n                except:\n                    print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                    pass\n\n                patient_pts = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"pts\")[0]\n                neural_rectime = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"neural_recording_time\")[0]\n\n                default_label = (MovieAnnotation &amp; f\"annotator_id='{annotator_id}'\" &amp; f\"label_name='{label_name}'\").fetch(\"indicator_function\")[0]\n                patient_aligned_label = match_label_to_patient_pts_time(default_label, patient_pts)\n                values, starts, stops = create_vectors_from_time_points.get_start_stop_times_from_label(neural_rectime, \n                                                                                        patient_aligned_label)\n\n                self.insert1({'patient_id': pat,\n                                'session_nr': sesh,\n                                'annotator_id': annotator_id,\n                                'label_name': label_name,\n                                'annotation_date': annotation_date,\n                                'label_in_patient_time': np.array(patient_aligned_label),\n                                'values': np.array(values),\n                                'start_times': np.array(starts),\n                                'stop_times': np.array(stops),\n                                }, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.MovieSkips","title":"MovieSkips","text":"<p>               Bases: <code>Computed</code></p> <p>Table containing information on segments of continuous vs. non-continuous movie watching.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass MovieSkips(dj.Computed):\n    \"\"\"Table containing information on segments of continuous vs. non-continuous movie watching.\"\"\"\n    definition = \"\"\"\n    # This table Contains start and stop time points, where the watching behaviour of the patient changed from \n    # continuous (watching the movie in the correct frame order) to non-continuous (e.g. jumping through the movie) or \n    # the other way round;\n    # all time points are in Neural Recording Time\n    -&gt; MovieSession                    # number of movie session\n    ---\n    values: longblob                   # values of continuous watch segments\n    start_times: longblob              # start time points of segments\n    stop_times: longblob               # end time points of segments\n    \"\"\"\n\n    def make(self, key):\n        \"\"\"Detect non-continuous segments (skips) from watchlogs and DAQ logs.\"\"\"\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                try:\n                    check = (MovieSkips &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"values\")\n                    if check.any():\n                        continue\n                    else:\n                        print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                        pass\n                except:\n                    print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n                starts, stops, values = time_conversion.convert_skips()\n\n                self.insert1({'patient_id': pat, \n                            'session_nr': sesh,\n                            'start_times': np.array(starts), \n                            'stop_times': np.array(stops), \n                            'values': np.array(values)}, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.MovieSkips.make","title":"make","text":"<pre><code>make(key)\n</code></pre> <p>Detect non-continuous segments (skips) from watchlogs and DAQ logs.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>def make(self, key):\n    \"\"\"Detect non-continuous segments (skips) from watchlogs and DAQ logs.\"\"\"\n    patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n    for i_pat, pat in enumerate(patient_ids):\n        pat_sessions = session_nrs[i_pat]\n\n        for i_sesh, sesh in enumerate([pat_sessions]):\n\n            try:\n                check = (MovieSkips &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"values\")\n                if check.any():\n                    continue\n                else:\n                    print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                    pass\n            except:\n                print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                pass\n\n            main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n            session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n            date = session_info.item().get(\"date\")\n            time = session_info.item().get(\"time\")\n            time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n            path_wl =  main_patient_dir / \"watchlogs\" \n            ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n            if ffplay_file:\n                print(\" Found ffplay file:\", ffplay_file)\n            else:\n                print(\" No ffplay file found in the watchlogs directory.\")\n                break\n\n            path_daq = main_patient_dir / \"daq_files\" \n            daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n            if ffplay_file:\n                print(\" Found DAQ file:\", daq_file)\n            else:\n                print(\" No DAQ file found in the daq_files directory.\")\n                break\n\n            path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n            time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                path_to_events=path_events)\n            starts, stops, values = time_conversion.convert_skips()\n\n            self.insert1({'patient_id': pat, \n                        'session_nr': sesh,\n                        'start_times': np.array(starts), \n                        'stop_times': np.array(stops), \n                        'values': np.array(values)}, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.MoviePauses","title":"MoviePauses","text":"<p>               Bases: <code>Computed</code></p> <p>Table containing information on pauses in movie playback detected from watchlogs and DAQ logs.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>@epi_schema\nclass MoviePauses(dj.Computed):\n    \"\"\"Table containing information on pauses in movie playback detected from watchlogs and DAQ logs.\"\"\"\n    definition = \"\"\"\n    # This table contains information about pauses in movie playback;\n    # This is directly computed from the watch log;\n    # Time points are in Neural Recording Time\n    -&gt; MovieSession                    # movie watching session of patient\n    ---\n    start_times: longblob              # start time points of pauses\n    stop_times: longblob               # end time points of pauses\n    \"\"\"\n\n    def make(self, key):\n\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                try:\n                    check = (MoviePauses &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"values\")\n                    if check.any():\n                        continue\n                    else:\n                        print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                        pass\n                except:\n                    print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n\n                starts, stops = time_conversion.convert_pauses()\n\n                self.insert1({'patient_id': pat,\n                            'session_nr': sesh,\n                            'start_times': np.array(starts),\n                            'stop_times': np.array(stops)}, skip_duplicates=True)\n</code></pre>"},{"location":"reference/database/#epiphyte.database.db_setup.populate_lfp_data_table","title":"populate_lfp_data_table","text":"<pre><code>populate_lfp_data_table()\n</code></pre> <p>Populate <code>LFPData</code> from <code>lfp_data</code> files under each session directory.</p> <p>Skips already-inserted channel entries.</p> Source code in <code>epiphyte/database/db_setup.py</code> <pre><code>def populate_lfp_data_table() -&gt; None:\n    \"\"\"Populate ``LFPData`` from ``lfp_data`` files under each session directory.\n\n    Skips already-inserted channel entries.\n    \"\"\"\n\n    patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n    for i_pat, pat in enumerate(patient_ids):\n        pat_sessions = session_nrs[i_pat]\n\n        for i_sesh, sesh in enumerate(pat_sessions):\n\n            path_ds_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\", \"lfp_data\")\n            lfp_files = list(path_ds_dir.glob(\"CSC*\"))\n\n            try:\n                check = (LFPData &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"csc_nr\")[0]\n                if len(check) == len(lfp_files):\n                    print(f\"    Patient {pat} session {sesh} already added.\")\n                    continue\n                else:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n            except:\n                print(f\"    Adding patient {pat} session {sesh} to database...\")\n                pass\n\n            path_channels = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\", \"ChannelNames.txt\")\n            channel_names = helpers.get_channel_names(path_channels)\n\n            for ds_file in path_ds_dir.iterdir():\n\n                csc_nr = ds_file.name.split('_')[0][3:]\n                region = channel_names[int(csc_nr)-1]\n                print(f\"  .. adding csc {csc_nr}..\")\n                ds_dict = np.load(ds_file, allow_pickle=True)\n                LFPData.insert1({\n                    'patient_id': pat,\n                    'session_nr': sesh,\n                    'csc_nr': csc_nr,\n                    'samples': ds_dict.item().get(\"samples\"),\n                    'timestamps': ds_dict.item().get(\"timestamps\"),\n                    'sample_rate': ds_dict.item().get(\"sample_rate\")[0],\n                    'brain_region': region\n                })\n\n\n                print(f\"  .. csc {csc_nr} added.\")\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers","title":"helpers","text":"<p>Helper functions used in the <code>database</code> module.</p> <p>This module provides small utilities for parsing filenames, sorting keys in a human-friendly way, and extracting metadata encoded in strings.</p>"},{"location":"reference/database/#epiphyte.database.helpers.atoi","title":"atoi","text":"<pre><code>atoi(text)\n</code></pre> <p>Convert a numeric substring to <code>int</code> or return the original string.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Substring that may contain only digits.</p> required <p>Returns:</p> Type Description <code>Union[int, str]</code> <p>Union[int, str]: Integer value (if all digits) or the original string.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def atoi(text: str) -&gt; Union[int, str]:\n    \"\"\"Convert a numeric substring to ``int`` or return the original string.\n\n    Args:\n        text (str): Substring that may contain only digits.\n\n    Returns:\n        Union[int, str]: Integer value (if all digits) or the original string.\n    \"\"\"\n\n    return int(text) if text.isdigit() else text\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.natural_keys","title":"natural_keys","text":"<pre><code>natural_keys(text)\n</code></pre> <p>Split a string into chunks for human (natural) sorting.</p> <p>Use as <code>alist.sort(key=natural_keys)</code> to sort filenames such as <code>CSC2_SU1.npy</code> before <code>CSC10_SU1.npy</code>.</p> Notes <p>Based on Ned Batchelder's human sorting recipe.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input string to split into text and integer chunks.</p> required <p>Returns:</p> Type Description <code>List[Union[int, str]]</code> <p>List[Union[int, str]]: Alternating text and integer parts suitable as a sort key.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def natural_keys(text: str) -&gt; List[Union[int, str]]:\n    \"\"\"Split a string into chunks for human (natural) sorting.\n\n    Use as ``alist.sort(key=natural_keys)`` to sort filenames such as\n    ``CSC2_SU1.npy`` before ``CSC10_SU1.npy``.\n\n    Notes:\n        Based on Ned Batchelder's human sorting recipe.\n\n    Args:\n        text (str): Input string to split into text and integer chunks.\n\n    Returns:\n        List[Union[int, str]]: Alternating text and integer parts suitable as a sort key.\n    \"\"\"\n\n    return [atoi(chunk) for chunk in re.split(r\"(\\d+)\", text)]\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.extract_sort_key","title":"extract_sort_key","text":"<pre><code>extract_sort_key(filename)\n</code></pre> <p>Extract a sortable key from a spike filename.</p> <p>Filenames are expected to follow <code>CSC&lt;nr&gt;_&lt;type&gt;&lt;nr&gt;.npy</code>. If the pattern matches, returns a tuple <code>(csc_number, unit_type, unit_nr)</code>. Otherwise, returns the original filename for fallback sorting.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Filename to parse.</p> required <p>Returns:</p> Type Description <code>Union[Tuple[int, str, int], str]</code> <p>Union[Tuple[int, str, int], str]: Tuple for sorting or the original filename.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def extract_sort_key(filename: str) -&gt; Union[Tuple[int, str, int], str]:\n    \"\"\"Extract a sortable key from a spike filename.\n\n    Filenames are expected to follow ``CSC&lt;nr&gt;_&lt;type&gt;&lt;nr&gt;.npy``. If the\n    pattern matches, returns a tuple ``(csc_number, unit_type, unit_nr)``.\n    Otherwise, returns the original filename for fallback sorting.\n\n    Args:\n        filename (str): Filename to parse.\n\n    Returns:\n        Union[Tuple[int, str, int], str]: Tuple for sorting or the original filename.\n    \"\"\"\n\n    match = re.match(r\"CSC(\\d+)_(\\w+)(\\d*)\\.npy\", filename)\n    if match:\n        csc_number = int(match.group(1))\n        mu_su = match.group(2)\n        mu_su_number = int(match.group(3)) if match.group(3) else 0\n        return csc_number, mu_su, mu_su_number\n    return filename\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.get_channel_names","title":"get_channel_names","text":"<pre><code>get_channel_names(path_channel_names)\n</code></pre> <p>Read channel names (without extensions) from a text file.</p> <p>The file is expected to contain lines like <code>&lt;name&gt;.ncs</code>. The suffix is stripped to yield bare channel identifiers.</p> <p>Parameters:</p> Name Type Description Default <code>path_channel_names</code> <code>Union[str, Path]</code> <p>Path to the channel names file.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of channel name strings.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def get_channel_names(path_channel_names: Union[str, Path]) -&gt; List[str]:\n    \"\"\"Read channel names (without extensions) from a text file.\n\n    The file is expected to contain lines like ``&lt;name&gt;.ncs``. The suffix is\n    stripped to yield bare channel identifiers.\n\n    Args:\n        path_channel_names (Union[str, Path]): Path to the channel names file.\n\n    Returns:\n        List[str]: List of channel name strings.\n    \"\"\"\n\n    channel_names: List[str] = []\n    with open(path_channel_names, \"r\") as handle:\n        for line in handle:\n            # Strip trailing \"\\n\" and \".ncs\" (5 chars), keep the base name only.\n            channel_names.append(line[:-5 - 1])\n    return channel_names\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.get_unit_type_and_number","title":"get_unit_type_and_number","text":"<pre><code>get_unit_type_and_number(unit_string)\n</code></pre> <p>Parse a unit string into unit type and number.</p> <p>Example: <code>CSC_MUA1</code> -&gt; (\"M\", \"1\").</p> <p>Parameters:</p> Name Type Description Default <code>unit_string</code> <code>str</code> <p>Original unit string (e.g., <code>\"MUA1\"</code> or <code>\"SU3\"</code>).</p> required <p>Returns:</p> Type Description <code>Tuple[str, str]</code> <p>Tuple[str, str]: Tuple <code>(unit_type, unit_nr)</code> where type is <code>\"M\"</code>, <code>\"S\"</code>, or <code>\"X\"</code>.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def get_unit_type_and_number(unit_string: str) -&gt; Tuple[str, str]:\n    \"\"\"Parse a unit string into unit type and number.\n\n    Example: ``CSC_MUA1`` -&gt; (\"M\", \"1\").\n\n    Args:\n        unit_string (str): Original unit string (e.g., ``\"MUA1\"`` or ``\"SU3\"``).\n\n    Returns:\n        Tuple[str, str]: Tuple ``(unit_type, unit_nr)`` where type is ``\"M\"``, ``\"S\"``, or ``\"X\"``.\n    \"\"\"\n\n    if \"MU\" in unit_string:\n        unit_type = \"M\"\n    elif \"SU\" in unit_string:\n        unit_type = \"S\"\n    else:\n        unit_type = \"X\"\n    unit_nr = unit_string[-1]\n    return unit_type, unit_nr\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.extract_name_unit_id_from_unit_level_data_cleaning","title":"extract_name_unit_id_from_unit_level_data_cleaning","text":"<pre><code>extract_name_unit_id_from_unit_level_data_cleaning(filename)\n</code></pre> <p>Split a unit-level cleaning filename into components.</p> <p>Filenames are expected as <code>\"&lt;name&gt;_unit&lt;id&gt;_&lt;annotator&gt;.npy\"</code>.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Filename to parse.</p> required <p>Returns:</p> Type Description <code>Tuple[str, str, str]</code> <p>Tuple[str, str, str]: Tuple <code>(name, unit_id, annotator)</code>.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def extract_name_unit_id_from_unit_level_data_cleaning(\n    filename: str,\n) -&gt; Tuple[str, str, str]:\n    \"\"\"Split a unit-level cleaning filename into components.\n\n    Filenames are expected as ``\"&lt;name&gt;_unit&lt;id&gt;_&lt;annotator&gt;.npy\"``.\n\n    Args:\n        filename (str): Filename to parse.\n\n    Returns:\n        Tuple[str, str, str]: Tuple ``(name, unit_id, annotator)``.\n    \"\"\"\n\n    name, unit_id, annotator = filename.split(\"_\")\n    unit_id = unit_id[4:]\n    annotator = annotator[:-4]\n    return name, unit_id, annotator\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.match_label_to_patient_pts_time","title":"match_label_to_patient_pts_time","text":"<pre><code>match_label_to_patient_pts_time(default_label, patient_pts)\n</code></pre> <p>Align a default label indicator function to patient PTS frames.</p> <p>Parameters:</p> Name Type Description Default <code>default_label</code> <code>ndarray</code> <p>Indicator vector (per canonical frame) of shape <code>(N,)</code>.</p> required <code>patient_pts</code> <code>ndarray</code> <p>Watched frame times in seconds, rounded to 2 decimals.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: Indicator value for each patient frame.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def match_label_to_patient_pts_time(\n    default_label: np.ndarray, patient_pts: np.ndarray\n) -&gt; List[int]:\n    \"\"\"Align a default label indicator function to patient PTS frames.\n\n    Args:\n        default_label (np.ndarray): Indicator vector (per canonical frame) of shape ``(N,)``.\n        patient_pts (np.ndarray): Watched frame times in seconds, rounded to 2 decimals.\n\n    Returns:\n        List[int]: Indicator value for each patient frame.\n    \"\"\"\n\n    return [\n        default_label[int(np.round(frame / 0.04, 0)) - 1]\n        for _, frame in enumerate(patient_pts)\n    ]\n</code></pre>"},{"location":"reference/database/#epiphyte.database.helpers.get_list_of_patient_ids","title":"get_list_of_patient_ids","text":"<pre><code>get_list_of_patient_ids(patient_dict)\n</code></pre> <p>Collect all patient IDs from an indexable sequence of dicts.</p> <p>Parameters:</p> Name Type Description Default <code>patient_dict</code> <code>Sequence[Dict[str, Any]]</code> <p>Sequence where each item has a <code>patient_id</code> key.</p> required <p>Returns:</p> Type Description <code>List[int]</code> <p>List[int]: List of integer patient identifiers.</p> Source code in <code>epiphyte/database/helpers.py</code> <pre><code>def get_list_of_patient_ids(patient_dict: Sequence[Dict[str, Any]]) -&gt; List[int]:\n    \"\"\"Collect all patient IDs from an indexable sequence of dicts.\n\n    Args:\n        patient_dict (Sequence[Dict[str, Any]]): Sequence where each item has a `patient_id` key.\n\n    Returns:\n        List[int]: List of integer patient identifiers.\n    \"\"\"\n\n    return [patient_dict[i][\"patient_id\"] for i in range(0, len(patient_dict))]\n</code></pre>"},{"location":"reference/database/#epiphyte.database.query_functions","title":"query_functions","text":""},{"location":"reference/preprocessing/","title":"Preprocessing","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing","title":"epiphyte.preprocessing","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation","title":"annotation","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.data_driven_annotation","title":"data_driven_annotation","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.data_driven_annotation.cpt","title":"cpt","text":"<p>Detects the changepoint in a spike train using parametric statistic testing.</p> <p>Plots the results and returns the index of the breakpoint and the stat test results.</p> <p>Used for demonstrating the addition of a new table to an existing database.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.data_driven_annotation.cpt.find_changepoint_tt","title":"find_changepoint_tt","text":"<pre><code>find_changepoint_tt(data, verbose=False)\n</code></pre> <p>Detects the changepoint in a spike train using parametric statistic testing. Plots the results and returns the index of the breakpoint and the stat test results.</p> <p>Accepts and runs one unit. Set up to be iterated over for the whole of a dataset of units.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>ndarray</code> <p>spike train data (1D array-like)</p> required <code>verbose</code> <code>bool</code> <p>if True, prints detailed changepoint and t-test results</p> <code>False</code> <p>Returns:</p> Name Type Description <code>taustar</code> <code>int</code> <p>index of the determined breakpoint.</p> <code>ttest</code> <code>ttest_ind_from_stats</code> <p>results from the scipy stats ttest (type is a specific class construction from scipy)</p> Source code in <code>epiphyte/preprocessing/annotation/data_driven_annotation/cpt.py</code> <pre><code>def find_changepoint_tt(data, verbose=False):\n    \"\"\"\n    Detects the changepoint in a spike train using parametric statistic testing.\n    Plots the results and returns the index of the breakpoint and the stat test results.\n\n    Accepts and runs one unit. Set up to be iterated over for the whole of a dataset of units.\n\n    Args:\n        data (np.ndarray):  spike train data (1D array-like)\n        verbose (bool):    if True, prints detailed changepoint and t-test results\n\n    Returns:\n        taustar (int): index of the determined breakpoint.\n        ttest (stats.ttest_ind_from_stats): results from the scipy stats ttest (type is a specific class construction from scipy)\n    \"\"\"\n    n = len(data)\n\n    mu0 = np.mean(data)  # global mean\n    s0 = np.sum((data - mu0) ** 2)  # squared difference from global mean\n    s1 = np.asarray(\n        [np.sum((data[0:i] - np.mean(data[0:i])) ** 2) for i in range(1, n)])  # squared sum before changepoint\n    s2 = np.asarray(\n        [np.sum((data[i:] - np.mean(data[i:])) ** 2) for i in range(1, n)])  # squared sum after changepoint\n\n    R = s0 - s1 - s2\n    G = np.max(R)\n\n    taustar = int(np.where(R == G)[0]) + 1\n\n    m1 = np.mean(data[0:taustar])\n    std1 = np.std(data[0:taustar])\n    nobs1 = len(data[0:taustar])\n    m2 = np.mean(data[taustar:])\n    std2 = np.std(data[taustar:])\n    nobs2 = len(data[taustar:])\n\n    ttest = stats.ttest_ind_from_stats(m1, std1, nobs1, m2, std2, nobs2)\n\n    if verbose:\n        print(\"Changepoint results:\")\n        print(\"tau*: \", taustar)\n        print(\"mean pre-tau: \", m1)\n        print(\"std  pre-tau: \", std1)\n        print(\"mean post-tau: \", m2)\n        print(\"std  post-tau:\", std2)\n        print(\"T-test results:\")\n        print(ttest)\n        print(\"\")\n\n    return taustar, ttest\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.data_driven_annotation.cpt.plot_changepoint","title":"plot_changepoint","text":"<pre><code>plot_changepoint(data, taustar, ttest, save=None, filename=None, comparison_tau=None)\n</code></pre> <p>Plot a change point in neural activity data and annotate with statistical results.</p> <p>This function visualizes time-binned neural activity and overlays vertical lines indicating the detected change point (<code>taustar</code>) and, optionally, a second change point (<code>comparison_tau</code>). It also displays the results of a t-test as legend entries.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>array - like</code> <p>Sequence of neural activity values.</p> required <code>taustar</code> <code>int</code> <p>Detected change point index (in 1-second bins).</p> required <code>ttest</code> <code>tuple</code> <p>A tuple containing (t-statistic, p-value) from a t-test.</p> required <code>save</code> <code>str</code> <p>Directory path where plots should be saved. If None, plots are not saved.</p> <code>None</code> <code>filename</code> <code>str</code> <p>Base filename (without extension) for saving plots. Required if <code>save</code> is provided.</p> <code>None</code> <code>comparison_tau</code> <code>int</code> <p>Another change point index to compare with <code>taustar</code>.</p> <code>None</code> Saves <ul> <li><code>{filename}_cpt.png</code> in the <code>save</code> directory if <code>save</code> is provided.</li> <li><code>{filename}_cpt.svg</code> in the <code>save</code> directory if <code>save</code> is provided.</li> </ul> Example <pre><code>from scipy.stats import ttest_ind\n\ndata = [0, 1, 2, 5, 6, 7, 10, 11]\nttest = ttest_ind(data[:4], data[4:])\nplot_changepoint(data, taustar=4, ttest=ttest, save=\"plots/\", filename=\"session1\")\n</code></pre> Source code in <code>epiphyte/preprocessing/annotation/data_driven_annotation/cpt.py</code> <pre><code>def plot_changepoint(data, taustar, ttest, save=None, filename=None, comparison_tau=None):\n    \"\"\"\n    Plot a change point in neural activity data and annotate with statistical results.\n\n    This function visualizes time-binned neural activity and overlays vertical\n    lines indicating the detected change point (`taustar`) and, optionally, a\n    second change point (`comparison_tau`). It also displays the results of a\n    t-test as legend entries.\n\n    Args:\n        data (array-like): \n            Sequence of neural activity values.\n        taustar (int): \n            Detected change point index (in 1-second bins).\n        ttest (tuple): \n            A tuple containing (t-statistic, p-value) from a t-test.\n        save (str, optional): \n            Directory path where plots should be saved. If None, plots are not saved.\n        filename (str, optional): \n            Base filename (without extension) for saving plots. Required if `save` is provided.\n        comparison_tau (int, optional): \n            Another change point index to compare with `taustar`.\n\n    Saves:\n        - `{filename}_cpt.png` in the `save` directory if `save` is provided.\n        - `{filename}_cpt.svg` in the `save` directory if `save` is provided.\n\n    Example:\n        ```python\n        from scipy.stats import ttest_ind\n\n        data = [0, 1, 2, 5, 6, 7, 10, 11]\n        ttest = ttest_ind(data[:4], data[4:])\n        plot_changepoint(data, taustar=4, ttest=ttest, save=\"plots/\", filename=\"session1\")\n        ```\n    \"\"\"\n    n = len(data)\n    fig = plt.figure(figsize=(25, 5))\n    plt.plot(np.arange(1, n + 1), data)\n    plt.axvline(x=taustar, color='r', label=\"tau: {}\".format(taustar))\n\n    if comparison_tau:\n        # note: comparison_tau is expected to be an int type value from a previously computed set of cpt results\n        plt.axvline(x=comparison_tau, color='y', label=\"other tau: {}\".format(comparison_tau))\n\n    pval_str = \"P-value: {}\".format(ttest[1])\n    tstat_str = \"T-statistic: {}\".format(ttest[0])\n    plt.plot([], [], \"\", label=pval_str)\n    plt.plot([], [], \"\", label=tstat_str)\n    plt.xlabel('Time [1 sec bins]')\n    plt.ylabel('Neural Activity [spikes / bin]')\n    plt.legend(prop={'size': 15})\n\n    if save:\n        plt.title(filename + ' change point statistics')\n\n        plt.savefig(save + \"{}_cpt.png\".format(filename), bbox_inches='tight')\n        plt.savefig(save + \"{}_cpt.svg\".format(filename), format='svg', bbox_inches='tight')\n\n    plt.show()\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation","title":"stimulus_driven_annotation","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies","title":"movies","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.annotation_utils","title":"annotation_utils","text":"<p>Helpers for handling stimulus-driven annotations in an analysis workflows.</p> <p>Provides utilities to split neural activity by label values for downstream analysis and visualization.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.annotation_utils.split_activity_by_value","title":"split_activity_by_value","text":"<pre><code>split_activity_by_value(binned_activity, binned_label, specific_values=None)\n</code></pre> <p>Split binned activity by the values in a binned label vector.</p> Example <p>For a binary label (stimulus on/off), the <code>binned_label</code> vector contains 0/1. This function returns two arrays mapping to segments where the label is off/on, respectively. For multi-valued labels, activity is split per unique value.</p> <p>Parameters:</p> Name Type Description Default <code>binned_activity</code> <code>ndarray</code> <p>Binned neural activity (shape <code>(N, ...)</code>).</p> required <code>binned_label</code> <code>ndarray</code> <p>Binned label aligned to the activity (length <code>N</code>).</p> required <code>specific_values</code> <code>Optional[Iterable[int]]</code> <p>If provided, only these label values are used.</p> <code>None</code> <p>Returns:</p> Type Description <code>Dict[str, ndarray]</code> <p>Dict[str, np.ndarray]: Mapping <code>{value_name: activity_subset}</code>.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/annotation_utils.py</code> <pre><code>def split_activity_by_value(\n    binned_activity: np.ndarray,\n    binned_label: np.ndarray,\n    specific_values: Optional[Iterable[int]] = None,\n) -&gt; Dict[str, np.ndarray]:\n    \"\"\"Split binned activity by the values in a binned label vector.\n\n    Example:\n        For a binary label (stimulus on/off), the ``binned_label`` vector\n        contains 0/1. This function returns two arrays mapping to segments\n        where the label is off/on, respectively. For multi-valued labels,\n        activity is split per unique value.\n\n    Args:\n        binned_activity (np.ndarray): Binned neural activity (shape ``(N, ...)``).\n        binned_label (np.ndarray): Binned label aligned to the activity (length ``N``).\n        specific_values (Optional[Iterable[int]]): If provided, only these label values are used.\n\n    Returns:\n        Dict[str, np.ndarray]: Mapping ``{value_name: activity_subset}``.\n    \"\"\"\n    # Set up for number --&gt; word converstion \n    alph = inflect.engine()\n\n    if not specific_values:\n        values = np.unique(binned_label)\n\n        ret_vectors = {}\n\n        for value in values:\n\n            indices = np.isin(binned_label, value)\n            activity_from_val = binned_activity[indices]\n\n            # Convert value number to the word, for easy referencing during analysis\n            name = alph.number_to_words(int(value))\n\n            ret_vectors[name] = activity_from_val\n\n    if specific_values:\n\n        ret_vectors = {}\n\n        for value in specific_values:\n            indices = np.isin(binned_label, value)\n            activity_from_val = binned_activity[indices]\n\n            name = alph.number_to_words(int(value))\n            ret_vectors[name] = activity_from_val\n\n    return ret_vectors\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling","title":"pause_handling","text":"<p>Helpers to handle pause intervals while binning labels and spikes.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling.pause_start_bin","title":"pause_start_bin","text":"<pre><code>pause_start_bin(bins, start)\n</code></pre> <p>Find start bin index inclusive of the pause start.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>ndarray or list - like</code> <p>bin edges (ms).</p> required <code>start</code> <code>float</code> <p>Pause start time (ms).</p> required <p>Returns:     int: index of the start bin.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/pause_handling.py</code> <pre><code>def pause_start_bin(bins: np.ndarray, start: float) -&gt; int:\n    \"\"\"Find start bin index inclusive of the pause start.\n\n    Args:\n        bins (np.ndarray or list-like): bin edges (ms).\n        start (float): Pause start time (ms).\n    Returns:\n        int: index of the start bin.\n    \"\"\"\n    ind_start = (np.abs(bins - start)).argmin()  \n    if bins[ind_start] &gt; start: \n        start_bin = ind_start - 1\n    else: \n        start_bin = ind_start\n    return start_bin \n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling.pause_stop_bin","title":"pause_stop_bin","text":"<pre><code>pause_stop_bin(bins, stop)\n</code></pre> <p>Find stop bin index inclusive of the pause stop.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>ndarray</code> <p>Bin edges (ms).</p> required <code>stop</code> <code>float</code> <p>Pause stop time (ms).</p> required <p>Returns:     int: Index of the stop bin.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/pause_handling.py</code> <pre><code>def pause_stop_bin(bins: np.ndarray, stop: float) -&gt; int: \n    \"\"\"Find stop bin index inclusive of the pause stop.\n\n    Args:\n        bins: Bin edges (ms).\n        stop: Pause stop time (ms).\n    Returns:\n        int: Index of the stop bin.\n    \"\"\"\n    ind_stop = (np.abs(bins - stop)).argmin()\n    if bins[ind_stop] &lt; stop:\n        stop_bin = ind_stop + 1\n    else:\n        stop_bin = ind_stop\n    return stop_bin\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling.make_pause_interval","title":"make_pause_interval","text":"<pre><code>make_pause_interval(bin_start, bin_stop)\n</code></pre> <p>Make a list of indices spanning the pause interval (inclusive).</p> <p>Parameters:</p> Name Type Description Default <code>bin_start</code> <code>int</code> <p>Start bin index.</p> required <code>bin_stop</code> <code>int</code> <p>Stop bin index.</p> required <p>Returns:     List[int]: List of indices spanning the pause interval (inclusive).</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/pause_handling.py</code> <pre><code>def make_pause_interval(bin_start: int, bin_stop: int) -&gt; List[int]:\n    \"\"\"Make a list of indices spanning the pause interval (inclusive).\n\n    Args:\n        bin_start (int): Start bin index.\n        bin_stop (int): Stop bin index.\n    Returns:\n        List[int]: List of indices spanning the pause interval (inclusive).\n    \"\"\"\n    pause = list(range(bin_start, (bin_stop + 1), 1))\n    return pause \n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling.rm_pauses_bins","title":"rm_pauses_bins","text":"<pre><code>rm_pauses_bins(bins, start, stop, return_intervals=False)\n</code></pre> <p>Remove bin edges that occur during paused playback.</p> <p>Parameters:</p> Name Type Description Default <code>bins</code> <code>ndarray or list - like</code> <p>Bin edges (ms).</p> required <code>start</code> <code>ndarray or list - like</code> <p>Pause starts (ms).</p> required <code>stop</code> <code>ndarray or list - like</code> <p>Pause stops (ms).</p> required <code>return_intervals</code> <code>bool</code> <p>If <code>True</code>, also return indices removed.</p> <code>False</code> <p>Returns:      Tuple[np.ndarray, List[int]]: Cleaned bins or <code>(bins_no_pauses, removed_indices)</code>.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/pause_handling.py</code> <pre><code>def rm_pauses_bins(\n    bins: np.ndarray,\n    start: np.ndarray,\n    stop: np.ndarray,\n    return_intervals: bool = False,\n) -&gt; np.ndarray | Tuple[np.ndarray, List[int]]:\n    \"\"\"Remove bin edges that occur during paused playback.\n\n    Args:\n        bins (np.ndarray or list-like): Bin edges (ms).\n        start (np.ndarray or list-like): Pause starts (ms).\n        stop (np.ndarray or list-like): Pause stops (ms).\n        return_intervals (bool): If ``True``, also return indices removed.\n    Returns: \n        Tuple[np.ndarray, List[int]]: Cleaned bins or ``(bins_no_pauses, removed_indices)``.\n    \"\"\"\n    pauses = []\n\n    for i in range(len(start)):\n        start_bin = pause_start_bin(bins, start[i])\n        stop_bin  = pause_stop_bin(bins, stop[i])\n        interval = make_pause_interval(start_bin, stop_bin)\n        pauses.append(interval)\n\n    flatten = lambda l: [item for sublist in l for item in sublist]\n    all_pauses = flatten(pauses)\n\n    no_pauses = np.delete(bins, all_pauses)\n\n    if return_intervals: \n        output = [no_pauses, all_pauses]\n    else:\n        output = no_pauses\n\n    return output\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.pause_handling.rm_pauses_spikes","title":"rm_pauses_spikes","text":"<pre><code>rm_pauses_spikes(unit, start, stop, return_intervals=False)\n</code></pre> <p>Remove spikes that occur during paused playback.</p> <p>Parameters:</p> Name Type Description Default <code>unit</code> <code>ndarray</code> <p>Spike times (ms).</p> required <code>start</code> <code>ndarray</code> <p>Pause starts (ms).</p> required <code>stop</code> <code>ndarray</code> <p>Pause stops (ms).</p> required <code>return_intervals</code> <code>bool</code> <p>If <code>True</code>, also return removed indices.</p> <code>False</code> <p>Returns:      Tuple[np.ndarray, List[int]]: Cleaned spikes or <code>(unit_no_pauses, removed_indices)</code>.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/pause_handling.py</code> <pre><code>def rm_pauses_spikes(\n    unit: np.ndarray,\n    start: np.ndarray,\n    stop: np.ndarray,\n    return_intervals: bool = False,\n) -&gt; np.ndarray | Tuple[np.ndarray, List[int]]:\n    \"\"\"Remove spikes that occur during paused playback.\n\n    Args:\n        unit (np.ndarray): Spike times (ms).\n        start (np.ndarray): Pause starts (ms).\n        stop (np.ndarray): Pause stops (ms).\n        return_intervals (bool): If ``True``, also return removed indices.\n    Returns: \n        Tuple[np.ndarray, List[int]]: Cleaned spikes or ``(unit_no_pauses, removed_indices)``.\n    \"\"\"\n    paused_spikes = []\n\n    for i, spk in enumerate(unit): \n        for j in range(len(start)):\n            if spk &gt;= start[j] and spk &lt;= stop[j]:\n                paused_spikes.append(i)\n\n    unit_no_pauses = np.delete(unit, paused_spikes)\n\n    if return_intervals: \n        output = [unit_no_pauses, paused_spikes]\n    else:\n        output = unit_no_pauses\n\n    return output\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels","title":"processing_labels","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels.make_label_from_start_stop_times","title":"make_label_from_start_stop_times","text":"<pre><code>make_label_from_start_stop_times(values, start_times, stop_times, ref_vec, default_value=0)\n</code></pre> <p>This function takes a vector with tuples with start and stop times and converts it to the default label</p> <p>Parameters:</p> Name Type Description Default <code>ref_vec</code> <code>ndarray</code> <p>reference vector, e.g. either PTS of movie or neural recording time of patient</p> required <code>default_value</code> <code>int</code> <p>default value of label, which shall be added to all gaps in start stop times</p> <code>0</code> <code>values</code> <code>list</code> <p>vector with all values</p> required <code>start_times</code> <code>list</code> <p>vector with all start_times of segments</p> required <code>stop_times</code> <code>list</code> <p>vector with all stop times of segments</p> required <p>Returns:     list[int] | int: Label vector, or <code>-1</code> on error.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/processing_labels.py</code> <pre><code>def make_label_from_start_stop_times(values: Sequence[int],\n    start_times: Sequence[float],\n    stop_times: Sequence[float],\n    ref_vec: Sequence[float] | np.ndarray,\n    default_value: int = 0,\n) -&gt; list[int]:\n    \"\"\"\n    This function takes a vector with tuples with start and stop times and converts it to the default label\n\n    Args:\n        ref_vec (np.ndarray): reference vector, e.g. either PTS of movie or neural recording time of patient\n        default_value (int): default value of label, which shall be added to all gaps in start stop times\n        values (list): vector with all values\n        start_times (list): vector with all start_times of segments\n        stop_times (list): vector with all stop times of segments\n    Returns:\n        list[int] | int: Label vector, or ``-1`` on error.\n    \"\"\"\n    if not (len(values) == len(start_times) == len(stop_times)):\n        print(\"vectors values, starts and stops have to be the same length\")\n        return -1\n\n    default_label = [default_value] * len(ref_vec)\n\n    for i in range(len(values)):\n        start_index_in_default_vec = create_vectors_from_time_points.get_index_nearest_timestamp_in_vector(np.array(ref_vec), start_times[i])\n        end_index_in_default_vec = create_vectors_from_time_points.get_index_nearest_timestamp_in_vector(np.array(ref_vec), stop_times[i])\n\n        default_label[start_index_in_default_vec:(end_index_in_default_vec+1)] = \\\n            [int(values[i])]*(end_index_in_default_vec - start_index_in_default_vec + 1)\n\n    return default_label\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels.create_xml_for_advene","title":"create_xml_for_advene","text":"<pre><code>create_xml_for_advene(id_name, start_end_times_vector, label_name)\n</code></pre> <p>This function creates an XML string, which can be imported to the movie annotation tool Advene</p> <p>Parameters:</p> Name Type Description Default <code>id_name</code> <code>str</code> <p>name of ID in XML file</p> required <code>start_end_times_vector</code> <code>list</code> <p>input vector that contains the start and end times of the label in milliseconds</p> required <code>label_name</code> <code>str</code> <p>the name of the label how it shall be displayed in the GUI of Advene</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>an XML string that can be copied to the content.xml file and loaded to Advene</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/processing_labels.py</code> <pre><code>def create_xml_for_advene(id_name: str, start_end_times_vector: list[tuple[float, float]], label_name: str) -&gt; str:\n    \"\"\"\n    This function creates an XML string, which can be imported to the movie annotation tool Advene\n\n    Args:\n        id_name (str): name of ID in XML file\n        start_end_times_vector (list): input vector that contains the start and end times of the label in milliseconds\n        label_name (str): the name of the label how it shall be displayed in the GUI of Advene\n\n    Returns:\n        str: an XML string that can be copied to the content.xml file and loaded to Advene\n    \"\"\"\n    new_annotations = \"\"\n    id_ = 0\n\n    for start, end in start_end_times_vector:\n        string_new_annotation = '&lt;annotation id=\"{}{}\" type=\"#{}\"&gt;&lt;millisecond-fragment begin=\"{}\" end=\"{}\"/&gt;&lt;content&gt;num=1&lt;/content&gt;&lt;/annotation&gt;'.format(\n            id_name, id_, label_name, int(start * 1000), int(end * 1000))\n\n        new_annotations += string_new_annotation\n\n        id_ += 1\n    return new_annotations\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels.start_stop_values_from_json","title":"start_stop_values_from_json","text":"<pre><code>start_stop_values_from_json(path_to_file, label_name)\n</code></pre> <p>This function extracts start times, stop times and values of all segments of a label from a json file</p> <p>Parameters:</p> Name Type Description Default <code>path_to_file</code> <code>str</code> <p>path to json file</p> required <code>label_name</code> <code>str</code> <p>name of label (how it was specified in json file)</p> required <p>Returns:     np.ndarray, np.ndarray, np.ndarray: first array: values of label, second array: start times of label segments in seconds, third array: stop times of label segments in seconds</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/processing_labels.py</code> <pre><code>def start_stop_values_from_json(path_to_file: str, label_name: str) -&gt; tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"\n    This function extracts start times, stop times and values of all segments of a label from a json file\n\n    Args:\n        path_to_file (str): path to json file\n        label_name (str): name of label (how it was specified in json file)\n    Returns:\n        np.ndarray, np.ndarray, np.ndarray: first array: values of label, second array: start times of label segments in seconds, third array: stop times of label segments in seconds\n    \"\"\"\n    # open and read json file\n    with open(path_to_file,'r') as jsonfile:\n        labels_json_file = json.load(jsonfile) \n\n    start_times = []\n    stop_times = []\n    values = []\n    # iterate through elements in json file to extract time points of segments\n    for annotation in labels_json_file.get(\"annotations\"):\n        if annotation.get(\"type\") == label_name:\n            start_times.append(annotation.get(\"begin\"))\n            stop_times.append(annotation.get(\"end\"))\n            values.append(annotation.get(\"title\"))\n\n    return np.array(values), np.array(start_times)/1000, np.array(stop_times)/1000\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels.export_labels_from_json_file","title":"export_labels_from_json_file","text":"<pre><code>export_labels_from_json_file(path_to_file, label_name, bool_save_start_end_times)\n</code></pre> <p>Process a json file from Advene and create a new label.</p> <p>Parameters:</p> Name Type Description Default <code>path_to_file</code> <code>str</code> <p>path to json file containing all information about the labels from Advene</p> required <code>label_name</code> <code>str</code> <p>name that was specified in Advene</p> required <code>bool_save_start_end_times</code> <code>bool</code> <p>determine whether the start and end times should be saved as a npy file</p> required <p>Returns:     list: new label, aligned with movie (default label)</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/processing_labels.py</code> <pre><code>def export_labels_from_json_file(path_to_file: str, label_name: str, bool_save_start_end_times: bool) -&gt; list[int] | int:\n    \"\"\"\n    Process a json file from Advene and create a new label.\n\n    Args:\n        path_to_file (str): path to json file containing all information about the labels from Advene\n        label_name (str): name that was specified in Advene\n        bool_save_start_end_times (bool): determine whether the start and end times should be saved as a npy file\n    Returns:\n        list: new label, aligned with movie (default label)\n    \"\"\"\n    with open(path_to_file, 'r') as jsonfile:\n        labels_json_file = json.load(jsonfile)\n\n    label_start_end_times = []\n    values = []\n    for annotation in labels_json_file.get(\"annotations\"):\n        if annotation.get(\"type\") == label_name:\n            label_start_end_times.append([annotation.get(\"begin\"), annotation.get(\"end\")])\n            values.append(annotation.get(\"title\"))\n\n    # if requested, the start and end times will be saved\n    if bool_save_start_end_times:\n        start_end_times_seconds = [[x / 1000, y / 1000] for [x, y] in label_start_end_times]\n        np.save(\"../useful_data/start_end_times/start_end_times_{}.npy\".format(label_name), start_end_times_seconds)\n\n    return label_start_end_times, values\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.processing_labels.get_start_stop_times_from_label","title":"get_start_stop_times_from_label","text":"<pre><code>get_start_stop_times_from_label(neural_rec_time, patient_aligned_label)\n</code></pre> <p>This function takes the patient aligned label and extracts the start and stop times from that.</p> <p>Parameters:</p> Name Type Description Default <code>neural_rec_time</code> <code>array</code> <p>neural recording time of patient</p> required <code>patient_aligned_label</code> <code>array</code> <p>patient aligned label</p> required <p>Returns:     values (list), start times (list) and stop times (list) of label segments</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/processing_labels.py</code> <pre><code>def get_start_stop_times_from_label(neural_rec_time: np.ndarray, patient_aligned_label: np.ndarray) -&gt; tuple[list, list, list]:\n    \"\"\"\n    This function takes the patient aligned label and extracts the start and stop times from that.\n\n    Args:\n        neural_rec_time (array): neural recording time of patient\n        patient_aligned_label (array): patient aligned label\n    Returns:\n        values (list), start times (list) and stop times (list) of label segments\n    \"\"\"\n\n    tmp = patient_aligned_label[0]\n    values = [tmp]\n    start_times = [neural_rec_time[0]]\n    stop_times = []\n    for i in range(1, len(patient_aligned_label)):\n        if not patient_aligned_label[i] == tmp:\n            values.append(patient_aligned_label[i])\n            start_times.append(neural_rec_time[i])\n            stop_times.append(neural_rec_time[i-1])\n            tmp = patient_aligned_label[i]\n    stop_times.append(neural_rec_time[-1])\n\n    return values, start_times, stop_times\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.watch_log","title":"watch_log","text":"<p>Watch log parsing utilities for extracting PTS and CPU timestamps.</p> <p>This module provides the :class:<code>WatchLog</code> class to read a \"watch log\" file, derive start/end times, and build aligned arrays/dataframes of presentation timestamps (PTS) and real (CPU) times. It also includes helpers to trim the recorded time series to a maximum movie duration.</p> Constants <p>MAX_MOVIE_TIME (int): Maximum allowable movie time (in the same units as PTS)     used to filter out timestamps beyond the movie length.</p> Example <p>wl = WatchLog(\"/path/to/watch.log\") wl.get_start_time(), wl.get_end_time() (12, 5012) wl.df_pts_cpu.head()</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.watch_log--pts-cpu_time","title":"pts  cpu_time","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.watch_log--0-000-1234","title":"0  0.00      1234","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.watch_log--1-004-1270","title":"1  0.04      1270","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies.watch_log.WatchLog","title":"WatchLog","text":"<p>Parse a watch log file and process the concurrent presentation time stamps (PTS) and the local PC (CPU) time series.</p> <p>On initialization, this class:   1) Reads the provided watch log file.   2) Extracts the start and end CPU timestamps.   3) Loads all PTS/CPU rows, trims them to the maximum movie length, and      converts CPU timestamps to seconds (integer, via floor division by 1000).   4) Builds a pandas DataFrame (:attr:<code>df_pts_cpu</code>) with <code>pts</code> and <code>cpu_time</code>.</p> <p>Attributes:</p> Name Type Description <code>watch_log_file</code> <code>str</code> <p>Absolute or relative path to the watch log file.</p> <code>start_time</code> <code>int</code> <p>Start time in seconds (CPU time derived from the file).</p> <code>end_time</code> <code>int</code> <p>End time in seconds (CPU time derived from the file).</p> <code>duration</code> <code>int</code> <p>Duration in seconds, computed as <code>end_time - start_time</code>.</p> <code>pts_time_stamps</code> <code>ndarray</code> <p>Array of PTS values (floats), possibly trimmed.</p> <code>dts_time_stamps</code> <code>ndarray</code> <p>Array of CPU times in seconds (ints), possibly trimmed.</p> <code>excluded_indices</code> <code>list[int]</code> <p>Indices removed when trimming to <code>MAX_MOVIE_TIME</code>.</p> <code>df_pts_cpu</code> <code>DataFrame</code> <p>Two-column DataFrame with <code>pts</code> and <code>cpu_time</code>.</p> Notes <ul> <li>The method :meth:<code>getlines</code> reads the log file in binary mode and   returns a list of byte strings. Downstream parsing assumes whitespace-   separated fields and converts to numeric types as needed.</li> <li>CPU timestamps are divided by 1000 and cast to <code>int</code>, so any sub-second   resolution is truncated rather than rounded.</li> </ul> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>class WatchLog:\n    \"\"\"\n    Parse a watch log file and process the concurrent presentation time stamps (PTS) and the local PC (CPU) time series.\n\n    On initialization, this class:\n      1) Reads the provided watch log file.\n      2) Extracts the start and end CPU timestamps.\n      3) Loads all PTS/CPU rows, trims them to the maximum movie length, and\n         converts CPU timestamps to seconds (integer, via floor division by 1000).\n      4) Builds a pandas DataFrame (:attr:`df_pts_cpu`) with `pts` and `cpu_time`.\n\n    Attributes:\n        watch_log_file (str): Absolute or relative path to the watch log file.\n        start_time (int): Start time in seconds (CPU time derived from the file).\n        end_time (int): End time in seconds (CPU time derived from the file).\n        duration (int): Duration in seconds, computed as `end_time - start_time`.\n        pts_time_stamps (np.ndarray): Array of PTS values (floats), possibly trimmed.\n        dts_time_stamps (np.ndarray): Array of CPU times in seconds (ints), possibly trimmed.\n        excluded_indices (list[int]): Indices removed when trimming to `MAX_MOVIE_TIME`.\n        df_pts_cpu (pd.DataFrame): Two-column DataFrame with `pts` and `cpu_time`.\n\n    Notes:\n        - The method :meth:`getlines` reads the log file in **binary** mode and\n          returns a list of byte strings. Downstream parsing assumes whitespace-\n          separated fields and converts to numeric types as needed.\n        - CPU timestamps are divided by 1000 and cast to `int`, so any sub-second\n          resolution is truncated rather than rounded.\n    \"\"\"\n    def __init__(self, path_watch_log: str):\n        \"\"\"\n        Initialize the WatchLog and populate derived fields.\n\n        Args:\n            path_watch_log (str): Path to the watch log file to load.\n\n        Side Effects:\n            - Reads the file at `path_watch_log`.\n            - Populates attributes documented in the class docstring.\n        \"\"\"\n        self.watch_log_file = path_watch_log\n        self.start_time, self.end_time = self.extract_start_and_end_time()\n        self.duration = self.end_time - self.start_time\n        self.pts_time_stamps, self.dts_time_stamps, self.excluded_indices = self.get_times_from_watch_log(path_watch_log)\n        # optionally divide time stamp by 1000 to get time in seconds\n        self.dts_time_stamps = np.array([int(x / 1000) for x in self.dts_time_stamps])\n        self.df_pts_cpu = pd.DataFrame({\"pts\": self.pts_time_stamps, \"cpu_time\": self.dts_time_stamps})\n\n        self.df_pts_cpu.sort_values(['cpu_time'])\n\n    def get_start_time(self) -&gt; int:\n        \"\"\"\n        Return the start CPU time (in seconds).\n\n        Returns:\n            int: Start time in seconds.\n        \"\"\"\n        return self.start_time\n\n    def get_end_time(self) -&gt; int:\n        \"\"\"\n        Return the end CPU time (in seconds).\n\n        Returns:\n            int: End time in seconds.\n        \"\"\"\n        return self.end_time\n\n    def _set_start_time(self, new_start_time: int):\n        \"\"\"\n        Set a new start time (in seconds).\n\n        Args:\n            new_start_time (int): The new start time in seconds.\n        \"\"\"\n        self.start_time = new_start_time\n\n    def _set_end_time(self, new_end_time: int):\n        \"\"\"\n        Set a new end time (in seconds).\n\n        Args:\n            new_end_time (int): The new end time in seconds.\n        \"\"\"\n        self.end_time = new_end_time\n\n    def extract_start_and_end_time(self) -&gt; tuple[int, int]:\n        \"\"\"\n        Extract the start and end CPU timestamps from the watch log.\n\n        The function reads the file in text mode, takes the second line as the\n        \"first\" data line, and scans backward from the end to find the last line\n        beginning with ``\"pts\"``. It returns the CPU timestamps from those two\n        lines, converted to seconds by dividing by 1000 and casting to `int`.\n\n        Returns:\n            tuple[int, int]: A `(start_time_s, end_time_s)` tuple in seconds.\n\n        Raises:\n            FileNotFoundError: If the watch log file cannot be opened.\n            ValueError: If the file does not contain expected fields/format.\n        \"\"\"\n        with open(self.watch_log_file, 'r') as f:\n            lines = f.read().splitlines()\n            first_line = lines[1]\n            i = len(lines)-1\n            while not lines[i].startswith(\"pts\"):\n                i -= 1\n            last_line = lines[i]  # TODO change this to make it generally applicable\n\n        # return cpu time stamp of first and last line in watch log\n        # divide by 1000 to get seconds\n        return int(int(first_line.split()[-1]) / 1000), int(int(last_line.split()[-1]) / 1000)\n\n    def get_times_from_watch_log(self, path_watch_log: str) -&gt; tuple[np.ndarray, np.ndarray, list[int]]:\n        \"\"\"\n        Extract PTS and CPU (real) times from the watch log.\n\n        The function reads raw lines via :meth:`getlines`, parses the whitespace-\n        separated fields, and collects two arrays:\n        - PTS values as floats rounded to 2 decimals.\n        - CPU timestamps as integers (original units, **not** yet divided by 1000).\n\n        It then trims both arrays to the maximum movie duration via\n        :meth:`cut_time_to_movie_pts`.\n\n        Args:\n            path_watch_log (str): Path to the watch log file to parse.\n\n        Returns:\n            tuple[np.ndarray, np.ndarray, list[int]]: A tuple\n            ``(pts_time_stamps, cpu_time_stamps, excluded_indices)`` where\n            - `pts_time_stamps` is a float array,\n            - `cpu_time_stamps` is an int array (original unit),\n            - `excluded_indices` lists indices removed due to `MAX_MOVIE_TIME`.\n\n        Raises:\n            FileNotFoundError: If the watch log file cannot be opened.\n            ValueError: If the log lines do not match the expected 4-field format.\n        \"\"\"\n        lines = self.getlines(path_watch_log)\n        pts = []\n        time = []\n\n        for line in lines[1:]:\n            fields = line.split()\n            if len(fields) == 4:\n                pts.append(round(float(fields[1]), 2))\n                time.append(int(fields[3]))\n\n        pts = np.array(pts)\n        time = np.array(time)\n\n        return self.cut_time_to_movie_pts(pts, time)\n\n    @staticmethod\n    def cut_time_to_movie_pts(pts_time_stamps: np.ndarray, cpu_time_stamps: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray, list[int]]:\n        \"\"\"\n        Trim PTS and CPU arrays to the maximum movie length.\n\n        Any PTS value strictly greater than :data:`MAX_MOVIE_TIME` is excluded.\n        The function returns aligned arrays of the retained elements and the\n        list of excluded indices.\n\n        Args:\n            pts_time_stamps (np.ndarray): Array of PTS values (floats).\n            cpu_time_stamps (np.ndarray): Array of CPU times (ints), aligned with PTS.\n\n        Returns:\n            tuple[np.ndarray, np.ndarray, list[int]]: A tuple\n            ``(cut_down_pts, cut_down_dts, excluded_indices)``:\n            - `cut_down_pts` (np.ndarray): PTS values \u2264 `MAX_MOVIE_TIME`.\n            - `cut_down_dts` (np.ndarray): Corresponding CPU times.\n            - `excluded_indices` (list[int]): Indices removed from the original arrays.\n\n        Notes:\n            - This function assumes `pts_time_stamps` and `cpu_time_stamps` are the\n              same length and aligned 1:1.\n        \"\"\"\n        excluded_time_points_based_on_max_movie_time = [0 if x &gt; MAX_MOVIE_TIME else 1 for x in pts_time_stamps]\n\n        cut_down_pts = []\n        cut_down_dts = []\n        excluded_indices = []\n        for i in range(0, len(pts_time_stamps)):\n            if excluded_time_points_based_on_max_movie_time[i] == 1:\n                cut_down_pts.append(pts_time_stamps[i])\n                cut_down_dts.append(cpu_time_stamps[i])\n            else:\n                excluded_indices.append(i)\n\n        return np.array(cut_down_pts), np.array(cut_down_dts), excluded_indices\n\n    @staticmethod\n    def getlines(filename: str) -&gt; list[bytes]:\n        \"\"\"\n        Read a file in binary mode and return its lines.\n\n        Args:\n            filename (str): Path to the file to read.\n\n        Returns:\n            list[bytes]: Lines of the file as byte strings (no newline characters).\n\n        Raises:\n            FileNotFoundError: If the file cannot be opened.\n        \"\"\"\n        with open(filename, 'rb') as logfile:\n            data = logfile.read()\n        lines = data.splitlines()\n        return lines\n</code></pre> get_start_time \u00b6 <pre><code>get_start_time()\n</code></pre> <p>Return the start CPU time (in seconds).</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>Start time in seconds.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>def get_start_time(self) -&gt; int:\n    \"\"\"\n    Return the start CPU time (in seconds).\n\n    Returns:\n        int: Start time in seconds.\n    \"\"\"\n    return self.start_time\n</code></pre> get_end_time \u00b6 <pre><code>get_end_time()\n</code></pre> <p>Return the end CPU time (in seconds).</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>End time in seconds.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>def get_end_time(self) -&gt; int:\n    \"\"\"\n    Return the end CPU time (in seconds).\n\n    Returns:\n        int: End time in seconds.\n    \"\"\"\n    return self.end_time\n</code></pre> extract_start_and_end_time \u00b6 <pre><code>extract_start_and_end_time()\n</code></pre> <p>Extract the start and end CPU timestamps from the watch log.</p> <p>The function reads the file in text mode, takes the second line as the \"first\" data line, and scans backward from the end to find the last line beginning with <code>\"pts\"</code>. It returns the CPU timestamps from those two lines, converted to seconds by dividing by 1000 and casting to <code>int</code>.</p> <p>Returns:</p> Type Description <code>tuple[int, int]</code> <p>tuple[int, int]: A <code>(start_time_s, end_time_s)</code> tuple in seconds.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the watch log file cannot be opened.</p> <code>ValueError</code> <p>If the file does not contain expected fields/format.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>def extract_start_and_end_time(self) -&gt; tuple[int, int]:\n    \"\"\"\n    Extract the start and end CPU timestamps from the watch log.\n\n    The function reads the file in text mode, takes the second line as the\n    \"first\" data line, and scans backward from the end to find the last line\n    beginning with ``\"pts\"``. It returns the CPU timestamps from those two\n    lines, converted to seconds by dividing by 1000 and casting to `int`.\n\n    Returns:\n        tuple[int, int]: A `(start_time_s, end_time_s)` tuple in seconds.\n\n    Raises:\n        FileNotFoundError: If the watch log file cannot be opened.\n        ValueError: If the file does not contain expected fields/format.\n    \"\"\"\n    with open(self.watch_log_file, 'r') as f:\n        lines = f.read().splitlines()\n        first_line = lines[1]\n        i = len(lines)-1\n        while not lines[i].startswith(\"pts\"):\n            i -= 1\n        last_line = lines[i]  # TODO change this to make it generally applicable\n\n    # return cpu time stamp of first and last line in watch log\n    # divide by 1000 to get seconds\n    return int(int(first_line.split()[-1]) / 1000), int(int(last_line.split()[-1]) / 1000)\n</code></pre> get_times_from_watch_log \u00b6 <pre><code>get_times_from_watch_log(path_watch_log)\n</code></pre> <p>Extract PTS and CPU (real) times from the watch log.</p> <p>The function reads raw lines via :meth:<code>getlines</code>, parses the whitespace- separated fields, and collects two arrays: - PTS values as floats rounded to 2 decimals. - CPU timestamps as integers (original units, not yet divided by 1000).</p> <p>It then trims both arrays to the maximum movie duration via :meth:<code>cut_time_to_movie_pts</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path_watch_log</code> <code>str</code> <p>Path to the watch log file to parse.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>tuple[np.ndarray, np.ndarray, list[int]]: A tuple</p> <code>ndarray</code> <p><code>(pts_time_stamps, cpu_time_stamps, excluded_indices)</code> where</p> <code>list[int]</code> <ul> <li><code>pts_time_stamps</code> is a float array,</li> </ul> <code>tuple[ndarray, ndarray, list[int]]</code> <ul> <li><code>cpu_time_stamps</code> is an int array (original unit),</li> </ul> <code>tuple[ndarray, ndarray, list[int]]</code> <ul> <li><code>excluded_indices</code> lists indices removed due to <code>MAX_MOVIE_TIME</code>.</li> </ul> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the watch log file cannot be opened.</p> <code>ValueError</code> <p>If the log lines do not match the expected 4-field format.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>def get_times_from_watch_log(self, path_watch_log: str) -&gt; tuple[np.ndarray, np.ndarray, list[int]]:\n    \"\"\"\n    Extract PTS and CPU (real) times from the watch log.\n\n    The function reads raw lines via :meth:`getlines`, parses the whitespace-\n    separated fields, and collects two arrays:\n    - PTS values as floats rounded to 2 decimals.\n    - CPU timestamps as integers (original units, **not** yet divided by 1000).\n\n    It then trims both arrays to the maximum movie duration via\n    :meth:`cut_time_to_movie_pts`.\n\n    Args:\n        path_watch_log (str): Path to the watch log file to parse.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, list[int]]: A tuple\n        ``(pts_time_stamps, cpu_time_stamps, excluded_indices)`` where\n        - `pts_time_stamps` is a float array,\n        - `cpu_time_stamps` is an int array (original unit),\n        - `excluded_indices` lists indices removed due to `MAX_MOVIE_TIME`.\n\n    Raises:\n        FileNotFoundError: If the watch log file cannot be opened.\n        ValueError: If the log lines do not match the expected 4-field format.\n    \"\"\"\n    lines = self.getlines(path_watch_log)\n    pts = []\n    time = []\n\n    for line in lines[1:]:\n        fields = line.split()\n        if len(fields) == 4:\n            pts.append(round(float(fields[1]), 2))\n            time.append(int(fields[3]))\n\n    pts = np.array(pts)\n    time = np.array(time)\n\n    return self.cut_time_to_movie_pts(pts, time)\n</code></pre> cut_time_to_movie_pts <code>staticmethod</code> \u00b6 <pre><code>cut_time_to_movie_pts(pts_time_stamps, cpu_time_stamps)\n</code></pre> <p>Trim PTS and CPU arrays to the maximum movie length.</p> <p>Any PTS value strictly greater than :data:<code>MAX_MOVIE_TIME</code> is excluded. The function returns aligned arrays of the retained elements and the list of excluded indices.</p> <p>Parameters:</p> Name Type Description Default <code>pts_time_stamps</code> <code>ndarray</code> <p>Array of PTS values (floats).</p> required <code>cpu_time_stamps</code> <code>ndarray</code> <p>Array of CPU times (ints), aligned with PTS.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>tuple[np.ndarray, np.ndarray, list[int]]: A tuple</p> <code>ndarray</code> <p><code>(cut_down_pts, cut_down_dts, excluded_indices)</code>:</p> <code>list[int]</code> <ul> <li><code>cut_down_pts</code> (np.ndarray): PTS values \u2264 <code>MAX_MOVIE_TIME</code>.</li> </ul> <code>tuple[ndarray, ndarray, list[int]]</code> <ul> <li><code>cut_down_dts</code> (np.ndarray): Corresponding CPU times.</li> </ul> <code>tuple[ndarray, ndarray, list[int]]</code> <ul> <li><code>excluded_indices</code> (list[int]): Indices removed from the original arrays.</li> </ul> Notes <ul> <li>This function assumes <code>pts_time_stamps</code> and <code>cpu_time_stamps</code> are the   same length and aligned 1:1.</li> </ul> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>@staticmethod\ndef cut_time_to_movie_pts(pts_time_stamps: np.ndarray, cpu_time_stamps: np.ndarray) -&gt; tuple[np.ndarray, np.ndarray, list[int]]:\n    \"\"\"\n    Trim PTS and CPU arrays to the maximum movie length.\n\n    Any PTS value strictly greater than :data:`MAX_MOVIE_TIME` is excluded.\n    The function returns aligned arrays of the retained elements and the\n    list of excluded indices.\n\n    Args:\n        pts_time_stamps (np.ndarray): Array of PTS values (floats).\n        cpu_time_stamps (np.ndarray): Array of CPU times (ints), aligned with PTS.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray, list[int]]: A tuple\n        ``(cut_down_pts, cut_down_dts, excluded_indices)``:\n        - `cut_down_pts` (np.ndarray): PTS values \u2264 `MAX_MOVIE_TIME`.\n        - `cut_down_dts` (np.ndarray): Corresponding CPU times.\n        - `excluded_indices` (list[int]): Indices removed from the original arrays.\n\n    Notes:\n        - This function assumes `pts_time_stamps` and `cpu_time_stamps` are the\n          same length and aligned 1:1.\n    \"\"\"\n    excluded_time_points_based_on_max_movie_time = [0 if x &gt; MAX_MOVIE_TIME else 1 for x in pts_time_stamps]\n\n    cut_down_pts = []\n    cut_down_dts = []\n    excluded_indices = []\n    for i in range(0, len(pts_time_stamps)):\n        if excluded_time_points_based_on_max_movie_time[i] == 1:\n            cut_down_pts.append(pts_time_stamps[i])\n            cut_down_dts.append(cpu_time_stamps[i])\n        else:\n            excluded_indices.append(i)\n\n    return np.array(cut_down_pts), np.array(cut_down_dts), excluded_indices\n</code></pre> getlines <code>staticmethod</code> \u00b6 <pre><code>getlines(filename)\n</code></pre> <p>Read a file in binary mode and return its lines.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str</code> <p>Path to the file to read.</p> required <p>Returns:</p> Type Description <code>list[bytes]</code> <p>list[bytes]: Lines of the file as byte strings (no newline characters).</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the file cannot be opened.</p> Source code in <code>epiphyte/preprocessing/annotation/stimulus_driven_annotation/movies/watch_log.py</code> <pre><code>@staticmethod\ndef getlines(filename: str) -&gt; list[bytes]:\n    \"\"\"\n    Read a file in binary mode and return its lines.\n\n    Args:\n        filename (str): Path to the file to read.\n\n    Returns:\n        list[bytes]: Lines of the file as byte strings (no newline characters).\n\n    Raises:\n        FileNotFoundError: If the file cannot be opened.\n    \"\"\"\n    with open(filename, 'rb') as logfile:\n        data = logfile.read()\n    lines = data.splitlines()\n    return lines\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing","title":"data_preprocessing","text":""},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.binning","title":"binning","text":"<p>Binning functions for spike times and labels.  Pulls data from the database using pre-defined query functions.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.binning.bin_label","title":"bin_label","text":"<pre><code>bin_label(patient_id, session_nr, values, start_times, stop_times, bin_size, exclude_pauses)\n</code></pre> <p>Bin a label timeline against fixed-size bins.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>int</code> <p>ID of patient.</p> required <code>session_nr</code> <code>int</code> <p>Session number for the movie watching.</p> required <code>values</code> <code>ndarray</code> <p>Values of the label per segment.</p> required <code>start_times</code> <code>ndarray</code> <p>Start times (ms) per segment.</p> required <code>stop_times</code> <code>ndarray</code> <p>Stop times (ms) per segment.</p> required <code>bin_size</code> <code>int</code> <p>Size of one bin in milliseconds.</p> required <code>exclude_pauses</code> <code>bool</code> <p>If <code>True</code>, exclude paused playback intervals.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Indicator vector (one value per bin).</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/binning.py</code> <pre><code>def bin_label(\n    patient_id: int,\n    session_nr: int,\n    values: np.ndarray,\n    start_times: np.ndarray,\n    stop_times: np.ndarray,\n    bin_size: int,\n    exclude_pauses: bool,\n) -&gt; np.ndarray:\n    \"\"\"Bin a label timeline against fixed-size bins.\n\n    Args:\n        patient_id (int): ID of patient.\n        session_nr (int): Session number for the movie watching.\n        values (np.ndarray): Values of the label per segment.\n        start_times (np.ndarray): Start times (ms) per segment.\n        stop_times (np.ndarray): Stop times (ms) per segment.\n        bin_size (int): Size of one bin in milliseconds.\n        exclude_pauses (bool): If ``True``, exclude paused playback intervals.\n\n    Returns:\n        np.ndarray: Indicator vector (one value per bin).\n    \"\"\"\n    neural_rec_time = get_neural_rectime_of_patient(patient_id, session_nr) / 1000\n\n    rec_on = neural_rec_time[0]\n    rec_off = neural_rec_time[-1]\n    total_msec = rec_off - rec_on\n    total_bins = int(total_msec / bin_size)\n    bins = np.linspace(rec_on, rec_off, total_bins)\n\n    if exclude_pauses:  \n        start_times_pauses, stop_times_pauses = get_start_stop_times_pauses(patient_id, session_nr)\n        bins_no_pauses = pause_handling.rm_pauses_bins(bins, start_times_pauses, stop_times_pauses)\n        reference_vector = bins_no_pauses\n    else:\n        reference_vector = bins\n\n    if os.path.exists(\"neural_rec_time.npy\"):\n        os.remove(\"neural_rec_time.npy\")\n\n    return create_vectors_from_time_points.create_vector_from_start_stop_times_reference(reference_vector,\n                                                                                         np.array(values),\n                                                                                         np.array(start_times),\n                                                                                         np.array(stop_times))\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.binning.bin_spikes","title":"bin_spikes","text":"<pre><code>bin_spikes(patient_id, session_nr, spike_times, bin_size, exclude_pauses, output_edges=False)\n</code></pre> <p>Bin spike times into fixed-size bins.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>int</code> <p>ID of the patient.</p> required <code>session_nr</code> <code>int</code> <p>Session number of the experiment.</p> required <code>spike_times</code> <code>ndarray</code> <p>Spike timestamps (ms) as a vector.</p> required <code>bin_size</code> <code>int</code> <p>Bin size in milliseconds.</p> required <code>exclude_pauses</code> <code>bool</code> <p>If <code>True</code>, exclude paused playback intervals.</p> required <code>output_edges</code> <code>bool</code> <p>If <code>True</code>, also return the bin edges used.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[ndarray, List[ndarray]]</code> <p>Union[np.ndarray, List[np.ndarray]]: Binned spikes or <code>[binned_spikes, bin_edges]</code> if requested.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/binning.py</code> <pre><code>def bin_spikes(\n    patient_id: int,\n    session_nr: int,\n    spike_times: np.ndarray,\n    bin_size: int,\n    exclude_pauses: bool,\n    output_edges: bool = False,\n) -&gt; Union[np.ndarray, List[np.ndarray]]:\n    \"\"\"Bin spike times into fixed-size bins.\n\n    Args:\n        patient_id (int): ID of the patient.\n        session_nr (int): Session number of the experiment.\n        spike_times (np.ndarray): Spike timestamps (ms) as a vector.\n        bin_size (int): Bin size in milliseconds.\n        exclude_pauses (bool): If ``True``, exclude paused playback intervals.\n        output_edges (bool): If ``True``, also return the bin edges used.\n\n    Returns:\n        Union[np.ndarray, List[np.ndarray]]: Binned spikes or ``[binned_spikes, bin_edges]`` if requested.\n    \"\"\"\n    rectime = get_neural_rectime_of_patient(patient_id, session_nr) / 1000\n    rec_on = rectime[0]\n    rec_off = rectime[-1]\n\n    total_msec = rec_off - rec_on\n    total_bins = int(total_msec / bin_size)\n    bins = np.linspace(rec_on, rec_off, total_bins)\n\n    if exclude_pauses:\n        start_times_pauses, stop_times_pauses = get_start_stop_times_pauses(patient_id, session_nr)\n\n        # rescale pauses from microseconds to milliseconds\n        start_times_pauses = start_times_pauses / 1000\n        stop_times_pauses = stop_times_pauses / 1000\n\n        # remove the pauses from the binning edges\n        bins_no_pauses = pause_handling.rm_pauses_bins(bins, start_times_pauses, stop_times_pauses)\n        unit_no_pauses, pause_spks = pause_handling.rm_pauses_spikes(spike_times, start_times_pauses, stop_times_pauses,\n                                                                     return_intervals=True)\n        # bin spikes\n        binned_spikes, _ = np.histogram(unit_no_pauses, bins=bins_no_pauses)\n\n        # output updated to bins without pause\n        bins = bins_no_pauses\n\n    else:\n        # bin spikes\n        binned_spikes, _ = np.histogram(spike_times, bins=bins)\n\n    if output_edges:\n        ret = [binned_spikes, bins]\n    else: \n        ret = binned_spikes\n\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points","title":"create_vectors_from_time_points","text":"<p>Functions related to processing the db stored time points (start/stop/values) into vectors for use in analysis.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_index_nearest_timestamp_in_vector","title":"get_index_nearest_timestamp_in_vector","text":"<pre><code>get_index_nearest_timestamp_in_vector(vector, timestamp)\n</code></pre> <p>Finds the index of the value in a vector that is nearest to a given timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>ndarray</code> <p>The array of timestamps to search.</p> required <code>timestamp</code> <code>float</code> <p>The target timestamp to find the nearest value to.</p> required <p>Returns:     int: The index of the value in <code>vector</code> that is closest to <code>timestamp</code>.</p> Example <pre><code>vector = np.array([1.0, 2.5, 3.8, 5.0])\nidx = get_index_nearest_timestamp_in_vector(vector, 3.0)\n# idx == 1\n</code></pre> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_index_nearest_timestamp_in_vector(vector: np.ndarray, timestamp: float) -&gt; int:\n    \"\"\"Finds the index of the value in a vector that is nearest to a given timestamp.\n\n    Args:\n        vector (np.ndarray): The array of timestamps to search.\n        timestamp (float): The target timestamp to find the nearest value to.\n    Returns:\n        int: The index of the value in `vector` that is closest to `timestamp`.\n\n    Example:\n        ```python\n        vector = np.array([1.0, 2.5, 3.8, 5.0])\n        idx = get_index_nearest_timestamp_in_vector(vector, 3.0)\n        # idx == 1\n        ```\n    \"\"\"\n    return (np.abs(np.array(vector) - timestamp)).argmin()\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_nearest_value_from_vector","title":"get_nearest_value_from_vector","text":"<pre><code>get_nearest_value_from_vector(vector, timestamp)\n</code></pre> <p>Finds the value in a vector closest to a given timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>vector</code> <code>ndarray</code> <p>Array of values to search.</p> required <code>timestamp</code> <code>float</code> <p>Target timestamp to find the nearest value to.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The value from the vector that is closest to the given timestamp.</p> Example <pre><code>import numpy as np\nvector = np.array([1.0, 2.5, 3.8, 5.0])\nget_nearest_value_from_vector(vector, 4.0)\n3.8\n</code></pre> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_nearest_value_from_vector(vector: np.ndarray, timestamp: float) -&gt; float:\n    \"\"\"Finds the value in a vector closest to a given timestamp.\n\n    Args:\n        vector (np.ndarray): Array of values to search.\n        timestamp (float): Target timestamp to find the nearest value to.\n\n    Returns:\n        float: The value from the vector that is closest to the given timestamp.\n\n    Example:\n        ```python\n        import numpy as np\n        vector = np.array([1.0, 2.5, 3.8, 5.0])\n        get_nearest_value_from_vector(vector, 4.0)\n        3.8\n        ```\n    \"\"\"\n    return vector[(np.abs(np.array(vector) - (timestamp))).argmin()]  # row number with matching pts\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.create_vector_from_start_stop_times_reference_cont_watch","title":"create_vector_from_start_stop_times_reference_cont_watch","text":"<pre><code>create_vector_from_start_stop_times_reference_cont_watch(reference_vector, values, starts, stops)\n</code></pre> <p>Creates a vector aligned to a reference vector using provided start and stop times and corresponding values.</p> <p>This function generates an indicator vector where each segment, defined by its start and stop times, is filled with the associated value. The output vector is aligned to the bins defined by the reference vector, which represents the edges of the bins.</p> <p>Parameters:</p> Name Type Description Default <code>reference_vector</code> <code>ndarray</code> <p>Array of timestamps or bin edges to which the output vector will be aligned.</p> required <code>values</code> <code>ndarray</code> <p>Array of values to assign to each segment.</p> required <code>starts</code> <code>ndarray</code> <p>Array of start times for each segment.</p> required <code>stops</code> <code>ndarray</code> <p>Array of stop times for each segment.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray:  Indicator vector aligned to the reference vector, with values assigned according to the specified intervals.</p> Notes <p>Prints an error and returns -1 if the lengths of <code>values</code>, <code>starts</code>, and <code>stops</code> do not match.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def create_vector_from_start_stop_times_reference_cont_watch(\n    reference_vector: np.ndarray,\n    values: np.ndarray,\n    starts: np.ndarray,\n    stops: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Creates a vector aligned to a reference vector using provided start and stop times and corresponding values.\n\n    This function generates an indicator vector where each segment, defined by its start and stop times, is filled with the associated value. The output vector is aligned to the bins defined by the reference vector, which represents the edges of the bins.\n\n    Args:\n        reference_vector (np.ndarray): \n            Array of timestamps or bin edges to which the output vector will be aligned.\n        values (np.ndarray): \n            Array of values to assign to each segment.\n        starts (np.ndarray): \n            Array of start times for each segment.\n        stops (np.ndarray): \n            Array of stop times for each segment.\n\n    Returns:\n        np.ndarray: \n            Indicator vector aligned to the reference vector, with values assigned according to the specified intervals.\n\n    Notes:\n        Prints an error and returns -1 if the lengths of `values`, `starts`, and `stops` do not match.\n    \"\"\"\n    # check if input has the correct format\n    if not (len(values) == len(starts) == len(stops)):\n        print(\"vectors values, starts and stops have to be the same length\")\n        return -1\n\n    nr_intervals = len(values)\n    ret = []\n    for i in range(0, nr_intervals):\n        index_dts_start = get_index_nearest_timestamp_in_vector(reference_vector, starts[i])\n        index_dts_stop = get_index_nearest_timestamp_in_vector(reference_vector, stops[i])\n        length_interval = index_dts_stop - index_dts_start\n        if length_interval == 0:\n            ret = np.append(ret, [values[i]])\n        else:\n            ret = np.append(ret, [values[i]] * (length_interval))\n\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.create_vector_from_start_stop_times","title":"create_vector_from_start_stop_times","text":"<pre><code>create_vector_from_start_stop_times(patient_id, session_nr, values, starts, stops)\n</code></pre> <p>Less powerful version of the function create_vector_from_start_stop_times_reference_cont_watch</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>int</code> <p>ID of patient</p> required <code>session_nr</code> <code>int</code> <p>unique number of session of patient</p> required <code>values</code> <code>ndarray</code> <p>array indicating all values in the right order</p> required <code>starts</code> <code>ndarray</code> <p>array indicating all start times of all segments in the right order</p> required <code>stops</code> <code>ndarray</code> <p>array indicating all stop times of all segments as a vector in the right order</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Indicator function aligned to reference vector.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def create_vector_from_start_stop_times(\n    patient_id: int,\n    session_nr: int,\n    values: np.ndarray,\n    starts: np.ndarray,\n    stops: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Less powerful version of the function create_vector_from_start_stop_times_reference_cont_watch\n\n    Args:\n        patient_id (int): ID of patient\n        session_nr (int): unique number of session of patient\n        values (np.ndarray): array indicating all values in the right order\n        starts (np.ndarray): array indicating all start times of all segments in the right order\n        stops (np.ndarray): array indicating all stop times of all segments as a vector in the right order\n\n    Returns:\n        np.ndarray: Indicator function aligned to reference vector.\n\n    \"\"\"\n    neural_rec_time = get_neural_rectime_of_patient(patient_id, session_nr)\n\n    # check if input has the correct format\n    if not (len(values) == len(starts) == len(stops)):\n        print(\"vectors values, starts and stops have to be the same length\")\n        return -1\n\n    nr_intervals = len(values)\n    ret = []\n    for i in range(0, nr_intervals):\n        index_dts_start = get_index_nearest_timestamp_in_vector(neural_rec_time, starts[i])\n        index_dts_stop = get_index_nearest_timestamp_in_vector(neural_rec_time, stops[i])\n        length_interval = len(neural_rec_time[index_dts_start:index_dts_stop + 1])\n        ret = np.append(ret, [values[i]] * length_interval)\n\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_start_stop_times_from_label","title":"get_start_stop_times_from_label","text":"<pre><code>get_start_stop_times_from_label(neural_rec_time, patient_aligned_label)\n</code></pre> <p>This function extracts the start and stop times from a label. <code>patient_aligned_label</code> has to have the same length as <code>neural_rec_time</code> The time points in the resulting vectors are in neural recording time</p> <p>Parameters:</p> Name Type Description Default <code>neural_rec_time</code> <code>ndarray</code> <p>array indicating neural recording time</p> required <code>patient_aligned_label</code> <code>ndarray</code> <p>array indicating label aligned to patient time</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple[list, list, list]</code> <p><code>(values, start_times, stop_times)</code> arrays.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_start_stop_times_from_label(\n    neural_rec_time: np.ndarray, patient_aligned_label: np.ndarray\n) -&gt; tuple[list, list, list]:\n    \"\"\"\n    This function extracts the start and stop times from a label.\n    `patient_aligned_label` has to have the same length as `neural_rec_time`\n    The time points in the resulting vectors are in neural recording time\n\n    Args:\n        neural_rec_time (np.ndarray): array indicating neural recording time\n        patient_aligned_label (np.ndarray): array indicating label aligned to patient time\n\n    Returns:\n        tuple: ``(values, start_times, stop_times)`` arrays.\n    \"\"\"\n    tmp = patient_aligned_label[0]\n    values = [tmp]\n    start_times = [neural_rec_time[0]]\n    stop_times = []\n    for i in range(1, len(patient_aligned_label)):\n        if not patient_aligned_label[i] == tmp:\n            values.append(patient_aligned_label[i])\n            start_times.append(neural_rec_time[i])\n            stop_times.append(neural_rec_time[i - 1])\n            tmp = patient_aligned_label[i]\n    stop_times.append(neural_rec_time[-1])\n\n    return values, start_times, stop_times\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_bins_excl_pauses","title":"get_bins_excl_pauses","text":"<pre><code>get_bins_excl_pauses(patient_id, session_nr, neural_rec_time, bin_size)\n</code></pre> <p>Returns edges of bins for a given patient with the right bin size, while excluding bins where the movie was paused.</p> <p>Parameters:</p> Name Type Description Default <code>patient_id</code> <code>int</code> <p>ID of patient</p> required <code>session_nr</code> <code>int</code> <p>session number</p> required <code>neural_rec_time</code> <code>ndarray</code> <p>vector of neural recording time of patient</p> required <code>bin_size</code> <code>int</code> <p>size of bin in milliseconds</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: Edges of bins, excluding paused intervals.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_bins_excl_pauses(\n    patient_id: int, session_nr: int, neural_rec_time: np.ndarray, bin_size: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Returns edges of bins for a given patient with the right bin size, while excluding bins where the movie was paused.\n\n    Args:\n        patient_id (int): ID of patient\n        session_nr (int): session number\n        neural_rec_time (np.ndarray): vector of neural recording time of patient\n        bin_size (int): size of bin in milliseconds\n\n    Returns:\n        np.ndarray: Edges of bins, excluding paused intervals.\n    \"\"\"\n    start_times_pauses, stop_times_pauses = get_start_stop_times_pauses(patient_id, session_nr)\n    rec_on = neural_rec_time[0]\n    rec_off = neural_rec_time[-1]\n    total_msec = rec_off - rec_on\n    total_bins = int(total_msec / bin_size)\n    bins = np.linspace(rec_on, rec_off, total_bins)\n    bins_no_pauses = pause_handling.rm_pauses_bins(bins, start_times_pauses, stop_times_pauses)\n\n    return bins_no_pauses\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.create_vector_from_start_stop_times_reference","title":"create_vector_from_start_stop_times_reference","text":"<pre><code>create_vector_from_start_stop_times_reference(reference_vector, values, starts, stops)\n</code></pre> <p>Create an indicator function from values, start and stop times of a label aligned to a reference vector of time points.  Used to create an indicator function (vector indicating if a labelled feature was present during the interval between two time points) from a set of bin edges. </p> <p>Parameters:</p> Name Type Description Default <code>reference_vector</code> <code>ndarray</code> <p>vector of linearly spaced time points (e.g. bin edges)</p> required <code>values</code> <code>ndarray</code> <p>values indicating presence or absence of a labeled feature</p> required <code>starts</code> <code>ndarray</code> <p>start times of the corresponding values </p> required <code>stops</code> <code>ndarray</code> <p>stop times of the corresponding values</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: indicator function vector.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def create_vector_from_start_stop_times_reference(\n    reference_vector: np.ndarray,\n    values: np.ndarray,\n    starts: np.ndarray,\n    stops: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Create an indicator function from values, start and stop times of a label aligned to a reference vector of time points. \n    Used to create an indicator function (vector indicating if a labelled feature was present during the interval between two time points) from a set of bin edges. \n\n    Args:\n        reference_vector (np.ndarray): vector of linearly spaced time points (e.g. bin edges)\n        values (np.ndarray): values indicating presence or absence of a labeled feature\n        starts (np.ndarray): start times of the corresponding values \n        stops (np.ndarray): stop times of the corresponding values\n\n    Returns:\n        np.ndarray: indicator function vector.\n    \"\"\"\n    # check if input has the correct format\n    if not (len(values) == len(starts) == len(stops)):\n        print(\"vectors values, starts and stops have to be the same length\")\n        return -1\n\n    ret = []\n\n    for i in range(0, len(reference_vector) - 1):\n        value = get_value_in_time_frame(time_point1=reference_vector[i], time_point2=reference_vector[i + 1],\n                                        values=values, start_times=starts, end_times=stops)\n        ret.append(value)\n\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_value_matching_start_point","title":"get_value_matching_start_point","text":"<pre><code>get_value_matching_start_point(time_point, values, start_times, end_times)\n</code></pre> <p>Finds the value in a vector that corresponds to the closest start time less than or equal to a given time point.</p> <p>Parameters:</p> Name Type Description Default <code>time_point</code> <code>float</code> <p>the time point for which the value shall be searched</p> required <code>values</code> <code>ndarray</code> <p>vector with all values</p> required <code>start_times</code> <code>ndarray</code> <p>vector with all start times</p> required <code>end_times</code> <code>ndarray</code> <p>vector with all stop times</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Value corresponding to the time point.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_value_matching_start_point(\n    time_point: float, values: np.ndarray, start_times: np.ndarray, end_times: np.ndarray\n) -&gt; float:\n    \"\"\"\n    Finds the value in a vector that corresponds to the closest start time less than or equal to a given time point.\n\n    Args:\n        time_point (float): the time point for which the value shall be searched\n        values (np.ndarray): vector with all values\n        start_times (np.ndarray): vector with all start times\n        end_times (np.ndarray): vector with all stop times\n\n    Returns:\n        float: Value corresponding to the time point.\n\n    \"\"\"\n    index = get_index_nearest_timestamp_in_vector(start_times, time_point)\n    if time_point &lt; start_times[index]:\n        if time_point &lt;= start_times[0]:\n            return index\n        index -= 1\n    return values[index]\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_value_matching_stop_point","title":"get_value_matching_stop_point","text":"<pre><code>get_value_matching_stop_point(time_point, values, start_times, end_times)\n</code></pre> <p>Finds the value in a vector that corresponds to the closest stop time less than or equal to a given time point.</p> <p>Parameters:</p> Name Type Description Default <code>time_point</code> <code>float</code> <p>the time point for which the value shall be searched</p> required <code>values</code> <code>ndarray</code> <p>vector with all values</p> required <code>start_times</code> <code>ndarray</code> <p>vector with all start times</p> required <code>end_times</code> <code>ndarray</code> <p>vector with all stop times</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>Value corresponding to the time point.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_value_matching_stop_point(\n    time_point: float, values: np.ndarray, start_times: np.ndarray, end_times: np.ndarray\n) -&gt; float:\n    \"\"\"\n    Finds the value in a vector that corresponds to the closest stop time less than or equal to a given time point.\n\n    Args:\n        time_point (float): the time point for which the value shall be searched\n        values (np.ndarray): vector with all values\n        start_times (np.ndarray): vector with all start times\n        end_times (np.ndarray): vector with all stop times\n\n    Returns:\n        float: Value corresponding to the time point.\n    \"\"\"\n\n    index = get_index_nearest_timestamp_in_vector(end_times, time_point)\n    if time_point &gt;= end_times[index]:\n        if time_point &gt;= end_times[-1]:\n            return index\n        index += 1\n    return values[index]\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_index_matching_start_point","title":"get_index_matching_start_point","text":"<pre><code>get_index_matching_start_point(time_point, values, start_times, end_times)\n</code></pre> <p>Finds the index of the start point that is the closest start point smaller than 'time_point'.</p> <p>Parameters:</p> Name Type Description Default <code>time_point</code> <code>float</code> <p>the time point for which the value shall be searched</p> required <code>values</code> <code>ndarray</code> <p>vector with all values</p> required <code>start_times</code> <code>ndarray</code> <p>vector with all start times</p> required <code>end_times</code> <code>ndarray</code> <p>vector with all stop times</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>int</code> <p>Value corresponding to the time point.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_index_matching_start_point(\n    time_point: float, values: np.ndarray, start_times: np.ndarray, end_times: np.ndarray\n) -&gt; int:\n    \"\"\"\n    Finds the index of the start point that is the closest start point smaller than 'time_point'.\n\n    Args:\n        time_point (float): the time point for which the value shall be searched\n        values (np.ndarray): vector with all values\n        start_times (np.ndarray): vector with all start times\n        end_times (np.ndarray): vector with all stop times\n\n    Returns:\n        float: Value corresponding to the time point.\n    \"\"\"\n    index = get_index_nearest_timestamp_in_vector(start_times, time_point)\n    if time_point &lt; start_times[index]:\n        if time_point &lt; start_times[0]:\n            return index\n        index -= 1\n    return index\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_index_matching_stop_point","title":"get_index_matching_stop_point","text":"<pre><code>get_index_matching_stop_point(time_point, values, start_times, end_times)\n</code></pre> <p>Finds the index of the stop point that is the closest stop point greater than 'time_point'.</p> <p>Parameters:</p> Name Type Description Default <code>time_point</code> <code>float</code> <p>the time point for which the value shall be searched</p> required <code>values</code> <code>ndarray</code> <p>vector with all values</p> required <code>start_times</code> <code>ndarray</code> <p>vector with all start times</p> required <code>end_times</code> <code>ndarray</code> <p>vector with all stop times</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>int</code> <p>Value corresponding to the time point.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_index_matching_stop_point(\n    time_point: float, values: np.ndarray, start_times: np.ndarray, end_times: np.ndarray\n) -&gt; int:\n    \"\"\"\n    Finds the index of the stop point that is the closest stop point greater than 'time_point'.\n\n    Args:\n        time_point (float): the time point for which the value shall be searched\n        values (np.ndarray): vector with all values\n        start_times (np.ndarray): vector with all start times\n        end_times (np.ndarray): vector with all stop times\n\n    Returns:\n        float: Value corresponding to the time point.\n    \"\"\"\n    index = get_index_nearest_timestamp_in_vector(end_times, time_point)\n    if time_point &gt;= end_times[index]:\n        if time_point &gt;= end_times[-1]:\n            return index\n        index += 1\n    return index\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.create_vectors_from_time_points.get_value_in_time_frame","title":"get_value_in_time_frame","text":"<pre><code>get_value_in_time_frame(time_point1, time_point2, values, start_times, end_times)\n</code></pre> <p>Finds the value that is most represented between two time points. Needed for creating an indicator function from a set of bin edges with a bin size longer than the frame length, as a bin could contain multiple segments with different values.</p> <p>Parameters:</p> Name Type Description Default <code>time_point1</code> <code>float</code> <p>lower bound of time frame         </p> required <code>time_point2</code> <code>float</code> <p>upper bound of time frame that is regarded</p> required <code>values</code> <code>ndarray</code> <p>vector with all values</p> required <code>start_times</code> <code>ndarray</code> <p>vector with all start time points</p> required <code>end_times</code> <code>ndarray</code> <p>vector with all stop time points</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>value most represented within the time frame.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/create_vectors_from_time_points.py</code> <pre><code>def get_value_in_time_frame(\n    time_point1: float,\n    time_point2: float,\n    values: np.ndarray,\n    start_times: np.ndarray,\n    end_times: np.ndarray,\n) -&gt; float:\n    \"\"\"\n    Finds the value that is most represented between two time points.\n    Needed for creating an indicator function from a set of bin edges with a bin size longer than the frame length, as a bin could contain multiple segments with different values.\n\n    Args:\n        time_point1 (float): lower bound of time frame         \n        time_point2 (float): upper bound of time frame that is regarded\n        values (np.ndarray): vector with all values\n        start_times (np.ndarray): vector with all start time points\n        end_times (np.ndarray): vector with all stop time points\n\n    Returns:\n        float: value most represented within the time frame.\n    \"\"\"\n    index_1 = get_index_matching_start_point(time_point1, values, start_times, end_times)\n    index_2 = get_index_matching_stop_point(time_point2, values, start_times, end_times)\n    if index_1 == index_2:\n        return values[index_1]\n    else:\n        df = pd.DataFrame(columns=[\"value\", \"weighing\"])\n        # first interval: add weighing of end_point of this segment - timepoint1\n        df = df.append({\"value\": values[index_1], \"weighing\": end_times[index_1] - time_point1}, ignore_index=True)\n        # all in between intervals: add weighing of length of segment\n        for i in range(1, index_2 - index_1):\n            if values[index_1 + i] in df.values:\n                df.loc[df[\"value\"] == values[index_1 + i], \"weighing\"] += end_times[index_1 + i] - start_times[\n                    index_1 + i]\n            df = df.append(\n                {\"value\": values[index_1 + i], \"weighing\": end_times[index_1 + i] - start_times[index_1 + i]},\n                ignore_index=True)\n        # last interval: add weighing of timepoint2 - start_point of this segment\n        df = df.append({\"value\": values[index_2], \"weighing\": time_point2 - start_times[index_2]}, ignore_index=True)\n\n    return list(df[df['weighing'] == df['weighing'].max()][\"value\"])[0]\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils","title":"data_utils","text":"<p>I/O and time-alignment utilities for Neuralynx-like event logs.</p> <p>Provides helpers to read <code>.nev</code> (and mock <code>.npy</code>) event files, parse watchlogs/DAQ logs, and linearly align between local computer time and neural recording system time.</p>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.TimeConversion","title":"TimeConversion","text":"<p>               Bases: <code>object</code></p> <p>Linear mapping between CPU time and neural recording time.</p> <p>Enables conversion of stimulus timestamps (e.g., movie frames) to the spike time scale.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>class TimeConversion(object):\n    \"\"\"Linear mapping between CPU time and neural recording time.\n\n    Enables conversion of stimulus timestamps (e.g., movie frames) to the spike\n    time scale.\n    \"\"\"\n\n    def __init__(self, path_to_wl: str | Path, path_to_dl: str | Path,\n                 path_to_events: str | Path) -&gt; None:\n        self.path_watchlog = path_to_wl\n        self.path_daqlog = path_to_dl\n        self.path_evts = path_to_events\n\n    def convert(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Compute mapping and convert watchlog times to DAQ times.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray, np.ndarray]: ``(pts_seconds, dts_ms, cpu_time_us)`` arrays.\n        \"\"\"\n\n        event_mat = process_events(nev_read(self.path_evts))\n        m, b = get_coeff(event_mat, self.path_daqlog)\n        pts, cpu_time = read_watchlog(self.path_watchlog)\n\n        # first convert cpu time to recording system time\n        daq_time = cpu_time * m + b\n\n        return pts, daq_time, cpu_time\n\n    def convert_pauses(self) -&gt; Tuple[List[float], List[float]]:\n        \"\"\"Convert pause CPU timestamps to neural recording time.\n\n        Returns:\n            Tuple[List[float], List[float]]: ``(starts_ms, stops_ms)`` lists in neural recording time.\n        \"\"\"\n        start, stop = read_watchlog_pauses(self.path_watchlog)\n        event_mat = process_events(nev_read(self.path_evts))\n        m, b = get_coeff(event_mat, self.path_daqlog)\n\n        convert_start = [time * m + b for i, time in enumerate(start)]\n        convert_stop = [time * m + b for i, time in enumerate(stop)]\n\n        #### NOTE: depending on the output set-up, comment/uncomment. \n        ##### Generally, can use the highlights options on the interactive plot\n        ##### to indicate if time-scales are not coherent between the data and the \n        ##### pauses. \n        #convert_start = make_msec(convert_start)\n        #convert_stop = make_msec(convert_stop)\n\n        return convert_start, convert_stop\n\n\n    def convert_skips(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n        \"\"\"Detect skips and return start/stop/value segments in DAQ time.\n\n        Returns:\n            Tuple[np.ndarray, np.ndarray, np.ndarray]: ``(start_values_ms, stop_values_ms, values_idx)`` arrays.\n        \"\"\"\n        pts, daq_time, cpu_time = self.convert()\n\n        threshold = 1\n        max_jump = np.max(np.abs(np.diff(pts)))\n\n\n        if max_jump &gt;= threshold:\n            print(\"There is a skip in the movie frame playback that is bigger than {} frames.\\nThe biggest skip is {} frames.\".format((threshold / 0.04), (max_jump / 0.04)))\n\n            # list of indices where the pts jumped by 25+ frames\n            beyond_threshold = np.where(np.abs(np.diff(pts)) &gt; threshold)[0]\n            print(\"Timepoints of skips, in neural_rec_time: {}\".format(daq_time[beyond_threshold]))\n\n            ## setting up start/stop values\n            timepoints_of_skips = []\n            timepoints_of_skips.append(daq_time[0]) # set first start point to the start of the rec_log\n\n            for index in beyond_threshold:\n                timepoints_of_skips.append(daq_time[index])\n                timepoints_of_skips.append(daq_time[index + 1])\n\n            timepoints_of_skips.append(daq_time[-1])\n\n            ## specifying starts and stops from timepoint collection \n            start_values = timepoints_of_skips[0:-1:2]\n            stop_values = timepoints_of_skips[1::2]\n            values = np.array(range(0, len(start_values)))\n            print(\"Start timepoints: {}\".format(start_values))\n            print(\"Stop timepoints: {}\".format(stop_values))\n            print(\"\")\n\n        else:\n            print(\"There's not any skips in the movie frame playback that are bigger than {} frames.\\nThe biggest skip is {} frames.\".format((threshold / 0.04), (max_jump / 0.04)))\n            print(\" \")\n            start_values = daq_time[0]\n            stop_values = daq_time[-1]\n            values = np.array([0])\n\n\n        return start_values, stop_values, values\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.TimeConversion.convert","title":"convert","text":"<pre><code>convert()\n</code></pre> <p>Compute mapping and convert watchlog times to DAQ times.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray, np.ndarray]: <code>(pts_seconds, dts_ms, cpu_time_us)</code> arrays.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def convert(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Compute mapping and convert watchlog times to DAQ times.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray, np.ndarray]: ``(pts_seconds, dts_ms, cpu_time_us)`` arrays.\n    \"\"\"\n\n    event_mat = process_events(nev_read(self.path_evts))\n    m, b = get_coeff(event_mat, self.path_daqlog)\n    pts, cpu_time = read_watchlog(self.path_watchlog)\n\n    # first convert cpu time to recording system time\n    daq_time = cpu_time * m + b\n\n    return pts, daq_time, cpu_time\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.TimeConversion.convert_pauses","title":"convert_pauses","text":"<pre><code>convert_pauses()\n</code></pre> <p>Convert pause CPU timestamps to neural recording time.</p> <p>Returns:</p> Type Description <code>Tuple[List[float], List[float]]</code> <p>Tuple[List[float], List[float]]: <code>(starts_ms, stops_ms)</code> lists in neural recording time.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def convert_pauses(self) -&gt; Tuple[List[float], List[float]]:\n    \"\"\"Convert pause CPU timestamps to neural recording time.\n\n    Returns:\n        Tuple[List[float], List[float]]: ``(starts_ms, stops_ms)`` lists in neural recording time.\n    \"\"\"\n    start, stop = read_watchlog_pauses(self.path_watchlog)\n    event_mat = process_events(nev_read(self.path_evts))\n    m, b = get_coeff(event_mat, self.path_daqlog)\n\n    convert_start = [time * m + b for i, time in enumerate(start)]\n    convert_stop = [time * m + b for i, time in enumerate(stop)]\n\n    #### NOTE: depending on the output set-up, comment/uncomment. \n    ##### Generally, can use the highlights options on the interactive plot\n    ##### to indicate if time-scales are not coherent between the data and the \n    ##### pauses. \n    #convert_start = make_msec(convert_start)\n    #convert_stop = make_msec(convert_stop)\n\n    return convert_start, convert_stop\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.TimeConversion.convert_skips","title":"convert_skips","text":"<pre><code>convert_skips()\n</code></pre> <p>Detect skips and return start/stop/value segments in DAQ time.</p> <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray, np.ndarray]: <code>(start_values_ms, stop_values_ms, values_idx)</code> arrays.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def convert_skips(self) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Detect skips and return start/stop/value segments in DAQ time.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray, np.ndarray]: ``(start_values_ms, stop_values_ms, values_idx)`` arrays.\n    \"\"\"\n    pts, daq_time, cpu_time = self.convert()\n\n    threshold = 1\n    max_jump = np.max(np.abs(np.diff(pts)))\n\n\n    if max_jump &gt;= threshold:\n        print(\"There is a skip in the movie frame playback that is bigger than {} frames.\\nThe biggest skip is {} frames.\".format((threshold / 0.04), (max_jump / 0.04)))\n\n        # list of indices where the pts jumped by 25+ frames\n        beyond_threshold = np.where(np.abs(np.diff(pts)) &gt; threshold)[0]\n        print(\"Timepoints of skips, in neural_rec_time: {}\".format(daq_time[beyond_threshold]))\n\n        ## setting up start/stop values\n        timepoints_of_skips = []\n        timepoints_of_skips.append(daq_time[0]) # set first start point to the start of the rec_log\n\n        for index in beyond_threshold:\n            timepoints_of_skips.append(daq_time[index])\n            timepoints_of_skips.append(daq_time[index + 1])\n\n        timepoints_of_skips.append(daq_time[-1])\n\n        ## specifying starts and stops from timepoint collection \n        start_values = timepoints_of_skips[0:-1:2]\n        stop_values = timepoints_of_skips[1::2]\n        values = np.array(range(0, len(start_values)))\n        print(\"Start timepoints: {}\".format(start_values))\n        print(\"Stop timepoints: {}\".format(stop_values))\n        print(\"\")\n\n    else:\n        print(\"There's not any skips in the movie frame playback that are bigger than {} frames.\\nThe biggest skip is {} frames.\".format((threshold / 0.04), (max_jump / 0.04)))\n        print(\" \")\n        start_values = daq_time[0]\n        stop_values = daq_time[-1]\n        values = np.array([0])\n\n\n    return start_values, stop_values, values\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.nev_read","title":"nev_read","text":"<pre><code>nev_read(filename)\n</code></pre> <p>Read event timestamps and codes from <code>.nev</code> or mock <code>.npy</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to <code>.nev</code> or mock <code>.npy</code> array.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: <code>(timestamp, nttl)</code> array of shape <code>(N, 2)</code>.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def nev_read(filename: str | Path) -&gt; np.ndarray:\n    \"\"\"Read event timestamps and codes from ``.nev`` or mock ``.npy`` file.\n\n    Args:\n        filename (str | Path): Path to ``.nev`` or mock ``.npy`` array.\n\n    Returns:\n        np.ndarray: ``(timestamp, nttl)`` array of shape ``(N, 2)``.\n    \"\"\"\n    filename = Path(filename)\n\n    if filename.suffix.lower() == \".nev\":\n        eventmap = np.memmap(filename, dtype=nev_type, mode='r', offset=NLX_OFFSET)\n        ret = np.array([eventmap['timestamp'], eventmap['nttl']]).T\n    elif filename.suffix.lower() == \".npy\":\n        ret = np.load(filename)\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.nev_string_read","title":"nev_string_read","text":"<pre><code>nev_string_read(filename)\n</code></pre> <p>Read event timestamps and strings from a <code>.nev</code> file.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to <code>.nev</code> file.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: <code>(timestamp, ev_string)</code> array of shape <code>(N, 2)</code>.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def nev_string_read(filename: str | Path) -&gt; np.ndarray:\n    \"\"\"Read event timestamps and strings from a ``.nev`` file.\n\n    Args:\n        filename (str | Path): Path to ``.nev`` file.\n\n    Returns:\n        np.ndarray: ``(timestamp, ev_string)`` array of shape ``(N, 2)``.\n    \"\"\"\n    eventmap = np.memmap(filename, dtype=nev_type, mode='r', offset=NLX_OFFSET)\n    return np.array([eventmap['timestamp'], eventmap['ev_string']]).T\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.process_movie_events","title":"process_movie_events","text":"<pre><code>process_movie_events(ev_array)\n</code></pre> <p>Filter raw event rows to the movie-event sequence.</p> <p>Parameters:</p> Name Type Description Default <code>ev_array</code> <code>ndarray</code> <p><code>(timestamp, code)</code> array.</p> required <p>Returns:     np.ndarray: Filtered movie event rows.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def process_movie_events(ev_array: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Filter raw event rows to the movie-event sequence.\n\n    Args:\n        ev_array (np.ndarray): ``(timestamp, code)`` array.\n    Returns:\n        np.ndarray: Filtered movie event rows.\n    \"\"\"\n\n    wait_for = [1]\n    last = 0\n    keep = []\n\n    for row in ev_array:\n        code = row[1].astype(int)\n\n        if code not in wait_for:\n            continue\n\n        elif code in [1, 2, 4, 8, 16, 32, 64, 128]:\n            wait_for = [0]\n            keep.append(row)\n\n        elif code == 0:\n\n            if last == 128:\n                wait_for = [1]\n            elif last in [1, 2, 4, 8, 16, 32, 64]:\n                wait_for = [last * 2]\n\n        last = code\n\n    return np.array(keep)\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.process_events","title":"process_events","text":"<pre><code>process_events(ev_array)\n</code></pre> <p>Extract movie-event rows from a full event array.</p> <p>Parameters:</p> Name Type Description Default <code>ev_array</code> <code>ndarray</code> <p>Full event array.</p> required <p>Returns:     np.ndarray: Movie-event subset.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def process_events(ev_array: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Extract movie-event rows from a full event array.\n\n    Args:\n        ev_array (np.ndarray): Full event array.\n    Returns:\n        np.ndarray: Movie-event subset.\n    \"\"\"\n\n    if float(101) in ev_array[:, 1]:\n        onsets = (ev_array[:, 1] == 101).nonzero()[0]\n        n_101 = onsets.shape[0]\n\n        # use the first 8 as marker that screening is over\n        first_8 = (ev_array[:, 1] == 8).nonzero()[0][0]\n\n        # go back to last 4 before first 8\n        last_4 = (ev_array[:first_8, 1] == 4).nonzero()[0][-2]\n        # print(first_8, last_4)\n\n        assert n_101 in (4, 8)\n\n        movie_events = ev_array[last_4 + 1:onsets[4], :]\n        ret = process_movie_events(movie_events)\n\n    elif not float(0) in ev_array[:,1]:\n        ret = ev_array\n\n    return ret\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.getlines","title":"getlines","text":"<pre><code>getlines(filename)\n</code></pre> <p>Read a text file and return the raw lines as bytes.</p> <p>Parameters:</p> Name Type Description Default <code>filename</code> <code>str | Path</code> <p>Path to file.</p> required <p>Returns:</p> Type Description <code>list[bytes]</code> <p>list[bytes]: List of lines (bytes).</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def getlines(filename: str | Path) -&gt; list[bytes]:\n    \"\"\"Read a text file and return the raw lines as bytes.\n\n    Args:\n        filename (str | Path): Path to file.\n\n    Returns:\n        list[bytes]: List of lines (bytes).\n    \"\"\"\n\n    with open(filename, 'rb') as logfile:\n        data = logfile.read()\n    lines = data.splitlines()\n    return lines\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.read_watchlog","title":"read_watchlog","text":"<pre><code>read_watchlog(watchlogfile)\n</code></pre> <p>Extract PTS (s) and CPU times (\u00b5s) from a watchlog.</p> <p>Parameters:</p> Name Type Description Default <code>watchlogfile</code> <code>str | Path</code> <p>Path to watchlog created by ffmpeg wrapper.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray]: Tuple <code>(pts_seconds, cpu_time_us)</code>.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def read_watchlog(watchlogfile: str | Path) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Extract PTS (s) and CPU times (\u00b5s) from a watchlog.\n\n    Args:\n        watchlogfile (str | Path): Path to watchlog created by ffmpeg wrapper.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray]: Tuple ``(pts_seconds, cpu_time_us)``.\n    \"\"\"\n    lines = getlines(watchlogfile)\n    pts = []\n    time = []\n\n    for line in lines[1:]:\n        fields  = line.split()\n        if len(fields) == 4:\n            pts.append(float(fields[1]))\n            time.append(int(fields[3]))\n\n    pts = np.array(pts)\n    time = np.array(time)\n    return pts, time\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.read_watchlog_pauses","title":"read_watchlog_pauses","text":"<pre><code>read_watchlog_pauses(watchlogfile)\n</code></pre> <p>Find pause segments in the watchlog.</p> <p>Parameters:</p> Name Type Description Default <code>watchlogfile</code> <code>str | Path</code> <p>Path to pts/CPU watchlog.</p> required <p>Returns:     Tuple[List[int], List[int]]: <code>(start_times_us, stop_times_us)</code> lists.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def read_watchlog_pauses(watchlogfile: str | Path) -&gt; Tuple[List[int], List[int]]:\n    \"\"\"Find pause segments in the watchlog.\n\n    Args:\n        watchlogfile (str | Path): Path to pts/CPU watchlog.\n    Returns:\n        Tuple[List[int], List[int]]: ``(start_times_us, stop_times_us)`` lists.\n    \"\"\"\n    lines = getlines(watchlogfile)\n    start_time = []\n    stop_time = []\n\n    for i, line in enumerate(lines):\n        fields = line.split()\n        first = str(fields[0])\n        # print(first)\n        if \"Pausing\" in first:\n            # print(line)\n            start = i - 1\n            start_line = lines[start]\n            # print(start_line)\n            start_fields = start_line.split()\n            start_time.append(int(start_fields[3]))\n\n        if \"Continuing\" in first:\n            # print(line)\n            stop = i + 1\n            stop_line = lines[stop]\n            stop_fields = stop_line.split()\n            stop_time.append(int(stop_fields[3]))\n\n        if \"Properly\" in first:\n            start = i - 3\n            start_line = lines[start]\n            # print(start_line)\n            start_fields = start_line.split()\n            stop_time.append(int(start_fields[3]))\n\n    return start_time, stop_time\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.read_daqlog","title":"read_daqlog","text":"<pre><code>read_daqlog(daqlogfile)\n</code></pre> <p>Extract DAQ values and pre/post times.</p> <p>Parameters:</p> Name Type Description Default <code>daqlogfile</code> <code>str | Path</code> <p>Path to DAQ log file.</p> required <p>Returns:</p> Type Description <code>Tuple[ndarray, ndarray, ndarray]</code> <p>Tuple[np.ndarray, np.ndarray, np.ndarray]: <code>(values, pretime_us, posttime_us)</code> arrays.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def read_daqlog(daqlogfile: str | Path) -&gt; Tuple[np.ndarray, np.ndarray, np.ndarray]:\n    \"\"\"Extract DAQ values and pre/post times.\n\n    Args:\n        daqlogfile (str | Path): Path to DAQ log file.\n\n    Returns:\n        Tuple[np.ndarray, np.ndarray, np.ndarray]: ``(values, pretime_us, posttime_us)`` arrays.\n    \"\"\"\n    lines = getlines(daqlogfile)\n    values = []\n    pretime = []\n    posttime = []\n\n    for line in lines[3:]:\n        fields = line.split()\n        if len(fields) == 4:\n            values.append(int(fields[0]))\n            pretime.append(int(fields[2]))\n            posttime.append(int(fields[3]))\n\n    values = np.array(values)\n    pretime = np.array(pretime)\n    posttime = np.array(posttime)\n\n    return values, pretime, posttime\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.get_coeff","title":"get_coeff","text":"<pre><code>get_coeff(event_mat, daqlogfile)\n</code></pre> <p>Fit a linear mapping from DAQ post times to event timestamps.</p> <p>Loads logs, validates events, and returns slope/intercept.</p> <p>Parameters:</p> Name Type Description Default <code>event_mat</code> <code>ndarray</code> <p><code>(timestamp, code)</code> event array.</p> required <code>daqlogfile</code> <code>str | Path</code> <p>Path to DAQ log file.</p> required <p>Returns:     np.ndarray: <code>[m, b]</code> array such that <code>timestamp = m*post + b</code>.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def get_coeff(event_mat: np.ndarray, daqlogfile: str | Path) -&gt; np.ndarray:\n    \"\"\"Fit a linear mapping from DAQ post times to event timestamps.\n\n    Loads logs, validates events, and returns slope/intercept.\n\n    Args:\n        event_mat (np.ndarray): ``(timestamp, code)`` event array.\n        daqlogfile (str | Path): Path to DAQ log file.\n    Returns:\n        np.ndarray: ``[m, b]`` array such that ``timestamp = m*post + b``.\n    \"\"\"\n    eventTimes, eventValues = event_mat[:,0],event_mat[:,1]\n    daqValues, daqPretimes, daqPosttimes = read_daqlog(daqlogfile)\n\n    # check events:\n    EventErrors = (eventValues != daqValues).sum()\n    if EventErrors:\n        raise(Warning('Events from 2 logs do not match, {} errors.'.\n                      format(EventErrors)))\n\n    # check that daq is quick enough\n    diffs = daqPosttimes - daqPretimes\n    print(\"Min Daq Diff: {:.1f} ms, Max Daq Diff: {:.1f} ms\".\n          format(diffs.min()/1e3, diffs.max()/1e3))\n\n    # convert daqPosttimes to eventTimes by polyfit, check error\n    m, b = np.polyfit(daqPosttimes, eventTimes, 1)\n    fitdaq = m*daqPosttimes + b\n    maxFitError = np.abs(fitdaq-eventTimes).max()/1e3\n\n    print(\"Maximum Error after Event fit: {:.1f} ms\".format(maxFitError))\n\n    return np.array([m, b])\n</code></pre>"},{"location":"reference/preprocessing/#epiphyte.preprocessing.data_preprocessing.data_utils.make_msec","title":"make_msec","text":"<pre><code>make_msec(list_usec)\n</code></pre> <p>Convert a list from microseconds to milliseconds.</p> <p>Parameters:</p> Name Type Description Default <code>list_usec</code> <code>list[int]</code> <p>Times in microseconds.</p> required <p>Returns:     list[float]: Times in milliseconds.</p> Source code in <code>epiphyte/preprocessing/data_preprocessing/data_utils.py</code> <pre><code>def make_msec(list_usec: list[int]) -&gt; list[float]:\n    \"\"\"Convert a list from microseconds to milliseconds.\n\n    Args:\n        list_usec (list[int]): Times in microseconds.\n    Returns:\n        list[float]: Times in milliseconds.\n    \"\"\"\n\n    list_msec = [time / 1000 for i, time in enumerate(list_usec)]\n    return list_msec\n</code></pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/","title":"Tutorial: Launch the MySQL database on a virtual machine","text":""},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#requirements","title":"Requirements:","text":"<ul> <li>a VM running Ubuntu on your hardware of choice.</li> </ul> <p>In this tutorial we'll cover how to launch the MySQL database, which will store, retrieve, and manage all (or most) of your data based on the commands and queries issued through DataJoint (covered in later tutorials).</p> <p>We'll launch the database on a virtual machine (VM). There are many ways to set up a VM, depending on the hardware you'll be using. We launched Epiphyte on a university cluster which has its own specific methodology for launching VMs. We won't go into the details here, as they won't be relevant to most people. </p> <p>We recommend getting in touch with your system administrator to first set up a VM on your organization's hardware, or if you're doing it yourself from a local computer, to follow tutorials such as this one by freeCodeCamp. We used Ubuntu Focal (20.04.2 LTS) for the operating system (OS), and the instructions below assume you are working from a Linux terminal. If your VM is running on another server, you should be able to access it with a command such as <code>ssh -i /path/to/.ssh/&lt;id_rsa.pub&gt; &lt;os&gt;@&lt;ip&gt;</code>.</p> <p>Whether you're working with a VM set up locally or on a remote server, be sure to allow admin access to anyone who will be managing the database by adding their public SSH keys to the VM  (the folder will be something like <code>~/.ssh/authorized_keys</code>, and you might need to first create the folder if it's not already present). </p> <p>We received feedback that users setting up their own VM locally ran into an issue regarding EFI Secure Boot and signing the kernel modules. Their proposed fix (source):</p> <p><code>sudo apt install --reinstall virtualbox-dkms</code> </p>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#1-configure-the-vm","title":"1. Configure the VM","text":"<p>First, enable <code>sudo</code> for your user (e.g. <code>ubuntu</code> if you installed an Ubuntu OS). You will need to set a password. Run the commands below from a terminal on your VM:</p> <pre>\nsudo -i\nsudo passwd ubuntu\n&lt;password&gt;\n</pre> <p>Don't allow <code>sudo</code> without password:</p> <pre>\nsudo -s\ncd /etc/sudoers.d\nnano 90-cloud-init-users\n</pre> <p>Remove <code>NOPASSWD</code> from the file and save it (<code>NOPASSWD:ALL</code> becomes just <code>ALL</code>).</p> <p>Unfortunately, it is highly likely that someone somewhere will try to break into your server using brute force attacks. That's why we'll add security with Fail2Ban, which bans IP addresses conducting too many failed login attempts. </p> <pre>\nsudo apt-get update\nsudo apt-get install fail2ban\n</pre> <p>You can edit the default settings at <code>sudo nano /etc/fail2ban/jail.local.save</code> (such as \"bantime\", the time a host is banned, or \"maxretry\", the number of failures before getting banned).</p> <p>Now we'll open the ports we'll use for SSH (port 22), MySQL (port 3306), and MinIO (port 9000, optional). We'll activate the Linux firewall, <code>ufw</code>, to enforce these changes.</p> <pre>\nsudo ufw allow 22 \nsudo ufw allow 3306 \nsudo ufw allow 9000  # optional, if using MinIO\nsudo ufw enable\n</pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#2-install-docker-and-docker-compose","title":"2. Install Docker and Docker Compose","text":"<p>The next step is to install Docker for Linux.</p> <p>Verify your Docker installation:</p> <pre>\ndocker --version\ndocker run hello-world\n</pre> <p>Next, install Docker Compose.</p> <p>Verify the Docker Compose installation:</p> <pre>\ndocker-compose --version\n</pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#3-install-the-mysql-client","title":"3. Install the MySQL client","text":"<pre>\nsudo apt-get install mysql-client\n</pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#4-set-up-your-docker-environment","title":"4. Set up your Docker environment","text":"<p>Create the directory where your Docker container will run (the folder names below are examples and can be changed, just be consistent with your new name in later steps).</p> <pre>\nsudo mkdir ~/mysql/mysql-docker\nsudo chown &lt;user&gt;: ~/mysql/mysql-docker\n</pre> <p>Download the files from here and place them in your new folder <code>~/mysql/mysql-docker</code> (we use a modified version of the Docker container provided by DataJoint).</p> <p>Choose a password for both MySQL and MinIO (optional).</p> <pre>\nsudo nano datajoint.env.example\n</pre> <p>Insert your password, <code>MYSQL_ROOT_PASSWORD=&lt;password&gt;</code>, and rename the file to <code>datajoint.env</code>.</p> <pre>\nmv datajoint.env.example datajoint.env\n</pre> <p>Do the same for the MinIO file (if using):</p> <pre>\nsudo nano minio.env.example\n</pre> <p>Set <code>MINIO_ROOT_USER=root</code> and insert your password of choice, <code>MINIO_ROOT_PASSWORD=&lt;password&gt;</code>. Rename this file, too.</p> <pre>\nmv minio.env.example minio.env\n</pre> <p>Edit directories as needed in <code>docker-compose.yaml</code> (relevant lines are marked in the file):</p> <pre>\nsudo nano docker-compose.yaml\n</pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#5-launch-the-containers-for-mysql-and-minio","title":"5. Launch the containers for MySQL and MinIO","text":"<pre>\nsudo docker-compose up -d\n</pre> <p>You can now log into your MySQL database! Exciting, but before we log in we still have a few steps to make our new database more secure. We'll start by attaching to our now-running Docker container:</p> <pre>\nsudo docker-compose exec &lt;container name&gt; bash\n</pre> <p>Now run the following command and follow the prompts to add essential security measures to your MySQL installation:</p> <pre>\nmysql_secure_installation\n</pre> <p>And again install Fail2Ban:</p> <pre>\nsudo apt-get update\nsudo apt-get install fail2ban\n</pre>"},{"location":"tutorials/1.%20Launch%20the%20MySQL%20database%20on%20a%20virtual%20machine/#6-create-user-accounts","title":"6. Create user accounts","text":"<p>Now for the fun part\u2014we can finally log into our new MySQL database!</p> <pre>\nmysql -h 127.0.0.1 -u root -p\n</pre> <p>Now you should be operating from a MySQL shell as the root user. Create new user accounts for the people you want to give access to:</p> <pre>\nCREATE USER '&lt;username&gt;'@'%' IDENTIFIED BY '&lt;password&gt;;\nGRANT ALL PRIVILEGES ON `&lt;username&gt;\\_%`.* TO '&lt;username&gt;'@'%';\n</pre>"},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/","title":"Tutorial: Add MinIO to an existing VM (optional)","text":""},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/#requirements","title":"Requirements:","text":"<ul> <li>a VM running your MySQL database (tutorial 1 complete).</li> </ul> <p>In this tutorial we'll cover how to launch MinIO from an existing VM (which was configured in the previous tutorial). </p> <p>MinIO is an object storage server useful for storing large files. If all of your data files are small (roughly &lt;10 MB), you can store everything directly in the MySQL database and skip this part. If you need to access larger files (and have the storage for them), then this tutorial is for you.</p>"},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/#1-create-the-minio-directory","title":"1. Create the <code>minio</code> directory","text":"<p>First, create a directory on your VM where you'll store your bulky data (we'll assume that the folder is called <code>minio</code>). </p> <pre>\nsudo mkdir minio\n</pre> <p>You might have to update permissions to use this folder:</p> <pre>\nsudo chown ubuntu: minio\n</pre>"},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/#2-mount-your-external-volume","title":"2. Mount your external volume","text":"<p>The specifics here will vary based on your setup. We'll cover some general steps, but if you're part of an organization, you should probably reach out to a system admin.</p> <p>If you don't have enough storage on the VM itself and are attaching an extra storage volume, then attach the volume to the <code>minio</code> folder you just made (e.g. via your cloud computing platform, such as OpenStack, or by plugging in an external hard drive and making sure it's recognized on the VM). Run <code>lsblk</code> or <code>df -h</code> to list all devices and check that it is attached (it will probably look something like <code>/dev/sdb1</code>). </p> <p>If the volume is new and has no data on it, then you will need to format it before using it. Follow the steps in this tutorial to format your new volume. To automatically mount the new volume when booting your VM, also follow the steps regarding adding an entry to your <code>/etc/fstab</code> file. </p> <p>You may have to edit permissions in order to work with data and directories on your new volume:</p> <pre>\nsudo chown -R ubuntu: minio\nsudo chmod -R 775 minio\n</pre>"},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/#3-launch-the-minio-server","title":"3. Launch the MinIO server","text":"<p>The MinIO server is the core component that provides object storage capabilities. In other words, in this step we'll set up the storage backend that will hold your data.</p> <p>We'll make a new terminal session using tmux, a terminal multiplexer (which is a fancy way of saying that it opens terminal sessions which you can attach to or detatch from). We'll launch our MinIO service from this terminal. This ensures that MinIO will keep running even if you disconnect from the server or your network connection is interrupted. </p> <p>Let's create a new terminal session and name it <code>minio</code>:</p> <pre>\ntmux new -s minio\n</pre> <p>Now you're in your new tmux terminal. </p> <p>(You can detach from the tmux session and return to your normal terminal by pressing <code>Ctrl+B D</code>. You can later reattach to the session using the command <code>tmux attach -t minio</code>.)</p> <p>Now we'll launch our MinIO server container using Docker. The command below maps ports 9000 and 9001 from the host to the container for server and console access, mounts the host <code>minio</code> directory as a volume for data storage, and sets up root access credentials for the server. Enter a password of your choosing.</p> <pre>\nsudo docker run -p 9000:9000 -p 9001:9001 --name minio -v ~/minio:/data -e \"MINIO_ROOT_USER=root\" -e \"MINIO_ROOT_PASSWORD=&lt;password&gt;\" quay.io/minio/minio:RELEASE.2021-10-23T03-28-24Z server /data -console-address \":9001\"\n</pre> <p>You should now be able to access your MinIO console via a web browser at <code>http://&lt;your.ip&gt;:9001</code> (you can find your IP from a terminal on the server via <code>hostname -I</code>). From here you can create new users and grant them the necessary privileges to access and store data on MinIO. </p>"},{"location":"tutorials/2.%20%28Optional%29%20Add%20MinIO%20to%20an%20existing%20virtual%20machine/#4-launch-the-minio-client","title":"4. Launch the MinIO client","text":"<p>The MinIO Client (<code>mc</code>) is a command-line tool designed to interact with the MinIO server. Although we recommend doing user management from the GUI at the link mentioned above (<code>http://&lt;your.ip&gt;:9001</code>), installing <code>mc</code> may prove useful for performing certain operations, especially if you prefer working via the command line (and either way, it certainly won't hurt to have it installed).</p> <p>Let's first split the current terminal pane vertically: <code>Ctrl+B Shift+%</code></p> <p>Now, from our new pane, we'll launch the MinIO client:</p> <pre>\nsudo docker run --name minio1_client --net=host -it -v ~/minio:/data --entrypoint=/bin/sh minio/mc\n</pre> <p>The above command binds the local directory <code>~/minio</code> to the <code>/data</code> directory inside the container. </p> <p>Now we'll tell the MinIO client to remember our new MinIO server and make it accesible via browser. Enter your password of choice. </p> <pre>\nmc config host add minio http://127.0.0.1:9001 root \"&lt;password&gt;\"\n</pre> <p>Now you're ready to store data on MinIO!</p> <p>In tutorial 5 we'll cover how to populate MinIO with your bulky data.</p>"},{"location":"tutorials/3.%20Install%20Epiphyte/","title":"Tutorial: Install and set up Epiphyte","text":""},{"location":"tutorials/3.%20Install%20Epiphyte/#requirements","title":"Requirements:","text":"<ul> <li>either a configured VM (tutorial 1) or local machine running Linux</li> <li>400 MB free disk space</li> <li>Python 3 and Anaconda (or Miniconda)</li> </ul> <p>Note: if using Windows, we highly recommended using VS Code for this tutorial.</p> <p>Once your MySQL database (and your optional additional storage) is configured, you're ready to install and set up Epiphyte!</p> <p>The database can be defined and structured remotely from a client computer, separate from where the database is hosted (e.g. on a remote server or virtual machine). This means you can install and configure Epiphyte on a separate computer (e.g., a workstation or personal laptop), while gaining the power and storage capacity of an external server. A schematic of this arrangement is given below:</p> <p></p> <p>Here, the VM (configured by you, the <code>dev</code> user) hosts the database, while the codebase controls and populates it with data. Once you install and configure Epiphyte, it's possible to directly interact with the remotely-hosted database from your PC or workstation. </p> <p>In this tutorial we'll go through how to install and set up Epiphyte on your PC, workstation, or whichever machine you'll use for interacting with the data. </p> <p>There are two ways to install Epiphyte: either via <code>pip</code> or by cloning the GitHub repository. We'll cover both methods, but if you already cloned the repo and are going through the tutorials locally, skip to that section. </p>"},{"location":"tutorials/3.%20Install%20Epiphyte/#installing-epiphyte-via-pip","title":"Installing Epiphyte via <code>pip</code>","text":"<p>Create a new <code>conda</code> environment suitable for the Epiphyte requirements:</p> <pre>\nconda create --name epiphyte python=3.9.18 ipython\n</pre> <p>Activate the conda environment and install Epiphyte:</p> <pre>\nconda activate epiphyte\npip install epiphyte\n</pre>"},{"location":"tutorials/3.%20Install%20Epiphyte/#installing-epiphyte-via-git","title":"Installing Epiphyte via <code>git</code>","text":"<p>Clone the repository, and change your directory to the repository: </p> <pre>\ngit clone git@github.com:mackelab/epiphyte.git\ncd epiphyte\n</pre> <p>Create a new <code>conda</code> environment suitable for the Epiphyte requirements:</p> <pre>\nconda create --name epiphyte python=3.9.18 ipython\n</pre> <p>Activate the <code>conda</code> environment and install the dependencies:</p> <pre>\nconda activate epiphyte\npip install -e .\n</pre> <p>Verify the installation:</p> <pre>\nconda list\n</pre>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/","title":"Tutorial: Configure and connect to the database","text":""},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#requirements","title":"Requirements:","text":"<ul> <li>completed tutorials 1-3.</li> </ul> <p>This notebook outlines the steps to configure database settings and connect to the MySQL database (hosted either on your local machine, or on a remote virtual machine).</p>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#1-configure-access-info","title":"1. Configure access info","text":"<p>Below is a code snippet containing the pieces that need to be configured in order to instantiate and connect to your database. </p> <p>Before running this code, you will need to change some parameters depending on the set-up you're using (all relevant lines are marked in the code):</p>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#option-a","title":"Option A:","text":"<p>If you are hosting the database via a virtual machine (VM), change the IP to that of your remote machine's. You can find your remote machine's IP by running the following command on that machine's terminal:</p> <pre>\nhostname -I\n</pre> <p>In case you receive multiple outputs, take the first entry. </p>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#option-b","title":"Option B:","text":"<p>If you plan to use this set-up at some point for real data with multiple users, you will need to change this line to accomodate the user in question. </p>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#option-c","title":"Option C:","text":"<p>Likewise, if you plan to use this set-up for real data, you will need to change the root password and alter it here. Note: since this requires storing a password in plain text, the safest option is to not include this in the configuration settings for a deployed database. In this case, only include the user name, and each time <code>dj.conn()</code> is run, you will be prompted for your password. Annoying, but safe. :)  </p> <pre><code>import os\nimport datajoint as dj\n\ndj.config['enable_python_native_blobs'] = True\ndj.config['database.host'] = '127.0.0.1:3306'            # Option A\ndj.config['database.user'] = 'root'                      # Option B\ndj.config['database.password'] = 'simple'                # Option C\n\nif not 'stores' in dj.config:\n    dj.config['stores'] = {}\n\nepi_schema = dj.schema('epiphyte_mock')\n\ndj.conn()\n</code></pre>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#2-configuring-storage","title":"2. Configuring storage","text":"<p>If you're working locally, run the following cell to configure storage:</p> <pre><code>dj.config['stores'] = {\n    'local': {  # store in files\n        'protocol': 'file',\n        'location': os.path.abspath('./dj-store')\n    }}\n</code></pre> <p>If you're working with a remote server using MinIO, run the cell below to configure storage. Replace the IP address (Option D) with the same one as above (Option A, i.e., the IP for your remote server running the VM). You'll also need to change the bucket name (Option E) to the one you're using:</p> <pre><code>dj.config[\"stores\"][\"minio\"] = {  \n        \"protocol\": \"s3\",\n        \"endpoint\": \"127.0.0.1:9000\",  # Option D\n        \"bucket\": \"&lt;bucket&gt;\",          # Option E\n        \"location\": \"data\",\n        \"access_key\": \"root\", \n        \"secret_key\": \"simple\" \n    }\n</code></pre> <p>Successful connection will output something like:</p> <p></p> <p>This code is already saved in the file <code>/src/epiphyte/database/access_info.py</code>, and can be modified to change the connection parameters. </p> <p>Once configured, you can connect by importing the <code>access_info.py</code> directly, instead of running the snippet above: </p> <pre><code># set relative import\nfrom .database import access_info \n</code></pre>"},{"location":"tutorials/4.%20Configure%20and%20connect%20to%20the%20database/#3-check-the-database-connection","title":"3. Check the database connection","text":"<p>This following snippet creates an <code>ERD</code> diagram, also known as an Entity Relationship Diagram. </p> <p>Before any tables are created, this diagram will be empty, since there are no relationships to visualize. </p> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre> <p>After creating tables, establishing relationships, and defining inheritances between them, you can visualize these entities and their connections using the function <code>dj.ERD(&lt;schema_name&gt;)</code>.</p>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/","title":"Tutorial: Define the database tables","text":""},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#requirements","title":"Requirements:","text":"<ul> <li>completed tutorials 1-5.</li> </ul> <p>This notebook covers the basics of defining tables. In particular, we'll go through: * Defining a table, * Defining inheritances and relationships between tables, * Defining how data is imported into a table, and * Creating mock-ups of tables before creating them within a database.</p> <p>All of the tables implemented here are taken from <code>/src/epiphyte/database/db_setup.py</code>. Importing this module will directely add these tables to the <code>epiphyte_mock</code> database schema. Only the tables that are set up as <code>Lookup</code> tables (i.e., draw their entries from a hard-coded source) will be populated upon first import; all others will need to be populated separately. Running the cells with the tables here will have the same effect as importing the module. </p> <pre><code>import numpy as np\nfrom pathlib import Path\nfrom datetime import datetime\n\nfrom epiphyte.database import config, helpers\nfrom epiphyte.database.access_info import *\nfrom epiphyte.preprocessing.data_preprocessing import data_utils, create_vectors_from_time_points\nfrom epiphyte.preprocessing.annotation.stimulus_driven_annotation.movies import processing_labels\nfrom epiphyte.data.mock_data_utils import *\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#1-generate-the-mock-data-for-the-example-database","title":"1. Generate the mock data for the example database.","text":"<p>The following function generates a mock dataset of patient \"recordings\" during a movie. This mock dataset consists of fake spiking data, local field potential, watchlogs, and annotations to demonstrate the design and population of database tables. </p> <p>The generated data is stored in <code>/epiphyte/data/mock_data/</code>.</p> <pre><code>run_data_generation()\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#2-identify-the-order-of-table-population","title":"2. Identify the order of table population","text":"<p>Since some tables pull information from other tables, we first need to decide on the order of table population. Details of this decision process are given in \u00a7 4.2.2 Identify a hierarchy, but ultimately it will depend heavily on the specifics of the dataset. </p> <p>In the example dataset, the most top-level information is that which describes a given patient. Each patient comes with the following information:  * Patient ID number, * Age of the patient, * Gender, and * Year of implantation. </p> <p>This information determines the columns of the <code>Patients</code> table:</p> <pre><code>@epi_schema\nclass Patients(dj.Lookup):\n    definition = \"\"\"\n    # general patient data, imported from config file\n    patient_id: int                                    # patient ID\n    ---\n    age: smallint                                      # age of patient\n    gender: enum('f', 'm', 'x')                        # gender of patient\n    year: int                                          # year of surgery\n    \"\"\"\n\n    contents = config.patients\n</code></pre> <p>Running the ERD should now show a diagram with a single table entity:</p> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre> <p>We can call the table now and take a look at its contents:</p> <pre><code>Patients()\n</code></pre> <p>Let's break down each line of the table definition for <code>Patients</code>:</p> <pre><code>1   @epi_schema\n2   class Patients(dj.Lookup):\n3       definition = \"\"\"\n4       # general patient data, imported from config file\n5       patient_id: int                                    # patient ID\n6       ---\n7       age: smallint                                      # age of patient\n8       gender: enum('f', 'm', 'x')                        # gender of patient\n9       year: int                                          # year of surgery\n10      \"\"\"\n\n11      contents = config.patients\n</code></pre> <ol> <li>Class decorator that connects the table to the correct database. You can have an arbitrary number of databases hosted on the same machine -- this line dictates to which schema the table belongs. </li> <li>Class definition. Here, you name the table (convention is the same as Python class naming), and specify how the table will be populated as the argument input (here, a Lookup table).</li> <li>Docstring specifying the columns of the table. </li> <li>Description of the table. Notice that this description is printed when the table is called to the notebook above. </li> <li>Define the primary key of the table. Here, only the patient ID number is needed to uniquely specify a table entry. </li> <li>Separate the primary from the secondary keys. </li> <li>Define secondary key, age. </li> <li>Define secondary key, gender.</li> <li>Define secondary key, year. </li> <li>Close the table definition docstring. </li> <li>Link the class to the location from which the contents should be populated. Here, the contents are drawn from a dictionary defined in <code>/src/epiphyte/database/config.py</code> as the variable <code>patients</code>. Adding a new line here and importing the table again will create the new corresponding row. </li> </ol> <p>For this experiment and dataset, a patient might run the same paradigm more than once, meaning that there can be more than one experimental session per patient. To represent this in the database, we separate the patient information from the session information by also creating a separate <code>Sessions</code> table. </p> <pre><code>@epi_schema\nclass Sessions(dj.Lookup):\n    definition = \"\"\"\n    # general session data, imported from config file\n    patient_id: int                                    # patient ID\n    session_nr: int                                    # session number\n    ---\n    session_type: enum('full_movie', 'follow_up', 'partial_movie')   # type of session for corresponding recording\n    \"\"\"\n\n    contents = config.sessions\n</code></pre> <p>There are two additional Lookup tables in the database, <code>Annotators</code> and <code>LabelNames</code>.  These tables contain the information regarding identity of label creators and the names of the created labels, respectively. </p> <pre><code>@epi_schema\nclass Annotator(dj.Lookup):\n    definition = \"\"\"\n    # annatotors of the video, imported from config file\n    annotator_id: varchar(5)                    # unique ID for each annotator\n    ---\n    first_name: varchar(32)                      # first name of annotator\n    last_name: varchar(32)                       # last name of annotator\n    \"\"\"\n\n    contents = config.annotators\n\n@epi_schema\nclass LabelName(dj.Lookup):\n    definition = \"\"\"\n    # names of existing labels, imported from config file\n    label_name: varchar(32)   # label name\n    \"\"\"\n\n    contents = config.label_names\n</code></pre> <p>Now looking at the entity relationship diagram, we can see 4 tables arranged with a flat hierarchy, since no table depends on another table.</p> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre> <p>The remaining tables, shown below in a modified Panel B from Figure 3, should be defined and instantiated according to the hierarchy, or \"downstream\" along the ERD.</p> <p></p> <p>Level I: <code>Patients</code>, <code>Sessions</code>, <code>Annotator</code>, <code>LabelName</code></p> <p>Level II: <code>MovieSession</code>, <code>ElectrodeUnit</code>, <code>LFPData</code>, <code>MovieAnnotation</code></p> <p>Level III: <code>SpikeData</code>, <code>PatientAlignedMovieAnnotations</code>, <code>MovieSkips</code>, <code>MoviePauses</code></p>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#3-define-remaining-tables-including-dependenciesrelationships","title":"3. Define remaining tables, including dependencies/relationships.","text":"<p>Now we can start defining the later tables (Level II, Level III).</p> <p>Technically, you can define all tables at once, and then instantiate and populate them in the correct order. For the sake of this tutorial, we will cover a couple tables from Level II and a couple from Level II, including the table a) definition, b) instantiation (addition of the empty table to the database), and c) population. </p>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#moviesession","title":"<code>MovieSession</code>","text":"<p>The <code>MovieSession</code> table contains the paradigm variables from each patient's movie watch. It takes its primary keys from the <code>Patients</code> and <code>Sessions</code> tables. Additionally, this table is of type <code>dj.Imported</code> and directly pulls its entries from the dataset created in the first tutorial. Since it imports its entries, we will need to additionally define a function for populating the table. Here, we will use the autopopulation method from the Datajoint package (more info here).</p> <pre><code>@epi_schema\nclass MovieSession(dj.Imported):\n    definition = \"\"\"\n    # data of individual movie watching sessions\n    -&gt; Patients                          # patient ID\n    -&gt; Sessions                          # session ID\n    ---\n    date : date                         # date of movie session\n    time : time\n    pts: longblob                       # order of movie frames for patient (pts) \n    dts: longblob                       # cpu time stamps (dts)\n    neural_recording_time: longblob     # neural recording time (rectime)\n    channel_names: longblob             # channel name, indicating electrode number and brain region\n    \"\"\"\n\n    def _make_tuples(self, key):\n        patient_ids = Patients.fetch(\"patient_id\")       \n\n        for _, pat in enumerate(patient_ids):\n\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")       \n\n            try:\n                checks = (MovieSession &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n                if len(checks) == len(pat_sessions):\n                    print(checks)\n                    print(len(checks), len(pat_sessions))\n                    continue\n                else:\n                    print(f\"Adding patient {pat} to database...\")\n                    pass\n            except:\n                print(f\"Adding patient {pat} to database...\")\n                pass\n\n            for _, sesh in enumerate(pat_sessions):\n\n                try:\n                    check = len((MovieSession &amp; f\"patient_id={1}\" &amp; f\"session_nr={1}\").fetch(\"pts\")[0])\n                    if check &gt; 0:\n                        print(f\"Adding patient {pat} to database...\")\n                        pass\n                    else:\n                        continue\n                except:\n                    print(f\"Adding patient {pat} to database...\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n                pts, rectime, dts = time_conversion.convert()\n\n                save_dir = main_patient_dir / \"movie_info\"\n                save_dir.mkdir(exist_ok=True)\n                np.save(save_dir / \"pts.npy\", pts)\n                np.save(save_dir / \"dts.npy\", dts)\n                np.save(save_dir / \"neural_rec_time.npy\", rectime)\n\n                path_channel_names = main_patient_dir / \"ChannelNames.txt\"\n                channel_names = helpers.get_channel_names(path_channel_names)\n\n                self.insert1({'patient_id': pat,\n                            'session_nr': sesh,\n                            'date': date,\n                            'time': time,\n                            'pts': pts,\n                            'dts': dts,\n                            'neural_recording_time': rectime,\n                            'channel_names': channel_names\n                            }, skip_duplicates=True)\n</code></pre> <p>TODO </p> <p>explain populate method a little bit, with the lfp manual population in mind</p> <pre><code>MovieSession.populate()\nMovieSession()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#lfpdata","title":"<code>LFPData</code>","text":"<p>The <code>LFPData</code> </p> <pre><code>@epi_schema\nclass LFPData(dj.Manual):\n    definition = \"\"\"\n    # local field potential data, by channel. \n    -&gt; Patients\n    -&gt; Sessions\n    csc_nr: int\n    ---\n    samples: longblob                # samples, in microvolts\n    timestamps: longblob             # timestamps corresponding to each sample, in ms\n    sample_rate: int                 # sample rate from the recording device\n    brain_region: varchar(8)         # brain region where unit was recorded\n    \"\"\"\n</code></pre> <p>defining a function for manually adding data to the table</p> <pre><code>def populate_lfp_data_table():\n    \"\"\"\n    Iterates over the channel files stored in config.PATH_TO_DATA/lfp_data/\n    and adds each channel to the table. \n\n    Ignores channels already uploaded.\n    \"\"\"\n\n    patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n    for i_pat, pat in enumerate(patient_ids):\n        pat_sessions = session_nrs[i_pat]\n\n        for i_sesh, sesh in enumerate(pat_sessions):\n\n            path_ds_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\", \"lfp_data\")\n            lfp_files = list(path_ds_dir.glob(\"CSC*\"))\n\n            try:\n                check = (LFPData &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"csc_nr\")[0]\n                if len(check) == len(lfp_files):\n                    print(f\"    Patient {pat} session {sesh} already added.\")\n                    continue\n                else:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n            except:\n                print(f\"    Adding patient {pat} session {sesh} to database...\")\n                pass\n\n            path_channels = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\", \"ChannelNames.txt\")\n            channel_names = helpers.get_channel_names(path_channels)\n\n            for ds_file in path_ds_dir.iterdir():\n\n                csc_nr = ds_file.name.split('_')[0][3:]\n                region = channel_names[int(csc_nr)-1]\n                print(f\"  .. adding csc {csc_nr}..\")\n                ds_dict = np.load(ds_file, allow_pickle=True)\n                LFPData.insert1({\n                    'patient_id': pat,\n                    'session_nr': sesh,\n                    'csc_nr': csc_nr,\n                    'samples': ds_dict.item().get(\"samples\"),\n                    'timestamps': ds_dict.item().get(\"timestamps\"),\n                    'sample_rate': ds_dict.item().get(\"sample_rate\")[0],\n                    'brain_region': region\n                })\n\n\n                print(f\"  .. csc {csc_nr} added.\")\n</code></pre> <pre><code># populate_lfp_data_table()\n# LFPData()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#electrodeunit","title":"<code>ElectrodeUnit</code>","text":"<p>The <code>ElectrodeUnit</code> </p> <pre><code>@epi_schema\nclass ElectrodeUnit(dj.Imported):\n    definition = \"\"\"\n    # Contains information about the implanted electrodes of each patient\n    -&gt; Patients                      # patient ID\n    -&gt; Sessions                      # session number\n    unit_id: int                     # unique ID for unit (for respective  patient)\n    ---\n    csc: int                         # number of CSC file\n    unit_type: enum('M', 'S', 'X')   # unit type: 'M' for Multi Unit, 'S' for Single Unit, 'X': undefined\n    unit_nr: int                     # number of unit, as there can be several multi units and single units in one CSC file\n    brain_region: varchar(8)         # brain region where unit was recorded\n    \"\"\"\n\n    def _make_tuples(self, key):\n        patient_ids = Patients.fetch(\"patient_id\")\n\n        # iterate over each patient in db\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n\n            # further iterate over each patient's sessions\n            for i_sesh, sesh in enumerate(pat_sessions):\n\n                path_channels = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n                channel_names = helpers.get_channel_names(path_channels / \"ChannelNames.txt\")\n\n                try:\n                    check = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"csc_nr\")\n                    if len(check) == len(channel_names):\n                        continue\n                    else:\n                        print(f\"    Adding patient {pat} session {sesh} to database...\")\n                        pass\n                except:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n\n                spike_dir = Path(config.PATH_TO_DATA, \"patient_data\", str(pat), f\"session_{sesh}\", \"spiking_data\")\n                spike_filepaths = list(spike_dir.iterdir())\n                spike_filenames = sorted([s.name for s in spike_filepaths], key=helpers.extract_sort_key)\n\n                for unit_id, filename in enumerate(spike_filenames):\n                    csc_nr, unit = filename[:-4].split(\"_\")\n                    csc_index = int(csc_nr[3:]) - 1\n                    print(f\"    ... Unit ID: {unit_id}, CSC #: {csc_nr}, Channel index: {csc_index}\")\n\n                    channel = channel_names[csc_index]\n                    print(f\"    ... Channel name: {channel}\")\n\n                    unit_type, unit_nr = helpers.get_unit_type_and_number(unit)\n                    print(f\"    ... Unit type: {unit_type},  Within-channel unit number: {unit_nr}\")\n\n                    self.insert1({'patient_id': pat,\n                                'session_nr': sesh,\n                                'unit_id': unit_id, \n                                'csc': csc_nr[3:], \n                                'unit_type': unit_type, \n                                'unit_nr': unit_nr,\n                                'brain_region': channel},\n                                    skip_duplicates=True)\n\n                    print(\" \")\n</code></pre> <pre><code>ElectrodeUnit.populate()\nElectrodeUnit()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#movieannotation","title":"<code>MovieAnnotation</code>","text":"<p>The <code>MovieAnnotation</code> </p> <pre><code>@epi_schema\nclass MovieAnnotation(dj.Imported):\n    definition = \"\"\"\n    # information about video annotations (e.g. labels of characters); \n    # this table contains start and end time points and values of the segments of the annotations;\n    # all time points are in Neural Recording Time;\n    -&gt; Annotator                    # creator of movie annotation\n    -&gt; LabelName                    # name of annotation\n    annotation_date: date           # date of annotation\n    ---\n    values: longblob                # list of values that represent label\n    start_times: longblob           # list of start times of label segments in movie play time (PTS)\n    stop_times: longblob            # list of stop times of label segments in movie play time (PTS)\n    category: varchar(32)           # category of label; e.g. 'character', 'emotion', 'location'\n    indicator_function: longblob    # full indicator function, one value for each movie frame\n    \"\"\"\n\n    def _make_tuples(self, key):\n        path_labels = Path(config.PATH_TO_LABELS)\n\n        for filepath in path_labels.iterdir():\n            label_id, label_name, annotator, date, category = filepath.name[:-4].split(\"_\")\n\n            try:\n                check = (MovieAnnotation &amp; f\"label_name='{label_name}'\" &amp; f\"category='{category}'\").fetch(\"values\")\n                if len(check) &gt; 0:\n                    continue\n                else: \n                    print(f\"    Adding {label_name}, category {category} to database...\")\n                    pass\n            except:\n                print(f\"    Adding {label_name}, category {category} to database...\")\n                pass\n\n            content = np.load(filepath)\n\n            values = np.array(content[0])\n            start_times = np.array(content[1])\n            stop_times = np.array(content[2])\n\n            ind_func = processing_labels.make_label_from_start_stop_times(values, start_times, stop_times, config.PTS_MOVIE_new)\n\n            print(f\"    ... # of occurrences: {int(sum(values))}\\n\")\n\n            self.insert1({'label_name': label_name,\n                            'annotator_id': annotator,\n                            'annotation_date': datetime.strptime(date, '%Y%m%d'),\n                            'category': category,\n                            'values': values,\n                            'start_times': start_times,\n                            'stop_times': stop_times,\n                            'indicator_function': np.array(ind_func)\n                            }, skip_duplicates=True)\n</code></pre> <pre><code>MovieAnnotation.populate()\nMovieAnnotation()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#remaining-tables","title":"Remaining tables","text":""},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#spikedata","title":"<code>SpikeData</code>","text":"<p>The <code>SpikeData</code> </p> <pre><code>@epi_schema\nclass SpikeData(dj.Imported):\n    definition = \"\"\"\n    # This table contains all spike times of all units of all patients in Neural Recording Time\n    # Each entry contains a vector of all spike times of one unit of one patient\n    -&gt; Sessions\n    -&gt; ElectrodeUnit                   # unit from which data was recorded\n    ---\n    spike_times: longblob              # in case bin_size is not 0: number of spikes; otherwise: times of spikes (original data)\n    spike_amps: longblob               # amplitudes for each spike in spike_times\n    \"\"\"\n\n    def _make_tuples(self, key):\n        patient_ids = Patients.fetch(\"patient_id\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = (Sessions &amp; f\"patient_id={pat}\").fetch(\"session_nr\")\n\n            for i_sesh, sesh in enumerate(pat_sessions):\n                spike_dir = Path(config.PATH_TO_DATA, \"patient_data\", str(pat), f\"session_{sesh}\", \"spiking_data\")\n                spike_files = list(spike_dir.iterdir())\n                unit_ids = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"unit_id\")\n\n                assert len(spike_files) == len(unit_ids), \"Number of units in ElectrodeUnits doesn't match number of spiking files.\"\n\n                try:\n                    check = (SpikeData &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"unit_id\")[0]\n                    if len(check) == len(spike_files) == len(unit_ids):\n                        continue\n                    else:\n                        print(f\"    Adding patient {pat} session {sesh} to database...\")\n                        pass\n                except:\n                    print(f\"    Adding patient {pat} session {sesh} to database...\")\n                    pass\n\n                for filepath in spike_files:\n                    filename = filepath.name\n                    csc_nr, unit = filename[:-4].split(\"_\")\n                    csc_nr = int(csc_nr[3:])\n                    unit_type, unit_nr = helpers.get_unit_type_and_number(unit)\n\n                    unit_id = (ElectrodeUnit &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\" \n                            &amp; f\"csc={csc_nr}\" &amp; f\"unit_nr={unit_nr}\" &amp; f\"unit_type='{unit_type}'\").fetch(\"unit_id\")[0]\n\n                    spikes_file = np.load(filepath, allow_pickle=True)\n                    spikes_file = spikes_file.item()\n                    times = spikes_file[\"spike_times\"]\n                    amps = spikes_file[\"spike_amps\"]\n\n                    print(f\"    ... Unit ID: {unit_id}, CSC #: {csc_nr}\")\n                    print(f\"    ... Nm. of spikes: {len(times)}\")\n                    print(f\"    ... Max amp.: {np.max(amps)} microV\\n\")\n\n                    self.insert1({'patient_id': pat, \n                                'session_nr': sesh, \n                                'unit_id': unit_id,\n                                'spike_times': times, \n                                'spike_amps': amps}, skip_duplicates=True)\n</code></pre> <pre><code>SpikeData.populate()\nSpikeData()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#patientalignedmovieannotations","title":"<code>PatientAlignedMovieAnnotations</code>","text":"<p>The <code>PatientAlignedMovieAnnotations</code> </p> <pre><code>@epi_schema\nclass PatientAlignedMovieAnnotation(dj.Computed):\n    definition = \"\"\"\n    # Movie Annotations aligned to patient time / time points are in neural recording time\n    -&gt; MovieSession        # movie watching session ID\n    -&gt; MovieAnnotation     # label\n    ---\n    label_in_patient_time: longblob    # label matched to patient time (pts)\n    values: longblob       # list of values that represent label\n    start_times: longblob  # list of start times of label segments in neural recording time\n    stop_times: longblob   # list of stop times of label segments in neural recording time\n    \"\"\"\n\n    def make(self, key):\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n        entries = (MovieAnnotation).fetch('KEY')\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                print(f\"Patient {pat} session {sesh}..\")\n\n                for entry in entries:\n\n                    annotator_id = entry[\"annotator_id\"]\n                    label_name = entry[\"label_name\"]\n                    annotation_date = entry[\"annotation_date\"]\n\n                    try:\n                        check = (PatientAlignedMovieAnnotation &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\"\n                                    &amp; f\"label_name='{label_name}'\" &amp; f\"annotator_id='{annotator_id}'\").fetch(\"values\")\n                        if check.any():\n                            print(f\"    ... {label_name} already in database.\")\n                            continue\n                        else:\n                            print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                            pass\n                    except:\n                        print(f\"    ... Adding patient {pat} session {sesh} label {label_name} to database.\")\n                        pass\n\n                    patient_pts = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"pts\")[0]\n                    neural_rectime = (MovieSession &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"neural_recording_time\")[0]\n\n                    default_label = (MovieAnnotation &amp; f\"annotator_id='{annotator_id}'\" &amp; f\"label_name='{label_name}'\").fetch(\"indicator_function\")[0]\n                    patient_aligned_label = match_label_to_patient_pts_time(default_label, patient_pts)\n                    values, starts, stops = create_vectors_from_time_points.get_start_stop_times_from_label(neural_rectime, \n                                                                                            patient_aligned_label)\n\n                    self.insert1({'patient_id': pat,\n                                    'session_nr': sesh,\n                                    'annotator_id': annotator_id,\n                                    'label_name': label_name,\n                                    'annotation_date': annotation_date,\n                                    'label_in_patient_time': np.array(patient_aligned_label),\n                                    'values': np.array(values),\n                                    'start_times': np.array(starts),\n                                    'stop_times': np.array(stops),\n                                    }, skip_duplicates=True)\n</code></pre> <pre><code>PatientAlignedMovieAnnotation.populate()\nPatientAlignedMovieAnnotation()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#movieskips","title":"<code>MovieSkips</code>","text":"<p>The <code>MovieSkips</code> </p> <pre><code>@epi_schema\nclass MovieSkips(dj.Computed):\n    definition = \"\"\"\n    # This table Contains start and stop time points, where the watching behaviour of the patient changed from \n    # continuous (watching the movie in the correct frame order) to non-continuous (e.g. jumping through the movie) or \n    # the other way round;\n    # all time points are in Neural Recording Time\n    -&gt; MovieSession                    # number of movie session\n    ---\n    values: longblob                   # values of continuous watch segments\n    start_times: longblob              # start time points of segments\n    stop_times: longblob               # end time points of segments\n    \"\"\"\n\n    def make(self, key):\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                try:\n                    check = (MovieSkips &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"values\")\n                    if check.any():\n                        continue\n                    else:\n                        print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                        pass\n                except:\n                    print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n                starts, stops, values = time_conversion.convert_skips()\n\n                self.insert1({'patient_id': pat, \n                            'session_nr': sesh,\n                            'start_times': np.array(starts), \n                            'stop_times': np.array(stops), \n                            'values': np.array(values)}, skip_duplicates=True)\n</code></pre> <pre><code>MovieSkips.populate()\nMovieSkips()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/5.%20Design%20and%20implement%20the%20database/#moviepauses","title":"<code>MoviePauses</code>","text":"<p>The <code>MoviePauses</code> </p> <pre><code>@epi_schema\nclass MoviePauses(dj.Computed):\n    definition = \"\"\"\n    # This table contains information about pauses in movie playback;\n    # This is directly computed from the watch log;\n    # Time points are in Neural Recording Time\n    -&gt; MovieSession                    # movie watching session of patient\n    ---\n    start_times: longblob              # start time points of pauses\n    stop_times: longblob               # end time points of pauses\n    \"\"\"\n\n    def make(self, key):\n\n        patient_ids, session_nrs = MovieSession.fetch(\"patient_id\", \"session_nr\")\n\n        for i_pat, pat in enumerate(patient_ids):\n            pat_sessions = session_nrs[i_pat]\n\n            for i_sesh, sesh in enumerate([pat_sessions]):\n\n                try:\n                    check = (MoviePauses &amp; f\"patient_id={pat}\" &amp; f\"session_nr={sesh}\").fetch(\"values\")\n                    if check.any():\n                        continue\n                    else:\n                        print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                        pass\n                except:\n                    print(f\"    ... Adding patient {pat} session {sesh} to database.\")\n                    pass\n\n                main_patient_dir = Path(config.PATH_TO_PATIENT_DATA, str(pat), f\"session_{sesh}\")\n\n                session_info = np.load(main_patient_dir / \"session_info.npy\", allow_pickle=True)\n                date = session_info.item().get(\"date\")\n                time = session_info.item().get(\"time\")\n                time = datetime.strptime(time, '%H-%M-%S').strftime('%H:%M.%S')\n\n                path_wl =  main_patient_dir / \"watchlogs\" \n                ffplay_file = next(path_wl.glob(\"ffplay*\"), None)\n\n                if ffplay_file:\n                    print(\" Found ffplay file:\", ffplay_file)\n                else:\n                    print(\" No ffplay file found in the watchlogs directory.\")\n                    break\n\n                path_daq = main_patient_dir / \"daq_files\" \n                daq_file = next(path_daq.glob(\"timedDAQ*\"), None)\n\n                if ffplay_file:\n                    print(\" Found DAQ file:\", daq_file)\n                else:\n                    print(\" No DAQ file found in the daq_files directory.\")\n                    break\n\n                path_events = main_patient_dir / \"event_file\" / \"Events.npy\"\n                time_conversion = data_utils.TimeConversion(path_to_wl=ffplay_file, path_to_dl=daq_file,\n                                                                    path_to_events=path_events)\n\n                start, stop = time_conversion.convert_pauses()\n\n                self.insert1({'patient_id': pat, \n                            'session_nr': sesh,\n                            'start_times': np.array(starts), \n                            'stop_times': np.array(stops)}, skip_duplicates=True)\n</code></pre> <pre><code>MoviePauses.populate()\nMoviePauses()\n</code></pre> <pre><code>erd = dj.ERD(epi_schema)\nerd\n</code></pre>"},{"location":"tutorials/6.%20Compile%20the%20codebase/","title":"Tutorial: Compile the codebase","text":"<p>The codebase is the interface for your database. The major benefit of separating these components is that it enables additional uses to flexibly interact with and use the data stored in the database, while minimizing the chances that unwanted destructive or constructive errors are made. It additionally ensures that all users have a single source of truth, and are interacting with the data in a consistent manner. </p> <p>In case you want to enable additional users, we recommend creating and maintaining a template codebase which can be downloaded and used to connect to your bespoke database. In essence, this is what Epiphyte is, but with additional modules to generate mock data and additional documentation. </p> <p>A compiled codebase only really needs 4 modules: 1. <code>access_info.py</code>: a script containing the server, storage, and user information. 2. <code>db_setup.py</code>: a script containing all the table definitions and package imports.  3. <code>config.py</code>: a script containing any hard-coded variables or pieces of information.  4. <code>query_functions</code>: a script defining common interactions with the database as convenience functions.</p> <p>Once a database is in a stable state, and these modules exist in a stable form, we recommend creating a private GitHub repository containing these scripts. New users can then clone and modify the relevant lines in <code>access_info.py</code> and then access and interact with the data. </p>"},{"location":"tutorials/7.%20%28Optional%29%20Run%20regular%20backups/","title":"Tutorial: Run regular backups","text":""},{"location":"tutorials/7.%20%28Optional%29%20Run%20regular%20backups/#requirements","title":"Requirements:","text":"<ul> <li>data stored in your database (and/or MinIO). </li> </ul> <p>We call this tutorial \"optional\" because the methods described here are optional\u2014there are many different ways you can configure regular backups, and at this point your database should be fully functional, which was the main goal of this tutorial series. </p> <p>That being said, you should consider regular backups an essential part of having a database!</p>"},{"location":"tutorials/7.%20%28Optional%29%20Run%20regular%20backups/#1-create-a-config-file-with-your-mysql-credentials","title":"1. Create a config file with your MySQL credentials","text":"<p>You shouldn't save your MySQL credentials directly in your backup script, as this can pose a security risk. Instead, we'll make a separate config file to save your credentials, and then restrict access to the root user only. </p> <p>Create a config file called <code>.my.cnf</code>:</p> <pre>\ntouch .my.cnf\nsudo nano .my.cnf\n</pre> <p>Now add your data to that file: </p> <pre>\nbash\n# needed for dump\n[mysqldump]\nuser = root\npassword = &lt;password&gt;\n\n# needed for restore\n[mysql]\nuser = root\npassword = &lt;password&gt;\n</pre> <p>Be sure to change the file's permissions to restrict access to the root user only:</p> <pre>\nchmod 600 .my.cnf\n</pre>"},{"location":"tutorials/7.%20%28Optional%29%20Run%20regular%20backups/#2-write-your-backup-script","title":"2. Write your backup script","text":"<p>Create a shell script <code>backup.sh</code>:</p> <pre>\ntouch backup.sh\nsudo nano backup.sh\n</pre> <p>Add the following lines to your script. Be sure to update the paths accordingly (for finding your config file, and where you want to send the backup to). Ideally you should send your backups to a separate piece of hardware than where your database is running, or store them in the cloud.</p> <pre>\n#!/bin/bash\n\n# Update paths accordingly in the following lines:\n# --defaults-extra-file=~/path/to/config_file\n# &gt; ~/destination/file/for/backups\necho \"$(date -u +\\%H:\\%M) Dumping database...\"\nmysqldump --defaults-extra-file=~/path/to/config_file/.my.cnf -h 127.0.0.1 -u root --column-statistics=0 --all-databases --skip-triggers &gt; ~/destiantion/file/for/backups/mysql_backup_$(date -u +\\%FT\\%H\\%MZ).sql\n\n# Removes backups older than 30 days\necho \"$(date -u +\\%H:\\%M) Deleting old dumps...\"\nfind ~/backups/mysql/* -mtime +30 -exec rm {} \\;\n\necho \"MySQL backup is finished!\"\n</pre> <p>If you're storing data on MinIO as well, you can add the following lines to backup your MinIO data using <code>rsync</code> (sample file paths are given, be sure to again update file paths accordingly):</p> <pre>\n# Syncs everything from bulk-minio to backup\n# -q: does syncronizing quietly (only error outputs will be shown)\necho \"$(date -u +\\%H:\\%M) Archiving MinIO...\"\nrsync -a ~/minio ~/backups/minio/minio_backup_$(date -u +\\%FT\\%H\\%MZ) -q\n\n# Removes backups older than 30 days\necho \"$(date -u +\\%H:\\%M) Deleting old archieves...\"\nfind ~/backups/minio/* -maxdepth 1  -mtime +30 -exec rm -r \"{}\" \\;\n\necho \"MinIO backup is finished!\"\n</pre>"},{"location":"tutorials/7.%20%28Optional%29%20Run%20regular%20backups/#3-schedule-your-backups-with-a-cron-job","title":"3. Schedule your backups with a cron job","text":"<p>A \"cron job\" is a scheduled task used in Unix and Unix-like operating systems to automate the execution of scripts at specified times or intervals. We'll set up a cron job to run backups at 1 a.m. server time.</p> <p>Edit a new crontab:</p> <pre>\ncrontab -e\n</pre> <p>Add the following lines to the crontab and update the path to your backup script accordingly: </p> <pre>\nbash\n0 1 * * * /bin/bash ~/path/to/backup/script/backup.sh &gt;/dev/null 2&gt;&amp;1\n</pre> <p>Whenever a crontab has been edited successfully <code>crontab: installing new crontab</code> will pop up.</p> <p>You can check the status of your crontab via <code>crontab -l</code>.</p> <p>Your backups should now be good to go!</p>"},{"location":"tutorials/8_Add_new_table/","title":"Adding Change Point Annotations to Database","text":""},{"location":"tutorials/8_Add_new_table/#1-design-new-table","title":"(1) Design new Table","text":"<ul> <li>import necessary modules </li> <li>think about the structure of the Table (primary keys, other keys) and the other existing Tables it might need to interact with</li> </ul>"},{"location":"tutorials/8_Add_new_table/#table-doc_string-convention","title":"Table doc_string convention:","text":"<pre><code>class TableName(dj.TableType):\n    definition = \"\"\"\n    # Description of Table purpose\n    -&gt; Dependency to existing Table           # Purpose of said existing Table\n    primary_key: datatype                     # Purpose of primary key \n    ---\n    normal_column:  datatype                  # Purpose of column (aka non-primary key) \n    \"\"\"\n</code></pre> <pre><code>from database.db_setup import *\n\nfrom annotation.data_driven_annotation import cpt\nimport preprocessing.data_preprocessing.binning as binning\nimport preprocessing.data_preprocessing.create_vectors_from_time_points as create_vectors_from_time_points            \n</code></pre> <p>(2) Define the Type of Table</p> <pre><code>class ChangePointAnnotation(dj.Computed):\n</code></pre> <p>(3) Initialize Table</p> <pre><code>class ChangePointAnnotation(dj.Computed):\n    \"\"\"\n    # This table contains information about change points detected in spiking acitivity of single units;\n    -&gt; BinnedSpikesDuringMovie                    # the unit information and the binned spike vectors\n    algorithm: varchar(32)                        # the algorithm version that was used to create the change point\n    ---\n    change_point: int                             # actual change point in neural recording time\n    t_value: int                                  # the t-value of the test statistic\n    additional_information=\"\":varchar(32)         # space for additional information\n    \"\"\"\n\n    def make(self, key):\n        \"\"\"\n        Function that will run change point algorithm on spike trains and store results in database.\n        \"\"\"\n</code></pre> <p>(4) Define how the Table with be populated </p> <ul> <li>write the make() function: generates the values to be put into the database</li> <li>define how those values will be inserted (order, column names, ect)</li> </ul> <pre><code>class ChangePointAnnotation(dj.Computed):\n    ### ask: is there a meaning to the breakpoints in the defs? \n    ### as in, above the ---, primary keys,  and below: secondary? \n    \"\"\"\n    # This table contains information about change points detected in spiking acitivity of single units;\n    -&gt; BinnedSpikesDuringMovie                    # the unit information and the binned spike vectors\n    algorithm: varchar(32)                        # the algorithm version that was used to create the change point\n    ---\n    change_point: int                             # actual change point in neural recording time\n    t_value: int                                  # the t-value of the test statistic\n    additional_information=\"\":varchar(32)         # space for additional information\n    \"\"\"\n\n    def make(self, key):\n        \"\"\"\n        Function that will run change point algorithm on spike trains and store results in database.\n        \"\"\"\n        # Retrieve all patient id's and units that exist within the \n        # database and use for setting up the new computed table\n        patient_ids, units_ids, session_nr = SpikeTimesDuringMovie().fetch(\"patient_id\",\"unit_id\", \"session_nr\")       \n\n        for i in range(len(patient_ids)):\n            pat_id = patient_ids[i]\n            unit_nr = units_ids[i]\n            session = session_nr[i]\n\n            # load spike times into kernel\n            unit_name = (SpikeTimesDuringMovie &amp; \"patient_id={}\".format(pat_id)\n                    &amp; \"unit_id={}\".format(unit_nr) &amp; \"session_nr={}\".format(session)).fetch(\"spike_times\")[0]\n            unit = np.load(unit_name)\n            os.remove(unit_name)\n\n            # bin spike times to 1000 msec (should this be a finer scale?)\n            bin_size = 1000\n            exclude_pauses = False\n            output_edges = True\n            binned_unit, edges = binning.bin_spikes(pat_id, session, unit, bin_size, exclude_pauses, output_edges)\n\n            # compute change points\n            # note: cpt algo auto-generates plots -- should make default not plotting for this purpose?\n            tau, ttest = cpt.find_changepoint_tt(binned_unit)\n\n            tstat = ttest[0] \n            change_point_time = [edges[tau], edges[tau+1]]\n\n            self.insert1({\"patient_id\": pat_id, \"unit_id\": unit_nr,\n                          \"session_nr\": session, \"bin_size\": bin_size,\n                          \"t_value\": tstat, \"change_point_bin\": tau, \"change_point_time\": change_point_time})\n</code></pre> <p>(5) Populate the Table</p> <p>After coding up the class, testing it, and implementing it in the db_setup.py file, add a line into the ~/database/datanase_set_up.ipynb notebook that will run and create the Table as part of the database. </p> <pre><code># insert this line into set_up notebook\nChangePointAnnotation.populate()\n\n# if manual Table, then would need to manually population \n# ExampleTable.insert1(to_be_inserted)\n</code></pre>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/","title":"Tutorial: Launch the MySQL database locally","text":""},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#requirements","title":"Requirements:","text":"<ul> <li>OS: Linux or Mac/OSx</li> <li>Python 3.5 or higher (either system-level, or in an IDE)</li> <li>400 MB free disk space</li> <li>Permission to perform sudo-level commands</li> </ul>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#installation","title":"Installation:","text":"<p>The installation of <code>epiphyte</code> has three steps: </p> <ol> <li>Install and set-up the DataJoint docker container. </li> <li>Download and launch the DataJoint MySQL server via docker-compose.</li> <li>Install <code>Epiphyte</code>.</li> </ol>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#1-install-and-set-up-the-datajoint-docker-container","title":"1. Install and set-up the DataJoint docker container.","text":"<ul> <li>Install the correct Docker for your OS.</li> <li>Verify the Docker installation: </li> </ul> <pre>\ndocker --version\ndocker run hello-world\n</pre> <ul> <li>Install Docker Compose.</li> <li>Verify the Docker Compose installation:</li> </ul> <pre>\ndocker-compose --version\n</pre>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#2-download-and-launch-the-datajoint-mysql-server-via-docker-compose","title":"2. Download and launch the DataJoint MySQL server via docker-compose.","text":"<p>(Following is taken from DataJoint documentation.)</p> <ul> <li>Create a directory to store the docker-compose YAML file:</li> </ul> <pre>\nmkdir mysql-docker\ncd mysql-docker\nwget https://raw.githubusercontent.com/datajoint/mysql-docker/master/docker-compose.yaml\ndocker-compose up -d\n</pre> <ul> <li>Download a package that enables access to your locally running MySQL server:</li> </ul> <p>Linux: </p> <pre>\nsudo apt-get install mysql-client\n</pre> <p>Mac (via Homebrew): </p> <pre>\nbrew install mysql@5.7\nbrew tap homebrew/services\nbrew services start mysql@5.7\nbrew services list\nbrew link --force mysql@5.7\nmysql -V # verify the installation\n</pre> <ul> <li>Test the server access. If there are issues, refer here.</li> </ul> <pre>\nmysql -h 127.0.0.1 -u root -p\nEnter password: [type in your password here: default is \"simple\"]\n</pre>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#3-install-epiphyte","title":"3. Install <code>Epiphyte</code>:","text":"<p>There are two ways to install <code>epiphyte</code> -- via <code>pip</code> or cloning this repo. </p> <p>Note: certain features of the DataJoint python package have not been updated for more recent releases of Python. Therefore, DataJoint and epiphyte require an older version of Python (&lt;=3.9). For this reason, we recommend using a conda environment to install all needed packages and to develop from. </p>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#install-via-git","title":"Install via <code>git</code>","text":"<ul> <li>Clone the repository:</li> </ul> <pre>\ngit clone git@github.com:mackelab/epiphyte.git\ncd epiphyte\n</pre> <ul> <li>Create a new conda environment suitable for the <code>epiphyte</code> requirements: </li> </ul> <pre>\nconda create --name epiphyte python=3.9.18 ipython\n</pre> <ul> <li>Activate the conda environment: </li> </ul> <pre>\nconda activate epiphyte\n</pre> <ul> <li>Install the needed dependencies using <code>setup.py</code>:</li> </ul> <pre>\npip install .\n</pre> <ul> <li>Verify the installation:</li> </ul> <pre>\nconda list\n</pre>"},{"location":"tutorials/Launch%20the%20MySQL%20database%20locally/#or-install-via-pip-in-a-conda-environment","title":"Or, install via <code>pip</code> in a <code>conda</code> environment","text":"<ul> <li>Create a new conda environment suitable for the <code>epiphyte</code> requirements: </li> </ul> <pre>\nconda create --name epiphyte python=3.9.18 ipython\n</pre> <ul> <li>Activate the conda environment and install <code>epiphyte</code>:</li> </ul> <pre>\nconda activate epiphyte\npip install epiphyte\n</pre> <p>Continue to Configure and connect to the database.</p>"}]}