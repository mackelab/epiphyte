{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Change Point Annotations to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table doc_string convention:\n",
    "\n",
    "    class TableName(dj.TableType):\n",
    "        definition = \"\"\"\n",
    "        # Description of Table purpose\n",
    "        -> Dependency to existing Table           # Purpose of said existing Table\n",
    "        primary_key: datatype                     # Purpose of primary key \n",
    "        ---\n",
    "        normal_column:  datatype                  # Purpose of column (aka non-primary key) \n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) Design new Table\n",
    "\n",
    "- import necessary modules \n",
    "- think about the structure of the Table (primary keys, other keys) and the other existing Tables it might need to interact with\n",
    "\n",
    "#### Table doc_string convention:\n",
    "\n",
    "    class TableName(dj.TableType):\n",
    "        definition = \"\"\"\n",
    "        # Description of Table purpose\n",
    "        -> Dependency to existing Table           # Purpose of said existing Table\n",
    "        primary_key: datatype                     # Purpose of primary key \n",
    "        ---\n",
    "        normal_column:  datatype                  # Purpose of column (aka non-primary key) \n",
    "        \"\"\"\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.db_setup import *\n",
    "\n",
    "from annotation.data_driven_annotation import cpt\n",
    "import preprocessing.data_preprocessing.binning as binning\n",
    "import preprocessing.data_preprocessing.create_vectors_from_time_points as create_vectors_from_time_points            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Define the Type of Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangePointAnnotation(dj.Computed):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Initialize Table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangePointAnnotation(dj.Computed):\n",
    "    \"\"\"\n",
    "    # This table contains information about change points detected in spiking acitivity of single units;\n",
    "    -> BinnedSpikesDuringMovie                    # the unit information and the binned spike vectors\n",
    "    algorithm: varchar(32)                        # the algorithm version that was used to create the change point\n",
    "    ---\n",
    "    change_point: int                             # actual change point in neural recording time\n",
    "    t_value: int                                  # the t-value of the test statistic\n",
    "    additional_information=\"\":varchar(32)         # space for additional information\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        \"\"\"\n",
    "        Function that will run change point algorithm on spike trains and store results in database.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Define how the Table with be populated \n",
    "\n",
    "- write the make() function: generates the values to be put into the database\n",
    "- define how those values will be inserted (order, column names, ect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangePointAnnotation(dj.Computed):\n",
    "    ### ask: is there a meaning to the breakpoints in the defs? \n",
    "    ### as in, above the ---, primary keys,  and below: secondary? \n",
    "    \"\"\"\n",
    "    # This table contains information about change points detected in spiking acitivity of single units;\n",
    "    -> BinnedSpikesDuringMovie                    # the unit information and the binned spike vectors\n",
    "    algorithm: varchar(32)                        # the algorithm version that was used to create the change point\n",
    "    ---\n",
    "    change_point: int                             # actual change point in neural recording time\n",
    "    t_value: int                                  # the t-value of the test statistic\n",
    "    additional_information=\"\":varchar(32)         # space for additional information\n",
    "    \"\"\"\n",
    "    \n",
    "    def make(self, key):\n",
    "        \"\"\"\n",
    "        Function that will run change point algorithm on spike trains and store results in database.\n",
    "        \"\"\"\n",
    "        # Retrieve all patient id's and units that exist within the \n",
    "        # database and use for setting up the new computed table\n",
    "        patient_ids, units_ids, session_nr = SpikeTimesDuringMovie().fetch(\"patient_id\",\"unit_id\", \"session_nr\")       \n",
    "\n",
    "        for i in range(len(patient_ids)):\n",
    "            pat_id = patient_ids[i]\n",
    "            unit_nr = units_ids[i]\n",
    "            session = session_nr[i]\n",
    "\n",
    "            # load spike times into kernel\n",
    "            unit_name = (SpikeTimesDuringMovie & \"patient_id={}\".format(pat_id)\n",
    "                    & \"unit_id={}\".format(unit_nr) & \"session_nr={}\".format(session)).fetch(\"spike_times\")[0]\n",
    "            unit = np.load(unit_name)\n",
    "            os.remove(unit_name)\n",
    "\n",
    "            # bin spike times to 1000 msec (should this be a finer scale?)\n",
    "            bin_size = 1000\n",
    "            exclude_pauses = False\n",
    "            output_edges = True\n",
    "            binned_unit, edges = binning.bin_spikes(pat_id, session, unit, bin_size, exclude_pauses, output_edges)\n",
    "\n",
    "            # compute change points\n",
    "            # note: cpt algo auto-generates plots -- should make default not plotting for this purpose?\n",
    "            tau, ttest = cpt.find_changepoint_tt(binned_unit)\n",
    "\n",
    "            tstat = ttest[0] \n",
    "            change_point_time = [edges[tau], edges[tau+1]]\n",
    "\n",
    "            self.insert1({\"patient_id\": pat_id, \"unit_id\": unit_nr,\n",
    "                          \"session_nr\": session, \"bin_size\": bin_size,\n",
    "                          \"t_value\": tstat, \"change_point_bin\": tau, \"change_point_time\": change_point_time})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Populate the Table\n",
    "\n",
    "After coding up the class, testing it, and implementing it in the db_setup.py file, add a line into the ~/database/datanase_set_up.ipynb notebook that will run and create the Table as part of the database. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert this line into set_up notebook\n",
    "ChangePointAnnotation.populate()\n",
    "\n",
    "# if manual Table, then would need to manually population \n",
    "# ExampleTable.insert1(to_be_inserted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
